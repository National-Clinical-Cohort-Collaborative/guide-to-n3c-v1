[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Guide to N3C",
    "section": "",
    "text": "The Guide to N3C is designed to guide research with the National COVID Cohort Collaborative (N3C)."
  },
  {
    "objectID": "index.html#contributing-content",
    "href": "index.html#contributing-content",
    "title": "Guide to N3C",
    "section": "Contributing Content",
    "text": "Contributing Content\nThe N3C and its domain teams are healthiest when assimilating contributions from reseachers of different skills (e.g., clinicians & informaticians), specialties (e.g., endocrinology & gerontology), programming languages (e.g., Python, R, & SQL) and experiences (e.g., students & PIs).\nAccordingly, the guide-to-n3c-v1 repository welcomes input from you.\nIf you see a small mistake or unclear language, we invite you to inform us in a new issue or to edit the source and submitting a pull request. When an editor reviews and accepts your change, the website will be updated within minutes.\nIf you have an idea for something more substantial such as a chapter or section, please start a new issue and the N3C Educational Committee will coordinate with you where it fits best."
  },
  {
    "objectID": "index.html#platform",
    "href": "index.html#platform",
    "title": "Guide to N3C",
    "section": "Platform",
    "text": "Platform\n\nAs the chapters are being written, talk to the chapter’s Lead Author to learn if it’s being written in GitHub or Google Docs. Eventually all Google Docs chapters will be translated to Markdown. Once a chapter has been finally converted to Markdown…\nTo make small changes like spelling corrections, we recommend editing the source directly in GitHub. It handles the details without your knowledge (like starting a fork and prompting your pull request). From the appropriate page of the book, click on the “Edit this page ” button and type your change in the GitHub editor.\nSubstantial edits and writing are better accommodated by a text editor on your local machine that can preview the rendered content as you type. We suggest Visual Studio Code or RStudio.\nYou don’t have to understand the rest to contribute, but for those interested:\n\nThe majority of this book is written in a collection of Markdown documents and assembled by the Quarto.\nAfter your change is pushed to GitHub, a GitHub Action spawns a small VM that (a) collects all the Markdown documents, (b) calls Quarto/Pandoc to convert them to html, and (c) moves the rendered html files to the “gh-pages” branch.\nGitHub Pages serves the contents of the gh-pages branch to anyone with a browser."
  },
  {
    "objectID": "index.html#funding-and-licensing",
    "href": "index.html#funding-and-licensing",
    "title": "Guide to N3C",
    "section": "Funding and Licensing",
    "text": "Funding and Licensing\nThe N3C is supported by NIH National Center for Advancing Translational Sciences (NCATS).\nThis book is licensed under the Creative Commons Attribution-NoDerivatives 4.0."
  },
  {
    "objectID": "chapters/intro.html#sec-intro-mission",
    "href": "chapters/intro.html#sec-intro-mission",
    "title": "1  Introduction",
    "section": "1.1 Mission",
    "text": "1.1 Mission\nThe National COVID Cohort Collaborative, or N3C, is an open-science community stewarded by the National Center for Data To Health (CD2H) and the NIH National Center for Advancing Translational Sciences (NCATS), with significant contributions from many partners including the Clinical and Translational Science Awards (CTSA) program, Centers for Translational Research (CTRs), and thousands of researchers from hundreds of participating institutions in the US and abroad.\nFaced with the COVID-19 pandemic, the issue addressed by N3C is clear and direct: the US has no centralized data repository for health records and related information, hindering the response of the scientific community.1 Although healthcare providers are mandated by law to utilize electronic health records (EHR), little guidance coordinates how or exactly what information to collect and store. Commercial data-collection suites (e.g. Epic) are widely used in clinical settings, and controlled vocabularies (e.g. ICD10 and SNOMED) provide standards for representing medical information, but there are many such standards in use and software is highly configurable to the needs of individual organizations. As a result, databases of EHR information across the US are largely non-interoperable, presenting challenges to researchers hoping to use this vast national store of information in practice."
  },
  {
    "objectID": "chapters/intro.html#sec-intro-cdm",
    "href": "chapters/intro.html#sec-intro-cdm",
    "title": "1  Introduction",
    "section": "1.2 Common Data Models and N3C",
    "text": "1.2 Common Data Models and N3C\nIn recent years, the common solution to these issues have been the creation of Common Data Models (CDMs). A Common Data Model is an agreed-upon structure and format for databases containing clinical information, into which diverse organizational EHR databases can be standardized for research purposes. Even so, healthcare organizations are reluctant to share their data directly, because the risks associated with data breaches for protected health information (PHI) defined by Health Information Portability and Accountability Act (HIPAA) are high. As a result, several groups of healthcare and research organizations have formed federated research networks, where each organization in a network translates some subset of its data into an agreed-upon common data model, and affiliated researchers can then write queries intended for data in that format. Examples of such federated networks include PCORNet, i2b2, and OHDSI, each of which utilize their own common data model. In a federated model, data queries are generated by researchers, but executed locally by the data owners and only summarized or specifically requested results are sent back to researchers. This ensures protection for the patient data (which never leaves the boundaries of any individual organization), but prevents exploratory data investigation and other techniques (like many machine-learning methods) which require direct access to the totality of the data.\n\n\n\nFigure 1.1: A visual representation of disparate, non-compatible EHR databases across the United States.\n\n\nDriven by the imperative of addressing COVID-19, in concert with the use of a FedRAMP-certified cloud-based analysis ecosystem we call the N3C Data Enclave,2 N3C is partnering with EHR data providers across the nation to collect billions of EHR data points for millions of patients with and without COVID-19 in a single, secure, accessible database for research use. In this centralized model, researchers have direct access to the entirety of the data to support complex analyses including AI and other machine learning techniques. N3C simultaneously moderates controlled access to these data by research teams from across the country (and beyond), including from private companies, community colleges, universities, medical schools, and government entities. While data cannot be exported from the Enclave, published results can be after an export review (see Chapter 10).\nLike federated research networks, N3C also uses a common data model, known as OMOP, chosen for its strong community support and open nature, support of scientific use cases, and availability of tools for translating and working with data (Chapter 7 and Chapter 8 discuss OMOP in more detail).3 To rapidly collect data from around the country, N3C leverages the existing work data owners have already done to convert their organization-unique data to one of a handful of N3C-supported “source” common data models: PCORNet, i2b2, TriNetX, ACT, and OMOP. A potential data partner with data in PCORNet format, for example, will locally run a set of N3C-generated “PCORNet to OMOP” translation scripts prior to transferring the result to N3C via a secure channel. The process of coalescing multiple such data payloads into a unified whole is known as harmonization, and is a complex task even after everything has been mapped to OMOP initially. Two overlapping teams of EHR data experts participate in this process: one works closely with data partners to make it as easy as possible to contribute data to N3C, and another handles the post-ingestion harmonization and comprehensive quality checks of the incoming data."
  },
  {
    "objectID": "chapters/intro.html#sec-intro-enclave",
    "href": "chapters/intro.html#sec-intro-enclave",
    "title": "1  Introduction",
    "section": "1.3 The N3C “Enclave” and Data Access",
    "text": "1.3 The N3C “Enclave” and Data Access\nOnce harmonized and stored in the secure Enclave, the data are made available via a web-based interface to research teams using common tools such as SQL, Python, and R, as well as a number of code-light graphical user interfaces.\n\n\n\nFigure 1.2: A visual representation of N3C’s data harmonization from source-CDM model, and team-based access to these data in a secure cloud-based enclave.\n\n\nMere access to the Enclave, however, doesn’t automatically provide access to any of the protected data itself (although we do make other, publicly-available datasets available with minimal restriction for practice and learning purposes). Multiple “levels” of the data are available with different anonymization techniques applied, facilitating “just enough” access to research teams depending on their needs and ability to access protected health information. Accessing the most secure level, for example, requires obtaining approval by an Institutional Review Board (IRB) who validates the appropriateness of human subjects research, while the lowest level is heavily anonymized and accessible by private individuals (citizen scientists) with only certain legal and training requirements.\nBecause effective analysis of EHR data requires a diverse set of skills–especially clinical and data science/statistical expertise–N3C provides organizational structures and resources to rapidly create and support multidisciplinary research teams, many of which are geographically diverse as well. As of February 2023, dozens of these “Domain Teams” have supported over 400 research projects, contributed to by over 3,300 researchers hailing from 350+ different institutions and organizations. Over seventy data partners provide EHR data for 17 million patients (a third of whom have had COVID-19), representing 10.5 billion lab results, 3.5 billion medication records, 2 billion clinical observations, and 1 billion clinical visits. For up-to-date information on these numbers and more, visit our dashboard at https://covid.cd2h.org/dashboard.\n\n\n\nFigure 1.3: Summary statistics for N3C patients as of Aug, 2022. Confirmed COVID-19 patients are those with a known positive PCR or Antigen lab test, possible patients are those with likely symptomatology."
  },
  {
    "objectID": "chapters/intro.html#sec-intro-next",
    "href": "chapters/intro.html#sec-intro-next",
    "title": "1  Introduction",
    "section": "1.4 Where to Go Next",
    "text": "1.4 Where to Go Next\n\n1.4.1 For Researchers\nSo, why should you get involved with N3C? First and foremost, N3C provides an opportunity to participate in impactful team science. Investigators with expertise in multiple domains come together across organizational boundaries to understand and address the impact of COVID-19 across the United States. Dozens of N3C-supported publications span the gamut of research: E. R. Pfaff et al. (2022) applied machine-learning methods to understand important predictive factors for Long-COVID, and Sharafeldin et al. (2021) identified demographic and clinical factors contributing to mortality risk in cancer patients. Mehta et al. (2021) studied the use of hydroxychloroquine, remdesivir, and dexamethasone over time at multiple sites, revealing how treatment guidelines evolve in response to updated information over time. Sun et al. (2022) studied breakthrough infections after vaccination, Yang et al. (2021) evaluated COVID-19 outcomes in HIV patients, Reese et al. (2023) clustered patients to reveal sub-types of Long-COVID, and Anzalone et al. (2023) found higher hospitalization and mortality in rural communities. These are but a small sample of work produced by researchers participating in N3C.\nThis range of work is only possible by the diversity of interests and expertise researchers bring. Practicing clinicians, biostatisticians, machine-learning researchers, and others collaborate on projects inside the secure data enclave. N3C supports team science in a variety of ways. Domain Teams, for example, serve to connect groups with similar interests for peer support, research coordination, and collaboration building. While most Domain Teams are clinically oriented (e.g. the Pregnancy Domain Team), others are more general (e.g. the Machine Learning Domain Team). Chapter 5 covers Domain Teams in more detail. N3C provides a number of training and support venues, including regular office hours, training modules, and of course this book. See Chapter 11 for more information on these topics.\nOf course, N3C brings significant value as one of the largest databases of de-identified patient records in the US, covering drug prescriptions, conditions, procedures, and more, each associated with a corresponding visit and other information. Data are extensively quality-checked and harmonized for consistency to the OMOP common data model (see Chapter 3), which supports sophisticated filtering and querying (Chapter 7 and Chapter 8). Other data are available as well, including publicly-available datasets (e.g. from the US Census) and, for some patients, additional mortality, viral variant, or billing data from non-EHR sources (Chapter QQQ).\nBig data is of little value without powerful analysis tools. Fortunately, N3C’s enclave supports analyses with SQL, Python, and R, including thousands of popular libraries for the latter two. Backed by the high-performance distributed-computing framework Apache Spark, researchers can include billions of rows of data in a single analysis. Graphical tools are also available for those without coding expertise, and the N3C community generates reusable code and datasets to pave the way for others. All of these tools are cloud-hosted, so researchers only need to bring a web browser. For information on these topics, see Chapter 8.\nFinally, N3C has worked hard to make these resources secure and accessible. Enclave access requires coverage by a Data Use Agreement, which hundreds of institutions across the US and beyond have signed on behalf of all their employees and students. Data itself is accessed via a guided Data Use Request form in the enclave, and researchers can invite others to their projects at any time. See Chapter 5 and Chapter 6 for details.\n\n\n1.4.2 For Institutions\nThere are two primary ways that institutions can participate in N3C: (1) by signing an institutional Data Use Agreement; and (2) by contributing data.\nSigning an institutional Data Use Agreement provides access to N3C’s data enclave to all employees and students at your institution. Hundreds of institutions have done so, connecting their research community to a vast network of data, tools, and expertise. For more information about Data Use Agreements, see Chapter 5.\nInstitutions that contribute data to N3C gain more than recognition–contributing sites get early access to new features and pilot programs. More importantly, N3C provides data partners feedback on their data quality. While contributing sites implement their own data quality checks, N3C has discovered a number of issues that are only apparent in an environment with multiple organizations’ data (Emily R. Pfaff et al. 2022).\nFinally, N3C’s governance structures may be of interest to other organizations embarking on large-scale, team-science efforts. Chapter 4 introduces these perspectives.\nRegardless of how you think your institution can work with N3C, getting started is as simple as reaching out–either by contacting N3C leadership, submitting a ticket to our enclave-external helpdesk, or just stopping by office hours. More information on these latter two options may be found in Chapter 11.\n\n\n\n\nAnzalone, Alfred Jerrod, Ronald Horswell, Brian M Hendricks, San Chu, William B Hillegass, William H Beasley, Jeremy R Harper, et al. 2023. “Higher Hospitalization and Mortality Rates Among SARS-CoV-2-Infected Persons in Rural America.” The Journal of Rural Health 39 (1): 39–54.\n\n\nMehta, Hemalkumar B., Huijun An, Kathleen M. Andersen, Omar Mansour, Vithal Madhira, Emaan S. Rashidi, Benjamin Bates, et al. 2021. “Use of Hydroxychloroquine, Remdesivir, and Dexamethasone Among Adults Hospitalized with Covid-19 in the United States: A Retrospective Cohort Study.” Annals of Internal Medicine 174 (10): 1395–1403. https://doi.org/10.7326/M21-0857.\n\n\nPfaff, E. R., A. T. Girvin, T. D. Bennett, A. Bhatia, I. M. Brooks, R. R. Deer, J. P. Dekermanjian, et al. 2022. “Identifying Who Has Long COVID in the USA: A Machine Learning Approach Using N3C Data.” Lancet Digit Health 4 (7): e532–41. https://doi.org/10.1016/S2589-7500(22)00048-6.\n\n\nPfaff, Emily R, Andrew T Girvin, Davera L Gabriel, Kristin Kostka, Michele Morris, Matvey B Palchuk, Harold P Lehmann, et al. 2022. “Synergies Between Centralized and Federated Approaches to Data Quality: A Report from the National COVID Cohort Collaborative.” Journal of the American Medical Informatics Association 29 (4): 609–18.\n\n\nReese, Justin T, Hannah Blau, Elena Casiraghi, Timothy Bergquist, Johanna J Loomba, Tiffany J Callahan, Bryan Laraway, et al. 2023. “Generalisable Long COVID Subtypes: Findings from the NIH N3C and RECOVER Programmes.” EBioMedicine 87.\n\n\nSharafeldin, Noha, Benjamin Bates, Qianqian Song, Vithal Madhira, Yao Yan, Sharlene Dong, Eileen Lee, et al. 2021. “Outcomes of COVID-19 in Patients with Cancer: Report from the National COVID Cohort Collaborative (N3C).” Journal of Clinical Oncology 39 (20): 2232–46. https://doi.org/10.1200/JCO.21.01074.\n\n\nSun, Jing, Qulu Zheng, Vithal Madhira, Amy L. Olex, Alfred J. Anzalone, Amanda Vinson, Jasvinder A. Singh, et al. 2022. “Association Between Immune Dysfunction and COVID-19 Breakthrough Infection After SARS-CoV-2 Vaccination in the US.” Archives of Internal Medicine (Chicago, Ill. : 1908) 182 (2): 153–62. https://doi.org/10.1001/jamainternmed.2021.7024.\n\n\nYang, Xueying, Jing Sun, Rena C Patel, Jiajia Zhang, Siyuan Guo, Qulu Zheng, Amy L Olex, et al. 2021. “Associations Between HIV Infection and Clinical Spectrum of COVID-19: A Population Level Analysis Based on US National COVID Cohort Collaborative (N3C) Data.” The Lancet HIV 8 (11): e690–700."
  },
  {
    "objectID": "chapters/research-story.html#sec-story-onboarding",
    "href": "chapters/research-story.html#sec-story-onboarding",
    "title": "2  A Research Story",
    "section": "2.1 Onboarding",
    "text": "2.1 Onboarding\nThe startup costs are more expensive for an N3C investigation compared to most, but the incremental costs are cheaper. Even with strong institutional support, the university’s agreement with the NIH takes several months in legal and administrative channels. Yet after clearing that first (tall) hurdle for your site, each specific project takes only a week or two to be processed by the N3C staff. That’s a remarkably short time considering the scale of available data. It’s likely quicker than initiating a project based on a single EMR from your site –much quicker than EMRs from 70+ sites.\n\n\n\n\n\n\nVoice of someone like Bill Kurtis, but without the connotation of murder\n\n\n\nThe next afternoon you are chatting with your institution’s Navigator.1 She organized the local N3C presentation and invited any interested attendees to contact her.\n\n\n\n\n\n\n\n\nHover over a footnote to see the popup, without jumping to the bottom of the page.\n\n\n\n\nNavigator: I’m glad you think the N3C might help your research. As I wrote in this morning’s email, the agreement between the university and the NIH was established last year, so don’t worry about that.2 There are two remaining steps. First, complete your personal paperwork.3 Second, submit a DUR tailored to your hypotheses.4\nInvestigator: Remind me what a DUR is?\nN: A data use request describes your upcoming project. Once a committee approves your proposal, your project’s code and data are protected in this workspace allotted on the NIH cloud.5 Everyone on your project uses this dedicated workspace too. But they don’t have to submit additional DURs –your grant them permission to join yours.6\nI: Umm, I think I got it.\nN: It will make sense once you get it into it. Skim the example DUR proposals I’m sending now. Then start filling out this online form. Get as far as you can, and then I’ll help with the rest. If there’s something I don’t know, I’ll ask a friend. The DUR application process will take about an hour. Then the proposal will likely be approved within a week or two. In the meantime, we can talk about potential collaborators."
  },
  {
    "objectID": "chapters/research-story.html#sec-story-team",
    "href": "chapters/research-story.html#sec-story-team",
    "title": "2  A Research Story",
    "section": "2.2 Team building & collaborating",
    "text": "2.2 Team building & collaborating\nThe next step is to build a team to leverage retrospective medical records. Like most contemporary research teams, heterogenous skills are important. Ideally a team has at least:\n\na navigator who has learned the administrative and IRB requirements and is able to facilitate the investigation,\na data engineer who understands the challenges of EMRs and is able to extract and transform information,\na statistician who understands the limitations of observational collection and is able to model retrospective data,\na subject matter expert (SME) who has clinical experience with the disease of interest and is able to inform decisions with EMR variables, and\na principal investigator who knows the literature and is able form testable hypotheses and write the manuscript.\n\nN3C teams have some differences from conventional research teams at single sites. Some trends we have noticed are:\n\nMost N3C teams have researchers from at least three institutions. In the experience of the authors and editors, this encourages more diverse opinions and more willingness to express constructive criticism. Researchers from a single institution/lab are sometimes are more reluctant to generate contrary views.\nThe role of navigator is even more important. Your local EMR investigations are likely guided by someone with years of experience with the institutional safeguards and the personnel who can help when something stalls. N3C is bigger and younger than your site’s EMR research team, so an N3C project will benefit when guided by a bright, patient, and persistent navigator.\n\nIf your team needs someone, consider asking a relevant domain team for helping identifying and approaching a potential collaborator.\n\n\n\n\n\n\nVoice of Jamie Foxx\n\n\n\nRecruiting your crew…"
  },
  {
    "objectID": "chapters/research-story.html#research-teams-first-meeting",
    "href": "chapters/research-story.html#research-teams-first-meeting",
    "title": "2  A Research Story",
    "section": "2.3 Research Team’s First Meeting",
    "text": "2.3 Research Team’s First Meeting\n\n\n\n\n\n\nVoice of …\n\n\n\nThree weeks later…\nOnce the team is assembled, the first discussion is usually a variation of this exchange:\n\n\n\nInvestigator: Welcome everyone. We’d like to know if Drug A or Drug B is associated with better outcomes.\nStatistician: No problem. I can longitudinally model the type and amount of each medication received by each patient, relative to their intake date.\nData Engineer: Hmmm. I’m happy to produce a dataset with the dose and frequency columns7, but you may not find it useful. Those two columns are sparsely populated and they look inconsistent across sites.8\nI: Bummer. Then what’s realistic or feasible?\nSubject Matter Expert: Maybe this simplifies the picture… In my clinical experience, a patient rarely switches between Drugs A & B. Based on the initial presentation, their provider will pick A or B, and complete the regimen unless there’s an adverse event.\nS: In that case, should my initial model have three levels for treatment: A, B, and A+B?\nI: Probably. In the N3C database, can someone tell me how many patients get both during the same visit?\nDE: I’m already logged into the Enclave9. Give me 2 minutes to whip up something in SQL.10\nI: Oh my goodness, is that your cat? What a cutie! 11\nDE after a few minutes: Ok, I got it. [Unmutes himself.] Ok, I got it. 40% of patients are Drug A only, 52% are Drug B only, while 8% have at least one administration of both Drug A & B in the same visit.\nSME: Weird. 8% is a lot more than I expected. I was thinking around 1%.\nDE: Hmm, let me check. Give me another minute.12\nDE after a few minutes: I see what you mean. It looks like the bulk of the combo patients were admitted in the spring of 2020. After Jan 2021, only 3% of patients have both Drug A & B.\nS: I was already planning to model the phase of the pandemic. I’ll test if there’s a significant interaction between time and treatment.\nI: I like that as a starting point. Regarding the question about dose and frequency… For now let’s assume the providers were following the current dosing guidelines. Therefore the dose and frequency variables can be dropped from the analyses.\nS: Phew. I didn’t want to admit this. But I skimmed the dosing guidelines you emailed yesterday. It looked complicated. I wasn’t sure if I could appropriately incorporate those variables in the model.\nI: Well, that’s everything I wanted to cover today. See you in two weeks. Wait. I can’t believe I forgot. Sorry -our Navigator is sick this week and I’m almost worthless in her absence. Is everyone still on the call? For our secondary hypothesis, we want everything to connect to a patient’s diagnoses. …before, during, and after their covid hospitalization.\nDE: Bad news. This is kinda like the dose and frequency situation a few minutes ago. The structure of the OMOP diagnosis table theoretically can connect a patient’s diagnoses across different locations. But the quality of the historical records really depends on the site. Some places like Delaware leverage their state’s HIE13 to populate their N3C dataset. However other places are not as well connected. If a patient doesn’t have diagnosis records, it’s tough to determine if they are healthy, or if their primary care provider uses a siloed EMR.14\nI: Ugh. Good point.\nDE: But I’ve got good news. All the N3C contributors comprehensively capture all conditions diagnosed during the visit. Furthermore the diagnosis codes are standardized really well across sites. That’s because all the providers enter ICD codes into the EMR, which eventually can be cleanly mapped to OMOP’s standard concepts.15\nI: Well, that’s fine for this paper. Maybe our next manuscript will follow up with N3C’s death records.16\nSME: Sorry everybody, I have clinic this week, and they’re calling me. I need to drop.17\nS: Can I go back and ask a question about medications? I see that Drug A has 15 different brand names. I don’t recognize half of them. How should I classify them?\nDE: It’s actually worse than that. Sorry I’m a downer today. Can you see my screen? Drug A has 15 brand names and 200 different RxNorm codes; each package is uniquely identified by the NIH’s NLM. SME and I started on a concept set Thursday. We’re operationalizing the drug classes by their RxNorm ingredient. There are five ingredients that are conceptualized as Drug A. A friend showed me how she used the OMOP tables in a different project.18 I’ll roll up the meds into the patient-level dataset. It will have one integer for the number of medication records tied to a Drug A ingredient and another integer for Drug B records. You’ll probably want to transform the two counts into two booleans.\nS: And if I change my mind and decide to use the counts, then at least I’ll know.\nShoreleave: and knowing is half the battle."
  },
  {
    "objectID": "chapters/research-story.html#protocol-variables-definitions",
    "href": "chapters/research-story.html#protocol-variables-definitions",
    "title": "2  A Research Story",
    "section": "2.4 Protocol, variables, & definitions",
    "text": "2.4 Protocol, variables, & definitions\nThis aspect of the scientific process is probably both the most familiar and most vague. Most researchers have several years of graduate-level courses and real-world experience.\n\nTradeoffs are inevitable when selecting variables. Rarely will an investigator’s first choice be available.\nRetrospective medical records are extracted from a larger dataset. An investigation can use only a fraction of the terabytes in an EMR. Many decisions are involve to include only the relevant variables among the qualifying patients.\n\n{Mention CD2H’s Informatics Playbook}\n(Wu and C2DH 2022, chap. 1)"
  },
  {
    "objectID": "chapters/research-story.html#creating-an-analysis-ready-dataset",
    "href": "chapters/research-story.html#creating-an-analysis-ready-dataset",
    "title": "2  A Research Story",
    "section": "2.5 Creating an analysis-ready dataset",
    "text": "2.5 Creating an analysis-ready dataset\n{Conventional data engineer role. Dataset is created with input from the analyst.}"
  },
  {
    "objectID": "chapters/research-story.html#learning-and-using-omop-e.g.-concept-sets",
    "href": "chapters/research-story.html#learning-and-using-omop-e.g.-concept-sets",
    "title": "2  A Research Story",
    "section": "2.6 Learning and using OMOP (e.g. concept sets)",
    "text": "2.6 Learning and using OMOP (e.g. concept sets)\nOMOP originated in 2014 to facilitate the detection of small but significant side effects from new pharmaceuticals. Detecting a small signal requires a large datasets –larger than any single health care database (Sciences and Informatics 2019, chap. 1). Since then, the foundation has supported many other research goals. It is well-suited for N3C because:\n\nIt has evolved from 10? years and accommodates a wide range of data sources\nIt has an established community and documentation to help institutions convert their EMR to OMOP and to help researchers analyze their hypotheses.\n\n{3-4 sentence description of the original OMOP motivation. It standardizes (a) tables & columns and (b) vocabulary. Spend 1-2 paragraphs on concept set, focusing more on motivations than the mechanics.}"
  },
  {
    "objectID": "chapters/research-story.html#analyses",
    "href": "chapters/research-story.html#analyses",
    "title": "2  A Research Story",
    "section": "2.7 Analyses",
    "text": "2.7 Analyses\n\nDeveloping the Analyses\nfinalizing analysis\n\nPinning to a release\nDRR\nfigures"
  },
  {
    "objectID": "chapters/research-story.html#draft-paper-pub-committee",
    "href": "chapters/research-story.html#draft-paper-pub-committee",
    "title": "2  A Research Story",
    "section": "2.8 Draft paper, pub committee",
    "text": "2.8 Draft paper, pub committee\n\n\n\n\n\n\nVoice of Sam Elliot\n\n\n\nNearing the trail head…\n\n\n\n\n\n\nSciences, Observational Health Data, and Informatics. 2019. The Book of OHDSI: Observational Health Data Sciences and Informatics. United States: Independent. https://ohdsi.github.io/TheBookOfOhdsi/.\n\n\nWu, Chunlei, and C2DH. 2022. “Informatics Playbook.” https://playbook.cd2h.org/."
  },
  {
    "objectID": "chapters/lifecycle.html",
    "href": "chapters/lifecycle.html",
    "title": "3  Data Lifecycle - From Patients to N3C Researchers",
    "section": "",
    "text": "Note\n\n\n\nThis chapter is being drafted in Google Docs at https://drive.google.com/drive/u/0/folders/1ZjnFezddZk0YllqIDZN1mgexn1yM51tH\nSee a draft of the chapter outline at https://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAt this point, any edits to this chapter should be made in Google Docs. The current Markdown is for testing only. It is NOT the source of truth (yet)."
  },
  {
    "objectID": "chapters/governance.html",
    "href": "chapters/governance.html",
    "title": "4  Governance, Leadership, and Operations Structures",
    "section": "",
    "text": "Note\n\n\n\nThis chapter is being drafted in Google Docs at https://drive.google.com/drive/u/0/folders/19lryu26FaMAVrDHHARYcFJFpb18vOxcT\nSee a draft of the chapter outline at https://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAt this point, any edits to this chapter should be made in Google Docs. The current Markdown is for testing only. It is NOT the source of truth (yet)."
  },
  {
    "objectID": "chapters/onboarding.html#researcher-eligibility",
    "href": "chapters/onboarding.html#researcher-eligibility",
    "title": "5  Onboarding, Enclave Access, N3C Team Science",
    "section": "5.1 Researcher Eligibility",
    "text": "5.1 Researcher Eligibility\nCitizen scientists, researchers from foreign institutions and researchers from U.S.-based institutions are all eligible to have access to the N3C Data Enclave. Everyone with an N3C Data Enclave account has access to the tools and public datasets that are available in the Enclave.\nThere are several levels of Electronic Health Record (EHR) data that are available within the N3C Data Enclave. (For more information about the levels of data, see the section ‘Description of Levels 1, 2, 3’ in the ‘Getting & Managing Data Access’ chapter. LINK NEEDS TO BE ADDED HERE)\nCitizen scientists are only eligible to access synthetic data (Level 1). This data is artificial but statistically-comparable to, and computationally derived from, the original EHR data.\nResearchers from foreign institutions are eligible to access synthetic data (Level 1) and patient data that has been deidentified by removal of protected health information (PHI) (Level 2). (PHI includes 18 elements defined by the Health Insurance Portability and Accountability Act (HIPAA).)\nResearchers from U.S.-based institutions are eligible to access synthetic data (Level 1), deidentified patient data (Level 2) and patient data that includes dates of service and patient zip code (Level 3). (The latter data set is referred to as a limited dataset because it contains only 2 or the 18 PHI elements.)"
  },
  {
    "objectID": "chapters/onboarding.html#registration",
    "href": "chapters/onboarding.html#registration",
    "title": "5  Onboarding, Enclave Access, N3C Team Science",
    "section": "5.2 Registration",
    "text": "5.2 Registration\n\n5.2.1 ORCiD; InCommon vs Login.gov\n\n\n5.2.2 NIH IT security training\n\n\n5.2.3 Human Subjects Training\nDue to the secure nature of the data that is available in the N3C Enclave registration of users is key. There are two options in which users can log in and create an account, InCOmmon or Login.gov. The InCommon pathway is available to select institutions that participate in that identity management service. You can clock of the link to confirm if your organization participates. If your institution does not participate with InCOmmon, you will need to create a login.gov account. Use the link to Login.gov and complete the required fields to create an account. Once you know which pathway you will use to create an enclave account there are other security measures that are put in place, you will need to have a ORCiD, complete NIH security Trainingn, and also human subjects tratining.\nORCiD, which stands for Open Researcher and Contributor ID, is a unique identifier free of charge to researchers.\nThe N3C Data enclave is hosted by National Center for Advancing Translational Sciences and all researchers must complete the “Informational Securty, Counterintelligence, Privacy Awareness, Records Management Refresher, Emergency Prepardeness Refresher” course. The course can be accessed at https://irtsectraining.nih.gov/public.aspx. The course take approximately 60-90 minutes to complete and you should print your certificate of completion. Users need to complete Human Subjects training that aligns with their institution’s guidelines. You will need to provide the date of completion as part of enclave creation.\nOverall, users will need to confirm if they use the InCOmmon or Login.gov pathway, register for an ORCiD, have completed NIH Security Training, and completed institution human subjects training."
  },
  {
    "objectID": "chapters/onboarding.html#data-use-agreements",
    "href": "chapters/onboarding.html#data-use-agreements",
    "title": "5  Onboarding, Enclave Access, N3C Team Science",
    "section": "5.3 Data Use Agreements",
    "text": "5.3 Data Use Agreements\nThe data use agreement (DUA) establishes the permitted uses of the data in the N3C Data Enclave. By signing the agreement, an institutional official is assuring that users from their institution will abide by the terms defined in the agreement.\nA DUA must be executed by National Center for Advancing Translational Science (NCATS) and a research institution. The DUA must be signed by authorized institutional officials who have the authority to bind all users at their institution to the terms of the DUA. (A citizen scientist who is not affiliated with an institution must execute a data use agreement with NCATS.) A DUA will be in effect for five years from the DUA Effective Date.\nEvery individual who has access to the N3C Data Enclave must be covered by a DUA. This DUA must be in place before an account for the N3C Enclave is requested. If your institution has an active DUA, there is no additional action required with regards to the DUA. A list of institutions with DUAs in place can be found at List of DUA Signatories: (https://covid.cd2h.org/duas).\nThe Institutional Data Use Agreement form is available at:\nhttps://ncats.nih.gov/files/NCATS_N3C_Data_Use_Agreement.pdf\nFor more information see:\nhttps://ncats.nih.gov/n3c/resources/data-access"
  },
  {
    "objectID": "chapters/onboarding.html#enclave-access",
    "href": "chapters/onboarding.html#enclave-access",
    "title": "5  Onboarding, Enclave Access, N3C Team Science",
    "section": "5.4 Enclave Access",
    "text": "5.4 Enclave Access"
  },
  {
    "objectID": "chapters/onboarding.html#research-project-teams",
    "href": "chapters/onboarding.html#research-project-teams",
    "title": "5  Onboarding, Enclave Access, N3C Team Science",
    "section": "5.5 Research Project Teams",
    "text": "5.5 Research Project Teams\n\n5.5.1 Project Lead vs COllaborations\n\n\n5.5.2 Common roles and expectations (PIs, PMs, SMEs, Analysts, …)\n\n5.5.2.1 Expertise needed"
  },
  {
    "objectID": "chapters/onboarding.html#domain-teams",
    "href": "chapters/onboarding.html#domain-teams",
    "title": "5  Onboarding, Enclave Access, N3C Team Science",
    "section": "5.6 Domain Teams",
    "text": "5.6 Domain Teams\nThe N3C Data enclave is built for multi-site collaboration, and aims to bring together researchers of different backgrounds with similar questions using domain teams. Because N3C is multi-site, it can be difficult to collaborate with researchers of different backgrounds from different sites. Domain Teams exist to alleviate this difficulty. Some collaboration examples could be collecting pilot data for grant submission, sharing methodology and cohort logic, or learning how to use tools for large-scale data like machine learning.\nFor example, let’s say your institution just signed the DUA and you have some questions about the relationship between rurality and COVID treatments. You can look at the list of domain teams to see rural health. Then you can get in contact and go to the next upcoming meeting. At the meeting you can find out whether your questions are already part of an existing project within the domain team, or if a new project should be created.\nIf you don’t see your type of questions belonging to any existing domain teams you can create a new one here:\nhttps://n3c-help.atlassian.net/servicedesk/customer/portal/2/group/3/create/58\nSee here for a list of existing domain teams:\nhttps://covid.cd2h.org/domain-teams"
  },
  {
    "objectID": "chapters/onboarding.html#browsing-researchersprojectsinstitutions",
    "href": "chapters/onboarding.html#browsing-researchersprojectsinstitutions",
    "title": "5  Onboarding, Enclave Access, N3C Team Science",
    "section": "5.7 Browsing Researchers/Projects/Institutions",
    "text": "5.7 Browsing Researchers/Projects/Institutions\n\n5.7.1 Object Explorer, Public Dashboard\nOnce you have an enclave account you can log in and use the object explorer to browse researchers and research projects. The object explorer can be found on the left hand side of your view on the enclave homepage. Click on Object Explorer and there are several object-type groups, to search researchers and projects, click on N3C Admin, from there are you can search Data Use Requests, N3C Researchers, and Research Projects. If you are looking for a particular N3C researcher, you can click on that box and in the search bar type in their name and hit enter. A new box will be displayed and you can clock on that researcher’s name and from there you can see the research projects that are lead of or a collabotaro on. You can go back to the Object Explorer, object type groups, click N3C Admin again, and search research projects by clicking that box. Using the search bar at the top of the page you can search by key word. Type in the key word and click enter and a results box will be displayed. You can view all results to find the project in which you are interested in joining. From that screen, you can select the title of the project that you are interested in joining or reading about. There is a public-facing version of searching projects in addition to using the enclave as a search method. Users can search https://covid.cd2h.org/projects or https://covid.cd2h.org/dashboard/exploration#projects and search for title, lead investigator name and also the institution. There are many features that are available to search using the public-facing dashboard. There are four categories of."
  },
  {
    "objectID": "chapters/data-access.html",
    "href": "chapters/data-access.html",
    "title": "6  Getting & Managing Data Access",
    "section": "",
    "text": "Note\n\n\n\nThis chapter is being drafted in Google Docs at https://drive.google.com/drive/u/0/folders/1rrYYjSm5cWni1wyvs__-ByPl9Q6uRy10\nSee a draft of the chapter outline at https://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAt this point, any edits to this chapter should be made in Google Docs. The current Markdown is for testing only. It is NOT the source of truth (yet)."
  },
  {
    "objectID": "chapters/data-understanding.html",
    "href": "chapters/data-understanding.html",
    "title": "7  Understanding the Data",
    "section": "",
    "text": "Note\n\n\n\nThis chapter is being drafted in Google Docs at https://drive.google.com/drive/u/0/folders/1OHv1P2DKGucKBpSNEiQp8lGfR2xYHPAW\nSee a draft of the chapter outline at https://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAt this point, any edits to this chapter should be made in Google Docs. The current Markdown is for testing only. It is NOT the source of truth (yet)."
  },
  {
    "objectID": "chapters/enclave-tools.html#sec-enclave-tools-intro",
    "href": "chapters/enclave-tools.html#sec-enclave-tools-intro",
    "title": "8  Introducing Enclave Analysis Tools",
    "section": "8.1 Introduction",
    "text": "8.1 Introduction\nThis chapter introduces tools in the N3C Enclave used to analyze data, view results, track project progress, and obtain shared data and code developed in the N3C community. The focus is on accessing and using each tool, the skill level needed, as well as what types of analyses each tool is geared toward. It is expected that you know how data are organized in the N3C Enclave, including the OMOP data model, vocabulary, and concept sets (see Chapter 7 for details).\n\n\n\nFigure 8.1: High-level overview of an N3C project\n\n\nDue to the complexities of analyzing large clinical datasets, such as that compiled in the N3C Enclave, it is common, and many times necessary, to work in multidisciplinary collaborative teams to answer a research question. Figure 8.1 provides a high-level overview of the process behind forming a team and performing research using the N3C Enclave, along with the recommended field expertise needed during each phase. It is important to note that while certain team members may take the lead at various stages, a project benefits if all team members are engaged to some degree at all phases. Managing these collaborative and multi-faceted projects requires good record keeping. The N3C Protocol Pad (see Section QQQ in Chapter 9 is designed specifically for N3C research and to aid teams in designing, implementing, reporting, and publishing their work in a Findable, Accessible, Interoperable, and Reusable (FAIR) manner (Wilkinson et al. 2016) (see also https://www.go-fair.org/fair-principles/). Thus it is recommended that you utilize this tool throughout the implementation of your project.\nA research project in N3C starts with organizing a team with the required expertise (clinical, informatics, statistical, etc), followed by defining clinical questions around COVID-19 and characterizing the cohorts needed to answer each, i.e. clinical phenotyping. Because the N3C contains real-world EHR data that is harmonized from multiple data models and dozens of institutions, some information needed to identify an ideal clinical phenotype may be missing or incomplete. Thus, it is important to assess what information is needed to create an N3C computational phenotype for your cohorts. This could include using conditions, labs, or medications as proxies to identify a cohort if some information is not available. Generally, clinicians or other subject matter experts are leading this process with informaticians/data scientists providing guidance on what information is included in the N3C Enclave, what is missing or sparse, and overall data quality (see Chapter 9). Some data quality aspects can be easily obtained through the use of Logic Liaison Templates (see Section 8.3.3) accessible through the N3C Knowledge Store. The N3C Enclave application Contour can be utilized at this stage, along with Code Workbooks for quick querying and visualizing of the data. Additionally, Fusion can be utilized to keep track of developed concept sets and utilized to easily input them into Logic Liaison Templates.\nThe generation of a computational phenotype overlaps with the generation of concept sets (see Section QQQ in Chapter 7 for details), and is often a cyclical process. Well-vetted concept sets are key to obtaining robust cohorts, thus, having a team member familiar with the organization of data and the OMOP vocabulary, such as a data liaison, who can work closely with a clinician is beneficial. Concept set generation can be done using the N3C Enclave Concept Set Browser, or externally through OHDSI ATLAS.\nInformaticians and data scientists then utilize the computational phenotype and vetted concept sets to generate fact tables (i.e. datasets containing information about each patient like demographics, comorbidities, lab results, etc) for the cohorts of interest using the raw OMOP tables, which requires specific knowledge of how to work with large datasets in a Spark environment. Fact tables include all the information needed to characterize a cohort and perform downstream analyses to answer your research questions. Facts can include patient demographics, socioeconomic status, COVID status/severity, medications, comorbidities, etc. Logic Liaison Fact Table Templates can provide you a boost by allowing fast and robust generation of commonly used facts using N3C vetted concept sets and peer-reviewed code as a starter table. You can then append this base fact table to include project-specific facts needed for analyses. Figure 8.6 and Figure 8.7 in the N3C Knowledge Store section of this chapter provide a more detailed view of how Logic Liaison Templates can be integrated into a project to expedite fact table generation. The generation of the original fact tables from raw OMOP tables can be done using Code Workbooks (Section 8.4.3) or Code Repositories (sec-enclave-apps-repo).\nData scientists and statisticians can then analyze the extracted and formatted fact tables. This includes statistical tests, summary tables, visualizations, and reports for the team to discuss. Data analysis is also a cyclical process with all team members engaged in assessing results and circling back to further refine the computational phenotype and concept sets if needed. Depending on the type of analysis needed, Code Workbooks or Contour can be utilized at this step, followed by Foundry’s Notepad for reporting out results for secure team dissemination within the Enclave environment.\nOnce you obtain results that you wish to share with others, all tables, figures, and other data needed for reporting in publications, conference submissions, presentations, or any other activity outside the N3C Enclave environment must be submitted as a Data Download Request for a download review by NCATS (see Chapter 10). The download request is meant to ensure no prohibited data is being downloaded as per the N3C Data Download Policy summarized in the Publishing and Sharing Your Work chapter. After approval, your results can be included in research outputs, such as publications, and then submitted to the Publication Review Committee (see Chapter 10). This step is necessary to ensure data are being reported properly in the context of the research project and that proper attribution is being given to all those who contributed to the success of the research, either directly or indirectly. Upon approval, you are free to submit to the venue of choice and freely present the approved data to anyone at any time. Data download requests are performed within the Enclave environment, followed by submitting a Google Form to the Publication Review Committee.\nThe following sections of this chapter discuss each of the features and applications needed to perform research in the N3C Enclave, and include links to external Palantir documentation, as well as direct the reader to other chapters of this book that contain a deeper dive into various N3C topics, such as the organization of data and best practices. This chapter is best utilized along side the information provided in the next chapter, Best Practices and Important Data Considerations (see Chapter 9), which includes information on recommended data workflows, such as scheduling automatic data builds, to keep your research current, managing your projects using the Protocol Pad, and much more."
  },
  {
    "objectID": "chapters/enclave-tools.html#sec-enclave-tools-concepts",
    "href": "chapters/enclave-tools.html#sec-enclave-tools-concepts",
    "title": "8  Introducing Enclave Analysis Tools",
    "section": "8.2 Using Concept Sets",
    "text": "8.2 Using Concept Sets\nAs discussed in the previous chapter Understanding the Data (see Chapter 7), the electronic health information coded in the various vocabularies used across the country are mapped to the OMOP common data model. By leveraging the hierarchical structure, parent codes and descendants can be captured in one fell swoop to create intensional concept sets for use in analysis.\n\n\n\nFigure 8.2: Concept Set Browser Homepage\n\n\nThe Concept Set Browser shown in Figure 8.2 is an N3C specific tool that allows you to explore and modify existing concept sets as well as create new concept sets to fit your exact study needs. For more details around the process of concept set creation, read the Concept Sets section (see Section QQQ in Chapter 7). It is recommended that, if you are a new researcher, you start your search for a concept set with the list of N3C Recommended concept sets. These concept sets have been frozen in their validated state by the Logic Liaisons and the Data Liaisons after obtaining clinician and informatic reviews (see Section QQQ in Chapter 7). They are also the ones used to identify common comorbidities and other facts on the Phenotype Explorer and in the Logic Liaison Fact Table templates. The recommended other method of finding commonly used concept sets is by exploring bundles within the Concept Set Browser. These are groups of concept sets that are often used together. Further exploration of all other concept sets in the Concept Set Browser is also an option, though only advised when proceeding with the understanding that many of the existing concept sets that are not part of the N3C Recommended or bundles are crafted to be specific to one particular study team’s requirements.\nOnce concept sets have been identified for use in your analysis through the Concept Set Browser, the concept set members table becomes the link between concepts and the encompassing concept set as shown by Figure 8.3. You then have to “point” the code to the concept set members table to access this linkage. Once this has been accomplished, the choice becomes using the most recent version of a concept set (concept_set_members.concept_set_name where most_recent_version = TRUE) or using a specific version of the concept set (concept_set_members.codeset_id = {codeset id value}). While there are alternative ways to utilize concept sets and concept ids, the method described above is highly recommended primarily for the ability to quickly update a concept set without having to find and change hard-coded concept ids in a data processing pipeline.\n\n\n\nFigure 8.3: concept_set_members table\n\n\nReferring to a concept set by name and using the most recent version is often the preferred method for concept sets marked as N3C Recommended since these concept sets can only be updated by N3C core contributors after they have gone through a validation process which has been described in the previous chapter Understanding the Data (see Chapter 7).\nFor concept sets that have not undergone the validation process and have not been marked as N3C Recommended by the N3C core contributors, it is recommended that the research team performs their own validation on an existing concept set or creates a new concept set with the input of a clinician. The concept set should then be referenced using its codeset ID when you are performing your data analysis. This will allow your team to perform their analysis from start to finish without worry about unvalidated modifications to the concept set. However, the codeset id being referenced in the code may need to be updated if the team chooses to modify the concept set once starting the analysis.\nIn constructing phenotypes from concept sets, concept sets may also need to be joined together; these actions are best done in SQL/R/Python code workbook (see Section 8.4.3) transforms with the use of the Logic Liaison’s Combined Variable template or in code repositories (see Section 8.4.4)."
  },
  {
    "objectID": "chapters/enclave-tools.html#sec-enclave-tools-store",
    "href": "chapters/enclave-tools.html#sec-enclave-tools-store",
    "title": "8  Introducing Enclave Analysis Tools",
    "section": "8.3 N3C Knowledge Store",
    "text": "8.3 N3C Knowledge Store\nThe N3C Knowledge Store is an application where you, as an Enclave user, can discover shared code templates, external datasets, reports, cohorts, and Python libraries (collectively also known as Knowledge Objects or KOs) and share similarly re-usable Knowledge Objects of your own with other Enclave users, regardless of the specific project from which the resource originated. Most Knowledge Store (KS) objects come about as core contributors and researchers alike develop resources they believe may be useful for others either within or outside of their research project team and wish to share them with the broader community. If you find yourself in this situation, you can easily create, submit, and share a KS resource by following this Code Workbook Template Quick Start Guide. Otherwise, more specifics on how to navigate the KS can be found in this Knowledge Store Guide within the Enclave.\n\n8.3.1 Datasets\nOf the many types of Knowledge Objects, the most common are datasets and code templates. Datasets in the Knowledge Store can be internal or external. Internal datasets are generated from data inside the enclave, typically by researchers as part of their project, and are often of patient or row level granularity. As described in the previous chapter Understanding the Data, external datasets found in the Knowledge Store provide a wealth of information from public datasets that have been brought into the Enclave along with the crosswalks necessary for joining these aggregate data to person level data at various levels of granularity (see Section QQQ in Chapter 7). Either type of dataset can be imported into a workbook or code repository of the appropriate data access level to be used as a starting point for further transformation or analysis.\n\n\n8.3.2 Code Templates\nDepending on the author’s intended use, some code templates can be applied to your custom input dataset while other code templates produce a dataset that can be joined to your study dataset. The code templates themselves can also be imported and customized to produce a dataset for defining a study cohort with key information to use during analysis or simply used as example logic if you are newer to coding. Code templates, in general, are often meant to help transform the massive amount of raw data to smaller, more digestible, and more readily applicable datasets and facts. A few helpful starter templates are those produced by the Logic Liaisons, some of which can be seen in Figure 8.4.\n\n\n\nFigure 8.4: N3C Knowledge Store Homepage\n\n\n\n\n8.3.3 Logic Liaison Fact Tables and Templates\nThe Logic Liaison Fact Tables and Templates are specifically designed to provide a validated and community agreed-upon method for calculating particular facts at the date level and/or the patient level. Through surveying the Domain Team Leads to establish a list of commonly derived variables and continuous feedback from the N3C Community to refine and update this list, the Logic Liaisons have developed, disseminated, and maintain two main fact table templates and an additional fact table template for SDoH variables. These two main fact table templates each produce day-level and person-level data frames of commonly used derived base variables for all N3C patients as well as a subset who have an index date for their acute COVID-19 infection, the confirmed COVID-19 positive patients (PCR/AG positive or U07.1 COVID-19 diagnosed). These day-level and person-level datasets are commonly referred to as the Logic Liaison Fact Tables and can be imported directly into a workbook for use without modifying the template. These fact tables are produced using a default set of concept sets from the N3C Recommended Concept Sets list and a set of default values for the template’s parameters.\nThe main fact table template KOs include not only the shared logic for importing/customizing the template for both data access levels, but also a detailed README, example datasets (aka default Logic Liaison Fact Tables), and example code workbooks as exemplified by Figure 8.5. It is recommended you first open the README and example code workbooks to see how the default fact tables are generated and then decide whether you would like to use the fact tables as they are or import the template to customize concept sets and/or template parameter values to generate your project specific version of the fact tables. The SDoH Variables ALL PATIENTS template provides you with a curated set of 70 geographically-based SDoH measures tied to each patient. Because joining this data requires a valid five digit zip code, these fields are only available for patients with a five digit zip code in Level 3 (LDS) data.\n\n\n\nFigure 8.5: Example Logic Liaison Fact Table Template Knowledge Object\n\n\nThe Logic Liaisons have also developed, disseminated, and maintained a handful of overall data quality templates, ancillary fact table, and ancillary data quality templates in the Knowledge Store. Figure 8.6 depicts how one could apply the set of Logic Liaison Templates to generate augmented fact tables with a goal of asking one or more research questions within that project.\n\n\n\nFigure 8.6: Example Application of Logic Liaison Overall Quality, Fact Table, and Ancillary Fact Templates\n\n\nThe data quality templates provide a variety of data tables and visualizations. The first two of which provide a method for evaluating overall quality of the harmonized data ingested from sites.\n\nData Density by Site and Domain: Calculates the Standardized Density, Median Absolute Deviation (MAD), and Directional Median Deviations (DMD) with respect to the number of unique patient/concept/days for each of the major OMOP tables (i.e. condition_occurrence, drug_exposure, etc) and uses them to create a heatmap displaying how many MADs each site is from the median for each OMOP table. The template also scores the site’s date shifting practices.\nWhitelist Filtering: Creates a bar plot showing whitelisted data partners that have, at minimum, a certain percentage of COVID patients associated with a specified measurement, condition, drug, procedure, etc. Sites not meeting the minimum requirement are removed from the whitelist. These tables can be used in downstream filtering to keep only sites meeting the user-defined minimum data quality.\n\nOnce the main fact table templates mentioned earlier this section have been applied to generate the base fact tables, the ancillary fact templates utilize the day-level and person-level datasets of the base fact templates to efficiently generate additional derived variables based on broadly requested and applicable logic such as:\n\nVaccine Fact: Creates a vaccine fact table at the person level that summarizes their vaccination information\nStudy Specific Fact Indexing: Summarizes the indicators of a visit-level patient fact table with respect to whether they were present pre-, post-, or in a user-defined window surrounding an index date corresponding to a study-specific event. This template is similar to the All Patients Facts Tables with the exception that it is organized around a study-specific event rather than COVID diagnosis.\nCombined Variables ALL PATIENTS: Allows you to combine two variables (variable 1 and variable 2) in a visit-level table by creating a new “same-day occurrence variable” indicating that both variables appear that day for that patient. You can also choose to make an “either/or” variable in the visit-level table that combines two variables (variable 3 and variable 4) into a new variable that flags days where at least one of the input variables is recorded for that patient.\nCombined Variables COVID PATIENTS: Same as above except for patients with facts found based on their covid index date.\nCCI Score: Provides an all-time score or a before-or-day-of-covid score (depending on your selection in the template) per patient based on the CCI weights (Charlson et al. 1987).\n\nFigure 8.7 is a continuation of Figure 8.3 to demonstrate how you could continue to apply the Logic Liaison Templates to the augmented fact table created in order to answer their specific research question within a project.\n\n\n\nFigure 8.7: Example Application of Logic Liaison Ancillary Quality Templates\n\n\nThe ancillary data quality templates are intended to be applied to fact tables after cohort creation and initial variable creation to stratify question specific facts by site.\n\nSystematic Missingness by Site and Study Variable: Produces a final visualization that has a binary indicator for whether or not a site is systematically missing meaningful data for the study variables in the input dataset\nFact Density by Site Visualization: Calculates the Standardized Density, Median Absolute Deviation (MAD), and Directional Median Deviations (DMD) with respect to the numerical values in each column of the input table (any non-numerical field is converted to a binary value using the isNotNull() function) and creates heatmaps to visualize the metrics.\n\nOnce you obtain results you wish to share outside of the Enclave for a project, the results must undergo a Data Download Request before being available to export outside of the Enclave. Additional details around exporting results can be found in the Publishing and Sharing Your Work chapter (see Chapter 10). Training materials for getting started with Logic Liaison Templates are available here within the Enclave. Outside of the main confirmed COVID+ template and a subset of columns in All Patients, these templates could be generalized to apply to research projects outside of the Enclave where studies do not necessarily need to fall within the scope of COVID-19.\nWhile it is not necessary to utilize Knowledge Store resources when conducting your research project, it does allow you to get a jumpstart on gathering and understanding the data by avoiding effort duplication and providing a general starting point. You can then build upon this fact table using the ancillary templates that allow self-definition of the index event, combining variables, generating a CCI score, and associating SDoH variables based on zip code crosswalks. The Logic Liaison ancillary data quality templates provide the same structure for analyzing data missingness, density, and contribution quality by site. Further explanation as to why these Knowledge Store objects are highly applicable can be found in the Best Practices and Important Data Considerations chapter (see Chapter 9)."
  },
  {
    "objectID": "chapters/enclave-tools.html#sec-enclave-apps",
    "href": "chapters/enclave-tools.html#sec-enclave-apps",
    "title": "8  Introducing Enclave Analysis Tools",
    "section": "8.4 N3C Enclave Applications",
    "text": "8.4 N3C Enclave Applications\nThis section will cover the usage of various applications made available in the N3C Enclave, including Protocol Pad, Contour, Code Workbooks, and more (a complete list of Foundry applications can be found here). Before designing and running an analysis utilizing data in the Enclave, it helps to understand the concepts of a “data pipeline” and a “data transform” as well as how the data are stored and accessed via Apache Spark on a distributed file system. For those unfamiliar with these concepts a high-level overview, along with links to documentation on code optimization in the N3C Enclave, can be found in Section [QQQ] of Chapter [QQQ].\n\n8.4.1 N3C Protocol Pad\nN3C Documentation: Quick Start Guide and Detailed Instructions\n\nElectronic lab notebook\nPromote collaboration, organize work, and translation to final manuscript\nMethodology checklist\n\n\n\n\nFigure 8.8: N3C Protocol Pad Homepage\n\n\nBefore diving into an analysis, it is highly recommended that you use N3C’s Protocol Pad shown in Figure 8.8 to organize your thoughts and path forward. Research studies can span many months and pass through the hands of many team members before reaching a stage where you may want to share the results through publication or other approved means. The Protocol Pad serves as an electronic lab notebook to help organize tasks, track progress, and document results in a cohesive format throughout the process of reaching a study’s final state. As a result of this organization and tracking, the tool facilitates easy translation of the work, decisions, and contributors to producing a final manuscript if that is the goal of the protocol.\nProtocol Pad is the foundation for performing reproducible and repeatable science within the N3C Enclave. The templates, checklists, and links to key resources provided within the tool guide you along the path of well structured division of labor and use of best practices when performing research using the observational data in the Enclave. The tool also assists your team in keeping the work in alignment with the project. A more in depth explanation of how Protocol Pad can facilitate research can be found in the Best Practices and Important Data Considerations chapter (see Chapter Chapter 9). Documentation on the tool’s functionality can be found in this Quick Guide as well as this more Detailed Guide.\n\n\n8.4.2 Contour\nPalantir Documentation: Contour Overview\n\nProgramming-free analysis interface\nPoint-and-Click data analysis pipeline development\nData summary and visualization\nAllows customization with Contour’s expression language\nDashboard development\n\n\n\n\nFigure 8.9: Example Contour Analysis\n\n\nThe Contour application is a programming-free interface to the N3C Enclave that allows those with limited knowledge of Python, R, and SQL to create top-down analysis pipelines in a point-and-click fashion, as well as generate dynamically updated dashboards. A Contour analysis starts by specifying the path to the input dataset as shown in Figure 8.9. Subsequent transforms of that dataset are then specified, which can include adding/calculating new columns, filtering rows or columns, joining with other datasets, creating summary figures and charts, summarizing tables through pivoting, and more. Contour’s expression language also allows for more complex querying and data aggregation beyond the default operations provided. Once an analysis is complete, resulting datasets can be saved to the Enclave for use in additional Contour pipelines or other Enclave applications, like Code Workbooks (see Section 8.4.3). Contour can also quickly create summary figures from source tables without code, and has a variety of visualization options, including bar charts, histograms and heatmaps.\nFigures or summary tables created in Contour can be exported to a dashboard within Contour. Contour Dashboards allows chart-to-chart filtering, and an easy drag-and-drop interface to build the dashboard while iterating on an analysis. A dashboard is dynamic and interactive, allowing the reader to adjust the graphs to better explore analysis results in a guided and structured way. Figures generated in a Contour analysis can also be exported to other Enclave applications like Notepad for reporting out results. The main difference between Notepad (see Section 8.4.6) and a Contour Dashboard is that Notepad provides a static report with figures that cannot be dynamically changed by the reader. A detailed orientation to Contour can be found in the Foundry Documentation here.\n\n\n8.4.3 Code Workbooks\nTutorial: Intro to Code Workbook\nPalantir Documentation: Code Workbook Overview\n\nGraphical organization of logic\nSimplification of code\nEasy reuse of pre-authored logic\nAdd visualizations to reports\nSupports Python, R, SQL, PySpark, and SparkR\nConsole debugging and development\nBranching facilitates collaboration and reproducibility\nWorkspace to reuse templatized logic\nExporting code to GitHub\n\nCode Workbook is a GUI-based application for you to apply code-based transformations to datasets for the purpose of creating new datasets and visualizations. The explicit goals of the application are to facilitate a collaborative environment in which you can quickly iterate over logic to produce artifacts interoperable with the suite of Enclave applications. The default Code Workbook interface is structured as a directed graph in which nodes represent either datasets or transformations that output datasets. Edges represent the flow of data through the graph such that upstream datasets are inputs for logical operations performed by downstream code transforms. Figure 8.10 shows an abstract version of a Code Workbook, while Figure 8.11 is an actual screenshot in the Enclave where data flows from the left to the right. Any dataset which you have access to within the workspace where the Code Workbook is located can be imported as an input to the various types of transformations. For each transformation one or more tables are specified as the input and are transformed into a single output table (Figure 8.10). Multiple transformations can also be strung together (Figure 8.11) to create an analysis pipeline (see Palantir’s Anatomy of a Data Pipeline module for more detailed information, as well as Chapter 9). In Code Workbook, the primary and required output of a transformation is always a single table; however, visualizations such as graphs and charts can also be generated and saved along the way. Note that the code performing the transformation and the resulting output table are always represented as a single node in the Code Workbook interface.\n\n\n\nFigure 8.10: Abstracted view of data transforms\n\n\n\n\n\nFigure 8.11: Example Data Transformation Pipeline in Code Workbook\n\n\n\n8.4.3.1 Types of Transforms\n\nManual Entry transforms allow you to manually populate a custom dataset directly in the specific Code Workbook you are currently working in as a “quick and dirty” alternative to manually populating importable or referenceable datasets with Fusion).\nPython/PySpark Code transforms contain a Python function that takes one or more datasets as input parameters and returns a single dataset as output.\nR/SparkR Code transforms contain an R function that takes one or more datasets as input parameters, and outputs a single data frame.\nSQL Code transforms let you write a Spark SQL query to create a new dataset from the available input datasets.\nTemplate transforms are parameterized blocks of reusable code which you can configure from a point-and-click interface. Many code templates are available in the Knowledge Store (see Section 8.3), but you can create your own templates scoped to their workspace. Multiple single-node templates can be combined to create a multi-node template to allow reuse of entire configurable pipelines.\nVisualize transforms offer a point-and-click interface for you to create figures and pivot tables. Note this transform is only available for use on saved datasets; it cannot accept unsaved transformations as an input parameter.\n\nBoth Python and R transforms can optionally return a single dataset and produce visualizations using Python libraries/R packages. Any visualization produced in a Code Workbook can subsequently be embedded in a Notepad document. Datasets returned by a transform are ephemeral by default, that is, the transform must be recomputed each time the dataset is used as a downstream input, but options exist to conserve compute power by either caching or saving the output. Caching stores the output temporarily, while saving the dataset stores it permanently in the Enclave. It is recommended that transforms in a pipeline requiring significant compute be saved as datasets to reduce iteration time during development. In addition to manually clicking “Run” on a transform, a build schedule can be defined to recompute it at regular intervals based on a trigger. You can choose the trigger to be the successful update of an input dataset or simply the elapsing of a specified period of time. This capability can best be visualized using the Data Lineage tool described later in this chapter (see Section 8.4.7).\nThe Console, Global Code, and Logs panels facilitate quick iteration and code development and debugging. The Console allows you to interactively execute and check syntax in Python, R, or SQL outside of a transform node. Global Code allows you to define custom functions available to all transforms in the Code Workbook. Each code transform includes a Logs panel to view console output generated by code and to view detailed stack traces when transforms fail due to an error.\nMany Python and R transforms rely on external libraries and packages which can be made available via the Environment Configuration. The Enclave provides default configurations tailored to common use cases. For instance, the default profile includes common packages like pandas and tidyverse for routine analysis, whereas the profile-high-memory profile includes packages like foundry_ml for machine learning. You can create your own Environment Configurations which include packages meeting your project’s specific needs.\nNot all libraries and packages are included in the list of options, but you can submit a ticket within the Enclave by clicking on Help & Support > Help Center > Report an Issue to request additional packages be made available. The Enclave maintains instances of the default configurations on warm standby, allowing them to be quickly initialized when you request a new environment. Custom configurations require more time for initialization as instances of these must be started from scratch rather than merely assigned. For this reason, it is recommended to use default configurations when possible.\nFollowing best practices for collaborative software development, Code Workbook allows for branching of the logic within a workbook. As with other popular version control technologies (i.e. Git), branching allows you to make copies of a workbook which your team members can develop independently of the source workbook. Once the development in a particular branch is deemed complete, it can be merged back into the originating branch. Prior to the merge, you can preview both line-level differences within each node, as well as node-level differences of nodes that have been added/removed. Good practice dictates that you perform all development on individual branches, which are then merged back into a common master branch.\nBecause the master branch can change in the interval between you creating a branch and merging it back in, it is important to preview merge changes to ensure that the branch’s contributions are both correct and compatible with the current state of the master branch. However, note that your branch will be automatically deleted after it is merged, which is an important difference from the normal Git behavior. Another prime use case for code branching is to ensure the reproducibility of a given dataset used in a research project. Because the OMOP and N3C-curated datasets are also versioned, you can create a code branch in which all input datasets are set to the same version release (as shown in Figure 8.12) to effectively freeze a dataset used in a specific analysis for later reproducibility while still allowing the possibility of adding additional features. User-generated datasets are set to the same branch as the Code Workbook in which they were created. Finally, Code Workbooks allow you to collect and download all coded transformations within a single workbook into a Git repository that can be easily uploaded to GitHub for public dissemination.\n\n\n\nFigure 8.12: Pinning to an input dataset’s release version\n\n\nPalantir has created extensive documentation of the Code Workbook application including tutorials. N3C has also published training materials.\n\n\n\n8.4.4 Code Repositories\nPalantir Documentation: Code Repository Overview\n\nProduction pipelines\nCode reuse across projects\nBuilt in version control\n\n\n\n\nFigure 8.13: Example Code Repository\n\n\nCode Repositories shown in Figure 8.13 are available within the N3C enclave and should be used when you wish to share code across multiple Code Workbooks or projects, or need to develop a robust production pipeline. Code Repositories do not support data visualization, coding in R, or point-and-click templates. Additional differences between Code Repositories and Code Workbooks can be found in the Palantir Documentation. Palantir has also compiled several tutorials on how to create, publish, and maintain Code Repositories.\nFor any large analytic project, there are many pieces of code and other artifacts that should be shared between different components within the project. Some code is useful enough that it should be shared across projects. Code Repositories provide a standard mechanism for encapsulating reusable components and allowing them to be reused within projects.\nUnderlying the Code Repository is the Git version control system. You can edit and maintain code using all of the capabilities of Git including comparing versions, branching and pull requests. Versions that are tagged in Git will be automatically published in the Enclave as a shared library, which allows you and others that have access to your project space to import that code into other Code Workbooks (note this requires you to create a customized environment that imports your code specifically, which may increase workbook initialization time). If you want to make your repository public so others outside of your project workspace can use it you can do one of the following:\n\nPackage your code into a properly structured python package. This allows other researchers from different project spaces to run it from their Code Workbooks or Repositories.\nSubmit the Code Repository to the Knowledge Store where it will then be visible to anyone who has Enclave access.\nPublish the Code Repository to a public Github where the code will then become accessible to anyone outside the Enclave.\n\nMore information on Code Repositories can be found in the Palantir Documentation (Palantir 2023).\n\n\n8.4.5 Fusion\nPalantir Documentation: Fusion Sheet Overview\n\nUseful for writing back datasets for use within the Enclave\nLeverage cell references and spreadsheet functions\nSync tables to a dataset to use in other Foundry applications\nCreate charts\nAllow customization and flexibility\n\n\n\n\nFigure 8.14: Example Fusion Sheet\n\n\nFusion, shown in Figure 8.14, is a spreadsheet application within the Enclave analogous to Microsoft Excel or Google Sheets. Palantir provides extensive documentation. Fusion allows you to sync specific cell ranges within a spreadsheet to Spark datasets, which can subsequently be imported into any other Enclave application. Fusion is an excellent option for use cases which require manual data entry, such as curating lists of concept sets (see Chapter 7) to configure the Logic Liaison Fact Tables and Templates (see Section 8.3). Unlike many other Enclave applications, Fusion is not suitable for large datasets; each document has a maximum size of 50 MB. Similar to Google Sheets, multiple users can simultaneously view and edit the same document.\nFusion provides many features familiar to other spreadsheet applications such as cell-referencing formulas, formatting, and a charting library to name a few. While you cannot directly import external .xls/.xlsx formatted files into the Enclave, you can copy/paste external dataset values into Fusion. For example, you can copy and paste concept IDs from ATLAS to use in an analysis or metadata manually curated for a dataset. To import larger external datasets into the N3C Enclave see Chapter X, and N3C procedures and protocols around importing large external datasets. In addition to standard spreadsheet functionality, Fusion has additional features which allow it to integrate with the rest of your Enclave environment. Objects created within Fusion, such as formatted tables, can be embedded in Notepad). Finally, Fusion sheets can be templatized to facilitate replication of similar functionality.\n\n\n8.4.6 Notepad\nPalantir Documentation: Notepad Overview\n\nNote taking with ability to add embeds of the workflow\nDocumentation of pipelines or datasets\nCreate report templates\nMonthly status reports using template function\nUnable to create dashboard or complex page-based text editing\n\n\n\n\nFigure 8.15: Example Notepad Document\n\n\nMany research projects in the Enclave are complex, involving multiple summary datasets, statistical analyses, and visualizations scattered across multiple applications and documents. Notepad is a tool that is often used for consolidating various research artifacts from multiple sources within the Enclave into a single coherent document as shown in Figure 8.15. Formatted Fusion tables, Contour charts, Python/R-generated images from Code Workbooks, and more are all embeddable in a Notepad document, with the option to add a title and caption for each artifact. Users can also create sections and provide narrative structure to their documents using Markdown. A Notepad document can be arranged and configured using a point-and-click interface.\nAll embedded objects can be configured to remain static or refresh automatically when the underlying data sources update. Notepad is also useful for annotating documents, presenting an executive summary of results for internal stakeholders, or external presentations after being approved for download request and export as PDF. Logic Liaison Templates (see Section 8.3.3) in the Knowledge Store generally includes a README which is created using Notepad. The tool does have limitations in that it cannot be used to create dashboards that include chart-to-chart filtering; however, Contour Dashboards can provide this feature for tabular data and Quiver Dashboards can provide this feature for object or time series data. Palantir has curated documentation for creating and editing Notepad documents. Palantir also has documentation for their application known as Reports that was previously used in a similar fashion though with less functionality compared to Notepad.\n\n\n8.4.7 Data Lineage (aka Monocle)\nPalantir Documentation: Data Lineage Overview\n\nFind datasets\nExpand or hide a dataset’s ancestors and descendants\nVisualize a data pipeline and its details\nFacilitate dataset build scheduling\n\n\nTODO: Figure for Example Data Lineage Visualization I can’t get the gif to work when rendering to pdf.\nWhether you’re creating a data pipeline for your research project or investigating one from the Knowledge Store, you’ll likely want to holistically assess the dataset’s origins with the Data Lineage tool shown in ?fig-16-data-lineage. The data pipeline flows from left to right, which is an intuitive way to visualize the relationships between datasets and their ancestors or descendants. Views are enhanced with color-coding and grouping. The Data Lineage tool allows you to view details such as a dataset’s schema, last build datetime, and the code that generated the dataset. You can use this lineage tracing tool to understand and verify the data curation methods when using Knowledge Objects and other shared datasets as part of their study analysis. The Data Lineage tool also allows you to see upstream dataset(s) aka potential triggers and downstream dataset(s) aka potential targets for setting up dataset build schedules. Palantir Documentation provides additional instructions and descriptions of Data Lineage.\n\n\n\n\nCharlson, Mary E., Peter Pompei, Kathy L. Ales, and C.Ronald MacKenzie. 1987. “A New Method of Classifying Prognostic Comorbidity in Longitudinal Studies: Development and Validation.” Journal of Chronic Diseases 40 (5): 373–83. https://doi.org/https://doi.org/10.1016/0021-9681(87)90171-8.\n\n\nPalantir. 2023. “Documentation: Code Repositories &Gt; Overview.” https://www.palantir.com/docs/foundry/code-repositories/overview/.\n\n\nWilkinson, Mark D, Michel Dumontier, IJsbrand Jan Aalbersberg, Gabrielle Appleton, Myles Axton, Arie Baak, Niklas Blomberg, et al. 2016. “The FAIR Guiding Principles for Scientific Data Management and Stewardship.” Scientific Data 3."
  },
  {
    "objectID": "chapters/practices.html",
    "href": "chapters/practices.html",
    "title": "9  Best Practices and Important Data Considerations",
    "section": "",
    "text": "Note\n\n\n\nThis chapter is being drafted in Google Docs at https://drive.google.com/drive/u/0/folders/1ExkYChsnO3hYZk6HCI5cEfQdQJ9F-ynw\nSee a draft of the chapter outline at https://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAt this point, any edits to this chapter should be made in Google Docs. The current Markdown is for testing only. It is NOT the source of truth (yet)."
  },
  {
    "objectID": "chapters/publishing.html",
    "href": "chapters/publishing.html",
    "title": "10  Publishing and Sharing Your Work",
    "section": "",
    "text": "Note\n\n\n\nThis chapter is being drafted in Google Docs at https://drive.google.com/drive/u/0/folders/1kmrjxsdrwbspPucPTU3hiOHMXJRQQpPp\nSee a draft of the chapter outline at https://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAt this point, any edits to this chapter should be made in Google Docs. The current Markdown is for testing only. It is NOT the source of truth (yet)."
  },
  {
    "objectID": "chapters/support.html#sec-support-internal",
    "href": "chapters/support.html#sec-support-internal",
    "title": "11  Help and Support",
    "section": "11.1 Support Tickets: Enclave-Internal",
    "text": "11.1 Support Tickets: Enclave-Internal\nWhile live-support options are available, submitting questions via “tickets” (also known as “issues” in the enclave) helps ensure they reach the right person and that questions are logged and tracked. Given the sensitive nature of N3C data, questions that pertain to patients or data partners should be asked within the enclave itself.\nThe within-enclave support ticket system is also a good avenue for technical questions, including about platform features, performance, permissions, and tooling. In fact, when submitting a ticket in the enclave, the ticket itself will automatically track the resource being viewed when the ticket is submitted.\nTo illustrate an example, we first navigate to the Synthea Notional Data entry in the Data Catalog (under “Projects & files” in the left navigation menu).\n\n\n\nFigure 11.1: Navigating to Synthea\n\n\nNext, we’ll open the condition_era table which displays a preview in the Dataset Preview application. Let’s suppose we have a question about this data, or perhaps have discovered a potential data quality issue.\n\n\n\nFigure 11.2: Synthea Preview\n\n\nTo submit a ticket about the currently opened dataset, we’ll open the Help menu near the top, and select “Report Issue.”\n\n\n\nFigure 11.3: New Issue\n\n\nThis opens a dialog requisition information about the ticket. Notice that the RESOURCE is identified as the condition_era table we had opened. Since we are asking a question about the data, we’ll select “Data quality.”\n\n\n\nFigure 11.4: New Issue: What kind of help do you need?\n\n\nOnce we click Next, we’ll be prompted to change the resource of interest or application being used (if desired). Since we are reporting an issue on a dataset, we even have the option of selecting the specific column we are interested in. We’ll just click Next here.\n\n\n\nFigure 11.5: Share some details\n\n\n\n\n\n\n\n\nReporting Issues via Help Center\n\n\n\nUsing “Report Issue” from the Help menu of an enclave application is the preferred way to submit a ticket, as this option keeps the best track of the resource being reported from. While most enclave applications have a Help menu near the top left, not all do. In these cases you can alternatively submit an issue by finding the “Help & support” option in the lower part of the left navigation bar and choosing the “Help Center”. This will open a sidebar to the right, with a large blue button at the bottom for “Report an Issue.”\n\n\nFinally, we are prompted to submit our issue, including a title and description with pre-filled questions depending on the issue type selected. Answering all of these is not required, but any information you can add that speaks to them is helpful. This section also allows you to upload a screenshot if desired. Even though these issues are protected in enclave, you should not screenshot any data (or results like summary tables or figures), as that would result in your local computer storing, even if temporarily, unapproved patient-level information. Nevertheless, when excluding patient data is possible, a screenshot may help diagnose the problem, and the support personnel who respond to the issue may request a screenshot during follow up.\n\n\n\nFigure 11.6: More details\n\n\nWe can scroll down in this panel to see more advanced information pertaining to the ticket. Priority should generally be left to “Medium,” since “High” priority is used to alert infrastructure support of system-wide issues or outages likely to affect a majority of users. The default assignee is the “N3C: Issues Triage Team,” who will further route the ticket to the appropriate support group (issues are triaged most business days, but follow up from support may take longer). Followers allow you to specify other users who will receive alerts about this issue. Adding labels to the ticket is optional as well, since the triage team usually applies relevant labels for tracking purposes.\n\n\n\nFigure 11.7: Submit\n\n\nOnce we click Submit and refresh the browser page, we’ll see that a new “warning” icon has been added to the interface indicating that the resource now has one or more open issues relating to it, and it can be clicked on to open a menu with details. This warning will also show for other users who open the resource, and it will show in the file browser for this dataset. Reporting issues about datasets from the datasets themselves is thus a mechanism for alerting support teams and other N3C researchers about potential data quality issues. The same principle applies to other resource types like Code Workbooks, in cases where multiple researchers are working with them.\n\n\n\nFigure 11.8: Recent Issues\n\n\n\n11.1.1 Issue followup\nAfter your ticket is submitted, it will be routed to a triage team who will decide which support group is best able to address it. These include groups with admin-level access and general knowledge of the enclave (at least one of which is familiar N3C-specific tools or workflows), experts in N3C data ingestion and harmonization processes, as well as individuals with expertise in OMOP and other N3C technologies.\nWhen activity occurs on your ticket you will see a small orange dot appear on the Notifications navigation menu item indicating you have a new notification, clicking this will show this notification (and any others you may have received). By default, you will also receive email notifications for ticket activity. This can be configured under your account preferences (the Account item in the left navigation menu). Finally, you can review and respond to tickets via the Issues application (which may be hidden for you in the left navigation bar under “View all apps”)."
  },
  {
    "objectID": "chapters/support.html#sec-support-external",
    "href": "chapters/support.html#sec-support-external",
    "title": "11  Help and Support",
    "section": "11.2 Support Tickets: Enclave-External",
    "text": "11.2 Support Tickets: Enclave-External\nWhile the enclave-internal ticket system is a good avenue for more technical questions about data analysis or the data itself, most other questions should be directed to an enclave-external ticket system (sometimes called the “support desk”). At the very least, if your issue is you cannot login to the enclave, that cannot be reported via the enclave-internal ticketing system!\n\n\n\nFigure 11.9: Starting a ticket\n\n\nThe external help desk can be found at https://covid.cd2h.org/support. Here you will find a link to “Submit a Support Request” that directs you to select the kind of support you need.\n\n\n\nFigure 11.10: Ticket details\n\n\nEach of the options are described, and range from enclave access support (commonly used for login issues), Domain Team creation or support, questions about Data Use Requests or the Data Access Committee (commonly used to check on DUR review status), PPRL data, and “everything else.” In general, this help desk is staffed by a broader range of core N3C administrators, and so is generally the best option outside of technical or data questions.\nAfter selecting a support area, you will be given the option to select sub-categorizations, enter a description of the issue or question, provide a summary title for tracking and select the user (usually you) submitting the request. The list of users is pre-populated based on N3C data, but you can also type an email address in the same field.\nOnce submitted, you will receive an email with a link to the ticket. You can use this link to make further comments, or do so by replying to the email directly."
  },
  {
    "objectID": "chapters/support.html#sec-support-office",
    "href": "chapters/support.html#sec-support-office",
    "title": "11  Help and Support",
    "section": "11.3 Office Hours",
    "text": "11.3 Office Hours\nN3C hosts office hours on Tuesdays and Thursdays of most weeks, at 10a PT/1p ET. The join link can be found at https://covid.cd2h.org/support. All are welcome to join, from experienced N3C analysts looking for help with complex machine learning implementations, to brand new researchers needing help finding their project workspace. Experienced N3C volunteers are on hand and able to help with most questions. They can also refer you to external resources, or suggest submitting a ticket when appropriate. Some researchers join just to watch and learn. To satisfy N3C data privacy rules, N3C staff utilize Zoom breakout rooms allowing researchers to share their screen only with others who have the same level of access."
  },
  {
    "objectID": "chapters/support.html#sec-support-training",
    "href": "chapters/support.html#sec-support-training",
    "title": "11  Help and Support",
    "section": "11.4 Training Resources",
    "text": "11.4 Training Resources\nMany training and educational resources are available within the enclave where we can readily organize and link them to relevant resources. The “Training Material” button on the enclave homepage displays several categories of training materials:\n\n\n\nFigure 11.11: Training Material\n\n\nWhile the documentation and self-guided tours provide information about the cloud-based enclave platform, they don’t provide any information specific to N3C. The Training Portal is the primary location for N3C-related training materials, while N3C Community Notes allow researchers to post short articles/guides for others to use. The Support option will redirect to a page linking to the two ticket systems described above.\n\n11.4.1 Training (Training Portal)\nThe N3C Training Portal hosts training “modules.” The list of training modules is roughly sorted by researchers’ N3C journey–those new to N3C will likely find the first modules of most interest, while those preparing to publish their results should scroll to the end.\nModules are searchable by keyword (from their title and description), and a brief list of Suggested Modules can be found in the orange button in the upper-right, though browsing through the full list is recommended.\n\n\n\nFigure 11.12: Training Modules\n\n\nThe Training Portal also has a Paths View, which shows potential learning paths of interest. These links are not formally assigned, and act more like a recommendation system to help navigate and find modules and resources of interest. This interface is limited in the number of items it can display, so you may want to filter using the “Starting Module Category” dropdown.\n\n\n\nFigure 11.13: Learning Paths\n\n\nOpening a module from the main list view reveals an overview of the module, including title, description, topics, learning objectives, suggested background, and estimated time to complete. Immediately below the title is a link whose URL points at this specific module in the portal for sharing.\n\n\n\nFigure 11.14: Overview of a Training Module\n\n\nTo the right is a list of resources comprising the materials of the module; these may be videos or documents, example enclave resources like code workbooks, or in some cases links to relevant external resources. The small search box allows you to filter the list, and is especially useful for modules with many resources such as our Enclave Users’ Group series discussed below.\nN3C community members are welcome to suggest or develop new training modules for inclusion in the portal. Several have been developed this way, and each module tracks authorship information. To contribute to the training portal or other N3C-related education and training efforts, just contact the Education & Training Domain Team at https://covid.cd2h.org/ET-DT.\n\n\n11.4.2 Self Guided Tours (Academy)\nThis platform feature provides step-by-step walkthroughs of individual tools like Contour and Code Workbooks. The Foundry 10X and 20X series are recommended and cover the basic tools researchers will encounter. Along the right individual steps walk you through an example workflow or analysis. Note that because these tours are not developed by N3C, the example analyses and data will not be N3C-relevant. You may also be prompted to create files or work in a “home folder” (which N3C has disabled) or a project workspace you don’t have write permissions to. Instead, you can utilize the N3C Training Area (see below).\n\n\n\nFigure 11.15: Academy walk-through\n\n\n\n\n11.4.3 N3C Community Notes\nN3C Community Notes is a within-enclave application where researchers can author and share short articles, code snippets, or FAQ items. The application supports a rich tagging system, and notes can be linked to other N3C resources like training modules, knowledge objects, and concept sets. The note overview contains a link whose URL points at this specific note in the application for sharing.\n\n\n\nFigure 11.16: N3C Community Notes\n\n\n\n\n11.4.4 Documentation\nThe official platform documentation is a rich resource for details on applications, and includes many guides and how-tos. If you don’t desire to read all of the documentation in detail, you should at least skim sections relevant to applications you use. The search function can find articles relevant to specific application features or techniques.\n\n\n\nFigure 11.17: Palantir Documentation\n\n\n\n\n11.4.5 Having Trouble? (Support)\nThis last entry in the Training Resources page simply redirects to a page describing, and linking to, the two ticket systems described earlier in this chapter."
  },
  {
    "objectID": "chapters/support.html#sec-support-area",
    "href": "chapters/support.html#sec-support-area",
    "title": "11  Help and Support",
    "section": "11.5 N3C Training Area",
    "text": "11.5 N3C Training Area\nThe N3C Training Area is a project workspace where all N3C users can practice and learn using notional datasets (described below). This workspace is also used to organize other training resources (like the Training Portal).\n\n\n\nFigure 11.18: Training Area\n\n\nIf you wish to create a practice folder, you are free to do so inside the “Practice Area - Public and Example Data.” Simply open it up, and using the green +New button create a new subfolder with a unique name (many use shortened usernames, e.g. “oneils”). Within this folder you will be able to create new analyses, and these will have access to the notional datasets described next."
  },
  {
    "objectID": "chapters/support.html#sec-support-notional",
    "href": "chapters/support.html#sec-support-notional",
    "title": "11  Help and Support",
    "section": "11.6 Notional Datasets",
    "text": "11.6 Notional Datasets\nOMOP-formatted N3C patient data are protected by a Data Use Request process, but researchers may wish to explore OMOP tables and enclave tools prior to completing a DUR. The N3C Training Area is the place to do such practice, and N3C provides two notional (i.e. fake) datasets formatted similarly to the Level 2 and Level 3 data that do not require a DUR to access. They are both available via the data catalog under “Synpuf Synthetic Data” and “Synthea Notional Data”.1 The data they contain differ in some important ways, described next.\n\n\n\nFigure 11.19: Two sets of synthetic data\n\n\n\n11.6.1 SynPuf Synthetic Data\nSynPuf is short for “Synthetic Public Use Files,” or EHR records that have been scrubbed of personally identifiable information and released for public educational use. These SynPuf files originate from SynPuf Medicare Claims data and have been converted to OMOP format by the OHDSI community. The content of these data differ from N3C data in many ways (e.g. records prior to Jan. 1, 2018 are included), and they represent a distinctive population of Medicare-eligible patients. Lastly, the data are not recent, and so contain no COVID-19 related records such as diagnoses, lab tests, or vaccine records. The SynPuf data do not contain some N3C customizations to the OMOP data model, for example the manifest table used in N3C data to describe metadata about contributing data partners.\nCompared to the Synthea data however, SynPuf data better represent real EHR data, including the potential for data entry errors, diversity in medical codes used, and missing data. We thus recommend that researchers interested in trying statistical or machine learning models (or other applications better suited for realistic data) use the SynPuf notional data.\n\n\n11.6.2 Synthea Notional Data\nIn contrast to the SynPuf data, the Synthea notional data are derived from a probabilistic model of early-pandemic COVID-19 patient trajectories published by Walonski et al. converted to OMOP. These data include COVID-19 diagnoses and lab tests for a subset of patients. The main limitation of this notional data is its model-generated cleanliness. Pneumonia in the Synthea dataset, for example, is always represented with the same concept ID, while in real data a variety of pneumonia sub-type concept IDs are represented. Real EHR data also contain missing, erroneous, or inconsistent information. With regard to COVID-19, N3C has modified the original data published by Walonski et al. to include more diversity and realism in COVID-19 diagnoses and lab tests; a README file in the data catalog describes the modifications in detail.\nThe Synthea data have an additional benefit of being slightly more aligned with real N3C data for additions beyond the OMOP standard. For example, while SynPuf data tables include data partner IDs, Synthea also includes a manifest table with mock data partner metadata. The Synthea data also include constructed macrovisit information."
  },
  {
    "objectID": "chapters/support.html#sec-support-ohdsi",
    "href": "chapters/support.html#sec-support-ohdsi",
    "title": "11  Help and Support",
    "section": "11.7 OHDSI Resources",
    "text": "11.7 OHDSI Resources\nN3C relies heavily on the OMOP common data model, developed by an international group of researchers comprising the Observational Health Data Sciences and Informatics consortium, or OHDSI. OHDSI provides a wealth of training and support resources, the most significant of which are the Book of OHDSI (the inspiration for this book), EHDEN Academy (online video-based courses and lectures), and the OHDSI forums. These cover basic and advanced usage of OMOP data as well as techniques and good practices for working with observational EHR data.\n\n\n\nFigure 11.20: The Book of OHDSI is a great starting place for learning OMOP"
  },
  {
    "objectID": "chapters/support.html#sec-support-community",
    "href": "chapters/support.html#sec-support-community",
    "title": "11  Help and Support",
    "section": "11.8 Community Resources",
    "text": "11.8 Community Resources\nIn addition to Community Notes mentioned above, several venues are available to get help and support from the broad community. N3C researchers include statisticians and data scientists of all stripes, clinicians, and even industry and government representatives. More than a few new collaborations have resulted from peer-to-peer support in N3C!\n\n11.8.1 Enclave Users’ Group\nThe Enclave Users Group (EUG) is a community-focused forum where analysts can share practical information on techniques, tips, and methods in the N3C Data Enclave. Each session one or more presenters share a topic, emphasizing live Q&A, discussions, and meeting new people. Topics range from statistical techniques like propensity score matching, scaling machine learning algorithms for use on billion-row datasets, tips for scientific software development, and introductions of new N3C resources and initiatives. EUG sessions do not present protected data, so sessions are recorded and example resources are available in the N3C Training Area. For more information and an index of recorded sessions see the Enclave Users’ Group module in the Training Portal.\n\n\n\nFigure 11.21: Enclave Users’ Group\n\n\n\n\n11.8.2 Slack\nSlack is commonly used for team communication in N3C, and several widely-subscribed channels are great support resources. These include #n3c-analytics where researchers ask general questions about methods or data (with 390+ members), #n3c-training where training-related announcements are posted, and a variety of topic-focused channels such as #n3c-ml for machine-learning. N3C uses the Slack organization of the National Center for Data To Health at https://cd2h.slack.com. Access however is managed via the N3C onboarding process, where Slack-preferred emails are collected.\n\n\n11.8.3 Domain Teams\nDomain Teams, covered in more detail in other parts of this book, are excellent support and training resources for their members. Not only can Domain Teams answer common questions of new N3C researchers, they can answer questions that pertain to their area of expertise. The pregnancy domain team, for example, is the best source of knowledge for locating pregnancy-related records in EHR data.2"
  },
  {
    "objectID": "chapters/support.html#sec-support-liaisons",
    "href": "chapters/support.html#sec-support-liaisons",
    "title": "11  Help and Support",
    "section": "11.9 Data and Logic Liaisons",
    "text": "11.9 Data and Logic Liaisons\nLogic and Data Liaisons are teams contributing to the N3C mission through software development and user support, prioritizing the needs of domain teams and their members. In order to perform research, users need to identify key variables for analysis. These key variables are generated through Code Workbooks and Templates that utilize specific Concept Sets (lists of key variables from constituent vocabularies), that identify and extract data to answer research questions. Through interaction with Domain Teams, the Data and Logic Liaisons continually develop and refine a core set of N3C Recommended concept sets and code templates that generate commonly used variables and support efficient customization by research teams. They also provide support services as described below.\n\n11.9.1 Data Liaison Services\nEHR data are complex, more so when they cover data contributed by 75+ sites. The Data Liaisons group consist of those most familiar N3C data, including members of the phenotype and ingestion and harmonization teams. Data Liaisons are subject matter experts in biomedical, translational, clinical data standards and Real-World data utilization to support program investigator analyses. Data Liaisons curate and review N3C-recommended concept sets for researcher use, and can field data-related questions, which should be submitted via the enclave-internal ticket system. Potential data quality issues should also be submitted via enclave-internal ticket system for routing to the Data Liaisons for review.\nFor basic questions about the OMOP common data model, refer to the OHDSI resources, and training portal modules for getting started with OMOP. Personalized assistance is provided during N3C Office Hours. Support for Concept Set consultation can be received by submitting a help desk technical support ticket in the N3C enclave. The Data Liaisons team will send a representative to your domain team meetings on an as needed basis for general consultation.\n\n\n11.9.2 Logic Liaison Services\nLogic Liaisons consist of analysts with significant technical expertise for research with N3C data. Although they do not develop project-specific research code as a service, they do create Knowledge Objects such as reusable code templates and convenient derived datasets. Logic Liaison members provide technical support at office hours, and many are active in the #n3c-analytics Slack channel.\nLogic Liaisons support N3C researchers who are learning to use and adapt the Logic Liaison code fact tables and templates. They also help researchers assess the feasibility of the project design with regards to data availability and data limitations. This team helps researchers assess and clean their project-specific fact tables using Logic Liaison Data Quality templates, which help research teams decide which sites to include in the analysis.\nLogic Liaison Code Fact Tables and Templates can be accessed by searching the Knowledge Store for “Logic Liaison Template”. Recorded trainings are provided in the “Logic Liaison Templates” module of the N3C Training Portal. Personalized help is provided during N3C Office Hours. Support for issues and errors encountered when using a Logic Liaison Template can be received by submitting a technical support ticket in the enclave. Team members are also active in the #n3c-analytics Slack channel. The Logic Liaison team will send a representative to your domain team meetings on an as needed basis for general consultation."
  },
  {
    "objectID": "chapters/machine-learning.html",
    "href": "chapters/machine-learning.html",
    "title": "12  Machine Learning",
    "section": "",
    "text": "Note\n\n\n\nThis chapter is being drafted in Google Docs at https://drive.google.com/drive/u/0/folders/1HZ3IGv17zUl9t8RxZSl4uOq_FRzrgTp_\nSee a draft of the chapter outline at https://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAt this point, any edits to this chapter should be made in Google Docs. The current Markdown is for testing only. It is NOT the source of truth (yet)."
  },
  {
    "objectID": "chapters/enclave-advanced.html",
    "href": "chapters/enclave-advanced.html",
    "title": "13  Advanced Enclave Coding Techniques",
    "section": "",
    "text": "Note\n\n\n\nThis chapter is being drafted in Google Docs at https://drive.google.com/drive/u/0/folders/1K660Qn7m1z4TswwepM06CKgAPTojjt7q\nSee a draft of the chapter outline at https://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAt this point, any edits to this chapter should be made in Google Docs. The current Markdown is for testing only. It is NOT the source of truth (yet)."
  },
  {
    "objectID": "chapters/examples.html",
    "href": "chapters/examples.html",
    "title": "14  Start to finish examples or worked examples",
    "section": "",
    "text": "Note\n\n\n\nThis chapter is being drafted in Google Docs at https://drive.google.com/drive/u/0/folders/1rWxFtzk1kyUSRJPDgPWwlmVCjnWEGf6i\nSee a draft of the chapter outline at https://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAt this point, any edits to this chapter should be made in Google Docs. The current Markdown is for testing only. It is NOT the source of truth (yet)."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Anzalone, Alfred Jerrod, Ronald Horswell, Brian M Hendricks, San Chu,\nWilliam B Hillegass, William H Beasley, Jeremy R Harper, et al. 2023.\n“Higher Hospitalization and Mortality Rates Among\nSARS-CoV-2-Infected Persons in Rural America.” The Journal of\nRural Health 39 (1): 39–54.\n\n\nCharlson, Mary E., Peter Pompei, Kathy L. Ales, and C.Ronald MacKenzie.\n1987. “A New Method of Classifying Prognostic Comorbidity in\nLongitudinal Studies: Development and Validation.” Journal of\nChronic Diseases 40 (5): 373–83. https://doi.org/https://doi.org/10.1016/0021-9681(87)90171-8.\n\n\nMehta, Hemalkumar B., Huijun An, Kathleen M. Andersen, Omar Mansour,\nVithal Madhira, Emaan S. Rashidi, Benjamin Bates, et al. 2021.\n“Use of Hydroxychloroquine, Remdesivir, and Dexamethasone Among\nAdults Hospitalized with Covid-19 in the United States: A Retrospective\nCohort Study.” Annals of Internal Medicine 174 (10):\n1395–1403. https://doi.org/10.7326/M21-0857.\n\n\nPalantir. 2023. “Documentation: Code Repositories &Gt;\nOverview.” https://www.palantir.com/docs/foundry/code-repositories/overview/.\n\n\nPfaff, E. R., A. T. Girvin, T. D. Bennett, A. Bhatia, I. M. Brooks, R.\nR. Deer, J. P. Dekermanjian, et al. 2022. “Identifying Who Has\nLong COVID in the USA: A Machine Learning Approach Using N3C\nData.” Lancet Digit Health 4 (7): e532–41. https://doi.org/10.1016/S2589-7500(22)00048-6.\n\n\nPfaff, Emily R, Andrew T Girvin, Davera L Gabriel, Kristin Kostka,\nMichele Morris, Matvey B Palchuk, Harold P Lehmann, et al. 2022.\n“Synergies Between Centralized and Federated Approaches to Data\nQuality: A Report from the National COVID Cohort Collaborative.”\nJournal of the American Medical Informatics Association 29 (4):\n609–18.\n\n\nReese, Justin T, Hannah Blau, Elena Casiraghi, Timothy Bergquist,\nJohanna J Loomba, Tiffany J Callahan, Bryan Laraway, et al. 2023.\n“Generalisable Long COVID Subtypes: Findings from the NIH N3C and\nRECOVER Programmes.” EBioMedicine 87.\n\n\nSciences, Observational Health Data, and Informatics. 2019. The Book\nof OHDSI: Observational Health Data Sciences and Informatics.\nUnited States: Independent. https://ohdsi.github.io/TheBookOfOhdsi/.\n\n\nSharafeldin, Noha, Benjamin Bates, Qianqian Song, Vithal Madhira, Yao\nYan, Sharlene Dong, Eileen Lee, et al. 2021. “Outcomes of COVID-19\nin Patients with Cancer: Report from the National COVID Cohort\nCollaborative (N3C).” Journal of Clinical Oncology 39\n(20): 2232–46. https://doi.org/10.1200/JCO.21.01074.\n\n\nSun, Jing, Qulu Zheng, Vithal Madhira, Amy L. Olex, Alfred J. Anzalone,\nAmanda Vinson, Jasvinder A. Singh, et al. 2022. “Association\nBetween Immune Dysfunction and COVID-19 Breakthrough Infection After\nSARS-CoV-2 Vaccination in the US.” Archives of Internal\nMedicine (Chicago, Ill. : 1908) 182 (2): 153–62. https://doi.org/10.1001/jamainternmed.2021.7024.\n\n\nWilkinson, Mark D, Michel Dumontier, IJsbrand Jan Aalbersberg, Gabrielle\nAppleton, Myles Axton, Arie Baak, Niklas Blomberg, et al. 2016.\n“The FAIR Guiding Principles for Scientific Data Management and\nStewardship.” Scientific Data 3.\n\n\nWu, Chunlei, and C2DH. 2022. “Informatics Playbook.” https://playbook.cd2h.org/.\n\n\nYang, Xueying, Jing Sun, Rena C Patel, Jiajia Zhang, Siyuan Guo, Qulu\nZheng, Amy L Olex, et al. 2021. “Associations Between HIV\nInfection and Clinical Spectrum of COVID-19: A Population Level Analysis\nBased on US National COVID Cohort Collaborative (N3C) Data.”\nThe Lancet HIV 8 (11): e690–700."
  }
]