[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"Book N3C designed guide research National COVID Cohort Collaborative (N3C).","code":""},{"path":"index.html","id":"contributing-content","chapter":"Welcome","heading":"0.1 Contributing Content","text":"N3C domain teams healthiest assimilating contributions reseachers different skills (e.g., clinicians & informaticians), specialties (e.g., endocrinology & gerontology), programming languages (e.g., Python, R, & SQL) experiences (e.g., students & PIs).Accordingly, book--n3c-v1 repository welcomes input .see small mistake unclear language, invite inform us new issue edit source submitting pull request. editor reviews accepts change, website updated within minutes.idea something substantial chapter section, please start new issue N3C Educational Committee coordinate fits best.","code":""},{"path":"index.html","id":"platform","chapter":"Welcome","heading":"0.2 Platform","text":"make small changes like spelling corrections, recommend editing source directly GitHub. handles details without knowledge (like starting fork prompting pull request). appropriate page book, click “Edit page ” button type change GitHub editor.Substantial edits writing better accommodated text editor local machine can preview rendered content type. suggest RStudio Visual Studio Code.don’t understand rest contribute, interested:majority book written collection markdown documents assembled bookdown package. See Yihui’s book authoritative details.majority book written collection markdown documents assembled bookdown package. See Yihui’s book authoritative details.change pushed GitHub, GitHub Action spawns small VM () collects markdown documents, (b) calls bookdown convert html, (c) moves compiled products “gh-pages” branch.change pushed GitHub, GitHub Action spawns small VM () collects markdown documents, (b) calls bookdown convert html, (c) moves compiled products “gh-pages” branch.GitHub Pages serves contents “docs/” directory anyone browser.GitHub Pages serves contents “docs/” directory anyone browser.","code":""},{"path":"index.html","id":"funding","chapter":"Welcome","heading":"0.3 Funding","text":"N3C supported NIH National Center Advancing Translational Sciences (NCATS).","code":""},{"path":"intro.html","id":"intro","chapter":"1 Introduction","heading":"1 Introduction","text":"chapter drafted Google Docs \nhttps://drive.google.com/drive/u/0/folders/16QkU2vonX5iZzjsLCxIEREPEdZ9S6wzaSee draft chapter outline \nhttps://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/Chapter Leads: Karen Crowley, Shawn O’NeilChapter Contributors: ","code":""},{"path":"intro.html","id":"mission","chapter":"1 Introduction","heading":"1.0.1 Mission","text":"National COVID Cohort Collaborative, N3C, open-science community stewarded National Center Data Health (CD2H) NIH National Center Advancing Translational Sciences (NCATS), significant contributions many partners including Clinical Translational Science Awards (CTSA) program, Centers Translational Research (CTRs), thousands researchers hundreds participating institutions US abroad.Faced COVID-19 pandemic, issue addressed N3C clear direct: US centralized data repository health records related information, hindering response scientific community.1 Although healthcare providers mandated law utilize electronic health records (EHR), little guidance coordinates exactly information collect store. Commercial EHR suites (e.g. Epic) widely used, controlled vocabularies (e.g. ICD10 SNOMED) provide standards representing medical information, many standards use EHR software highly configurable needs individual organizations. result, databases EHR information across US largely non-interoperable, presenting challenges researchers hoping use vast national store information practice.","code":""},{"path":"intro.html","id":"common-data-models-and-n3c","chapter":"1 Introduction","heading":"1.0.2 Common Data Models and N3C","text":"recent years, common solution issues creation Common Data Models (CDMs). Common Data Model agreed-upon structure format databases containing clinical information, diverse organizational EHR databases can standardized research purposes. Even , healthcare organizations reluctant share data directly, risks associated data breaches protected health information (PHI) defined HIPAA high. result, several groups healthcare research organizations formed _federated _research networks, organization aA visual representation disparate, non-compatible EHR databases across United States.network translates subset EHR data agreed-upon common data model, affiliated researchers can write queries intended data format. Examples federated networks include PCORNet i2b2, utilize common data model. federated model, data queries generated researchers, executed locally data owners summarized specifically requested results sent back researchers. ensures protection raw data (never leaves boundaries individual organization), prevents exploratory data investigation techniques (like many machine-learning methods) require direct access totality data.Driven imperative addressing COVID-19, concert use FedRAMP-certified cloud-based analysis ecosystem call N3C Data Enclave,2 N3C partnering EHR data providers across nation collect billions EHR data points millions patients without COVID-19 single, secure, accessible database research use. N3C simultaneously moderates controlled access data research teams across country (beyond), including private companies, community colleges, universities, medical schools, government entities.Like federated research networks, N3C also uses common data model, known OMOP, chosen strong community support open nature, support scientific use cases, availability tools translating working data (’ll discuss OMOP data format detail later chapters).3 rapidly collect data around country, N3C leverages existing work data owners already done convert organization-unique data one handful N3C-supported “source” common data models: PCORNet, i2b2, TriNetX, ACT, OMOP. potential data partner data PCORNet format, example, locally run set N3C-generated “PCORNet OMOP” translation scripts prior transferring result N3C via secure channel. process coalescing multiple data payloads unified whole known harmonization, complex task even everything mapped OMOP initially. Two overlapping teams EHR data experts participate process: one works closely data partners make easy possible contribute data N3C, another handles post-ingestion harmonization comprehensive quality checks incoming data.","code":""},{"path":"intro.html","id":"the-n3c-enclave-and-data-access","chapter":"1 Introduction","heading":"1.0.3 The N3C “Enclave” and Data Access","text":"harmonized stored secure Enclave, data made available via web-based interface research teams using common tools SQL, Python, R, well number code-light graphical user interfaces.visual representation N3C’s data harmonization source-CDM model, team-based access data secure cloud-based enclave.Mere access Enclave, however, doesn’t automatically provide access protected data (although make , publicly-available datasets available minimal restriction practice learning purposes). Multiple “levels” data available different anonymization techniques applied, facilitating “just enough” access research teams depending needs ability access protected health information. Accessing secure level, example, requires obtaining approval Institutional Review Board (IRB) validates appropriateness human subjects research, lowest level heavily anonymized accessible private individuals (citizen scientists) certain legal training requirements.effective analysis EHR data requires diverse set skills–especially clinical data science/statistical expertise–N3C provides organizational structures resources rapidly create support multidisciplinary research teams, many geographically diverse well. December 2021, dozens “Domain Teams” support nearly 300 ongoing research projects, contributed 2500 researchers hailing 250+ different institutions organizations. Sixty-nine data partners provide EHR data 10 million patients (⅓ COVID-19), representing 5.5 billion lab results, 1.6 billion medication records, 1 billion clinical observations, 500 million clinical visits. --date information numbers , visit dashboard https://covid.cd2h.org/dashboard.Summary statistics N3C patients Aug, 2022. Confirmed COVID-19 patients known positive PCR Antigen lab test, possible patients likely symptomatology.","code":""},{"path":"intro.html","id":"benefits-of-participation","chapter":"1 Introduction","heading":"1.0.4 Benefits of Participation","text":"researchers, N3C provides unique opportunity participate next-generation, distributed team science. Investigators expertise multiple domains come together across organizational boundaries answer questions critical understanding management COVID-19 impact health individuals communities across United States. Clinical, health informatics, data science, epidemiology, biostatistics, public health experts join forces true team science manner …. form Domain Teams support encourage….researchers:Participate next-generation distributed team scienceParticipate next-generation distributed team scienceBuild connections collaborationsBuild connections collaborationsSupport fellow researchers domain experts (computational, clinical, etc)Support fellow researchers domain experts (computational, clinical, etc)See chapter “Onboarding, Enclave Access, N3C Team Science”See chapter “Onboarding, Enclave Access, N3C Team Science”“N3C Clinical Domain Teams enable researchers shared interests analyze data within N3C Data Enclave efficiently collaborate multi-site research. Clinical Domain Teams, developed within Clinical Scenarios subgroup, focus specific clinical questions surrounding COVID-19’s impact health conditions. Clinical Domain Teams enabled Slack channels discussion, meetings, document management, supported N3C workstreams administration. N3C encourages researchers levels join Domain Team represents interests, suggest new clinical areas explore.”\n“N3C Domain Teams enable researchers shared interests analyze data within N3C Data Enclave collaborate efficiently team science environment. teams provide opportunity collect pilot data grant submissions, train algorithms larger datasets, inform clinical trial design, learn use tools large scale COVID-19 data, validate results. Domain Teams enabled Slack channels discussion, meetings, document management supported N3C workstreams. N3C encourages researchers levels join Domain Team represents interests, suggest new clinical areas explore. Domain Team can submit one research projects, collaboration encouraged similar concepts.”\n“Multi-discipline Clinical Domain Teams focus clinical questions surrounding COVID-19’s impact health conditions consist clinical subject matter experts, statisticians, informaticists, machine learning specialists. Cross-Cutting Domain Teams varied focus applies multiple domains.”\n“N3C Clinical Domain Teams enable researchers shared interests analyze data within N3C Data Enclave efficiently collaborate multi-site research. Clinical Domain Teams, developed within Clinical Scenarios subgroup, focus specific clinical questions surrounding COVID-19’s impact health conditions. Clinical Domain Teams enabled Slack channels discussion, meetings, document management, supported N3C workstreams administration. N3C encourages researchers levels join Domain Team represents interests, suggest new clinical areas explore.”“N3C Domain Teams enable researchers shared interests analyze data within N3C Data Enclave collaborate efficiently team science environment. teams provide opportunity collect pilot data grant submissions, train algorithms larger datasets, inform clinical trial design, learn use tools large scale COVID-19 data, validate results. Domain Teams enabled Slack channels discussion, meetings, document management supported N3C workstreams. N3C encourages researchers levels join Domain Team represents interests, suggest new clinical areas explore. Domain Team can submit one research projects, collaboration encouraged similar concepts.”“Multi-discipline Clinical Domain Teams focus clinical questions surrounding COVID-19’s impact health conditions consist clinical subject matter experts, statisticians, informaticists, machine learning specialists. Cross-Cutting Domain Teams varied focus applies multiple domains.”Largest database de-identified EHR data US\n“one largest, secure clinical data resources accelerating collaborating COVID-19 research” N3C website\nLargest database de-identified EHR data US“one largest, secure clinical data resources accelerating collaborating COVID-19 research” N3C websiteBig-data capabilities powerful tools (R, python, packages, sql)Big-data capabilities powerful tools (R, python, packages, sql)Accessible - compute infrastructure needed browserAccessible - compute infrastructure needed browserLearn gain experience working clinical data common data modelLearn gain experience working clinical data common data modelWork EHR data checked quality, completeness, consistencyWork EHR data checked quality, completeness, consistencyFor institutions w/ researchers (sign DUA):Increase research productivity profileEncourage cross-institutional/geographically-diverse connectionsProvide clinical translational research opportunities faculty studentsEnable real-world learning opportunities studentsFor data partners (contribute data):Raise institutional research profileGet feedback local data quality completeness comparison peers\nCompare local research results results data partners across US assess generalizability\nCompare local research results results data partners across US assess generalizabilityPlace data secure enclave supports broad access reproducibilityGrow userbase researchers utilizing data, including institutionNews articles N3CVOX oneMIT press articleExemplars great projectsQuery community see wants featured :)Projects news (press/news articles) /published, potentially highly citedStudent papers/projectsMaybe restrict peer-reviewed publication?BARDA challenge","code":""},{"path":"story.html","id":"story","chapter":"2 A Research Story","heading":"2 A Research Story","text":"50,000-foot view research project, onboarding publishingNow introduced N3C described motivation importance, ’ll walk lifecycle example project onboarding publishing. path typically takes least 6 months 6 collaborators. difficult , fortunately N3C attracted large diverse set researchers. Coupled large diverse set patients, possible complete research project within year.starting project , ’ll likely able recruit collaborators complementary set skills (addition resources instructional material office hours). like join existing project, domain teams ongoing projects likely fit interests benefit abilities.","code":""},{"path":"story.html","id":"story-person","chapter":"2 A Research Story","heading":"2.1 Onboarding","text":"first data point viewed, three things established institution:{person’s paperwork. Include ORCiD}{DUA coverage & institution’s paperwork.}{DUR & project’s paperwork.}startup costs expensive N3C investigation compared , incremental costs cheaper. Even strong institutional support, DUA take several months legal administrative channels. Yet clearing first (tall) hurdle site, specific project takes days processed N3C staff. ’s remarkably short time scale available data. ’s likely quicker initiating project based single EMR site –much less EMRs 70+ sites.","code":""},{"path":"story.html","id":"team-building-collaborating","chapter":"2 A Research Story","heading":"2.2 Team building & collaborating","text":"next step build team leverage retrospective medical records. Like contemporary research teams, heterogenous skills important. Ideally team least:navigator learned administrative IRB requirements able facilitate investigation,data engineer understands challenges EMRs able extract transform information,statistician understands limitations observational collection able model retrospective data,subject matter expert clinical experience disease interest able inform decisions EMR variables, anda principal investigator knows literature able form testable hypotheses write manuscript.N3C teams differences conventional research teams single sites. trends noticed :N3C teams researchers least three institutions. experience authors editors, encourages diverse opinions willingness express constructive criticism. Researchers single institution/lab sometimes reluctant generate contrary views.N3C teams researchers least three institutions. experience authors editors, encourages diverse opinions willingness express constructive criticism. Researchers single institution/lab sometimes reluctant generate contrary views.role navigator even important. local EMR investigations likely guided someone years experience institutional safeguards personnel can help something stalls. N3C bigger younger site’s EMR research team, N3C project benefit guided bright, patient, persistent navigator.role navigator even important. local EMR investigations likely guided someone years experience institutional safeguards personnel can help something stalls. N3C bigger younger site’s EMR research team, N3C project benefit guided bright, patient, persistent navigator.team needs someone, consider asking relevant domain team helping identifying approaching potential collaborator.","code":""},{"path":"story.html","id":"common-discussion-at-the-teams-first-meeting","chapter":"2 A Research Story","heading":"2.3 Common Discussion at the Team’s First Meeting","text":"team assembled, first discussion usually variation exchange:Investigator: Welcome everyone. ’d like know Drug Drug B associated better outcomes.Statistician: problem. can longitudinally model type amount medication received patient, relative intake date.Data Engineer: Hmmm. ’m happy produce dataset dose frequency columns4, may find useful. two columns sparsely populated look inconsistent across sites.5I: Bummer. ’s realistic feasible?Subject Matter Expert: Maybe simplifies picture… clinical experience, patient rarely switches Drugs & B. Based initial presentation, provider pick B, complete regimen unless ’s adverse event.S: case, initial model three levels treatment: , B, +B?: Probably. N3C database, can someone tell many patients get visit?DE: ’m already logged Enclave6. Give 2 minutes whip something SQL.7I: Oh goodness, cat? cutie! 8DE minutes: Ok, got . [Unmutes .] Ok, got . 40% patients Drug , 52% Drug B , 8% least one administration Drug & B visit.SME: Weird. 8% lot expected. thinking around 1%.DE: Hmm, let check. Give another minute.9DE minutes: see mean. looks like bulk combo patients admitted spring 2020. Jan 2021, 3% patients Drug & B.S: already planning model phase pandemic. ’ll test ’s significant interaction time treatment.: like starting point. Regarding question dose frequency…\nnow let’s assume providers following current dosing guidelines. Therefore dose frequency variables can dropped analyses.S: Phew. didn’t want admit . skimmed dosing guidelines emailed yesterday. looked complicated. wasn’t sure appropriately incorporate variables model.: Well, ’s everything wanted cover today. See two weeks. Wait. can’t believe forgot. Sorry -Navigator sick week ’m almost worthless absence. everyone still call? secondary hypothesis, want everything connect patient’s diagnoses. …, , covid hospitalization.DE: Bad news. kinda like dose frequency situation minutes ago. structure OMOP diagnosis table theoretically can connect patient’s diagnoses across different locations. quality historical records really depends site. places like Delaware leverage state’s HIE10 populate N3C dataset. However places well connected. patient doesn’t diagnosis records, ’s tough determine healthy, primary care provider uses siloed EMR.11I: Ugh. Good point.DE: ’ve got good news. N3C contributors comprehensively capture conditions diagnosed visit. Furthermore diagnosis codes standardized really well across sites. ’s providers enter ICD codes EMR, eventually can cleanly mapped OMOP’s standard concepts.12I: Well, ’s fine paper. Maybe next manuscript follow N3C’s death records.13SME: Sorry everybody, clinic week, ’re calling . need drop.14S: Can go back ask question medications? see Drug 15 different brand names. don’t recognize half . classify ?DE: ’s actually worse . Sorry ’m downer today. Can see screen? Drug 15 brand names 200 different RxNorm codes; package uniquely identified NIH’s NLM. SME started concept set Thursday. ’re operationalizing drug classes RxNorm ingredient. five ingredients conceptualized Drug . friend showed used OMOP tables different project.15 ’ll roll meds patient-level dataset. one integer number medication records tied Drug ingredient another integer Drug B records. ’ll probably want transform two counts two booleans.S: change mind decide use counts, least ’ll know.Shoreleave: knowing half battle.","code":""},{"path":"story.html","id":"protocol-variables-definitions","chapter":"2 A Research Story","heading":"2.4 Protocol, variables, & definitions","text":"aspect scientific process probably familiar vague. researchers several years graduate-level courses real-world experience.Tradeoffs inevitable selecting variables. Rarely investigator’s first choice available.Tradeoffs inevitable selecting variables. Rarely investigator’s first choice available.Retrospective medical records extracted larger dataset. investigation can use fraction terabytes EMR. Many decisions involve include relevant variables among qualifying patients.Retrospective medical records extracted larger dataset. investigation can use fraction terabytes EMR. Many decisions involve include relevant variables among qualifying patients.{Mention CD2H’s Informatics Playbook}","code":""},{"path":"story.html","id":"creating-an-analysis-ready-dataset","chapter":"2 A Research Story","heading":"2.5 Creating an analysis-ready dataset","text":"{Conventional data engineer role. Dataset created input analyst.}","code":""},{"path":"story.html","id":"learning-and-using-omop-e.g.-concept-sets","chapter":"2 A Research Story","heading":"2.6 Learning and using OMOP (e.g. concept sets)","text":"OMOP originated around 20qq facilitate detection small significant side effects new pharmaceuticals. Detecting small signal requires large datasets –larger single health care database.16 Since , foundation supported many research goals. well-suited N3C :evolved 10? years accommodates wide range data sourcesIt established community documentation help institutions convert EMR OMOP help researchers analyze hypotheses.{3-4 sentence description original OMOP motivation. standardizes () tables & columns (b) vocabulary. Spend 1-2 paragraphs concept set, focusing motivations mechanics.}","code":""},{"path":"story.html","id":"analyses","chapter":"2 A Research Story","heading":"2.7 Analyses","text":"Developing Analysesfinalizing analysis\nPinning release\nDRR\nfigures\nPinning releaseDRRfigures","code":""},{"path":"story.html","id":"draft-paper-pub-committee","chapter":"2 A Research Story","heading":"2.8 Draft paper, pub committee","text":"","code":""},{"path":"lifecycle.html","id":"lifecycle","chapter":"3 Data Lifecycle - From Patients to N3C Researchers","heading":"3 Data Lifecycle - From Patients to N3C Researchers","text":"chapter drafted Google Docs \nhttps://drive.google.com/drive/u/0/folders/1ZjnFezddZk0YllqIDZN1mgexn1yM51tHSee draft chapter outline \nhttps://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/","code":""},{"path":"governance.html","id":"governance","chapter":"4 Governance, Leadership, and Operations Structures","heading":"4 Governance, Leadership, and Operations Structures","text":"chapter drafted Google Docs \nhttps://drive.google.com/drive/u/0/folders/19lryu26FaMAVrDHHARYcFJFpb18vOxcTSee draft chapter outline \nhttps://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/","code":""},{"path":"onboarding.html","id":"onboarding","chapter":"5 Onboarding, Enclave Access, N3C Team Science","heading":"5 Onboarding, Enclave Access, N3C Team Science","text":"chapter drafted Google Docs \nhttps://drive.google.com/drive/u/0/folders/1zOGR2rGGgr1lxP8mV5XmtkuxEZI_R7IISee draft chapter outline \nhttps://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/Chapter Leads: Sharon Patrick, Jonathan Emery, Suzanne McCahan, Mary Helen MaysChapter Contributors:N3C extensive secure onboarding process due sensitivity data within enclave. several steps need completed order researcher N3C user gain access enclave.","code":""},{"path":"onboarding.html","id":"researcher-eligibility","chapter":"5 Onboarding, Enclave Access, N3C Team Science","heading":"5.1 Researcher Eligibility","text":"Citizen scientists, researchers foreign institutions researchers U.S.-based institutions eligible access N3C Data Enclave. Everyone N3C Data Enclave account access tools public datasets available Enclave.several levels Electronic Health Record (EHR) data available within N3C Data Enclave. (information levels data, see section ‘Description Levels 1, 2, 3’ ‘Getting & Managing Data Access’ chapter. LINK NEEDS ADDED )Citizen scientists eligible access synthetic data (Level 1). data artificial statistically-comparable , computationally derived , original EHR data.Researchers foreign institutions eligible access synthetic data (Level 1) patient data deidentified removal protected health information (PHI) (Level 2). (PHI includes 18 elements defined Health Insurance Portability Accountability Act (HIPAA).)Researchers U.S.-based institutions eligible access synthetic data (Level 1), deidentified patient data (Level 2) patient data includes dates service patient zip code (Level 3). (latter data set referred limited dataset contains 2 18 PHI elements.)","code":""},{"path":"onboarding.html","id":"registration","chapter":"5 Onboarding, Enclave Access, N3C Team Science","heading":"5.2 Registration","text":"","code":""},{"path":"onboarding.html","id":"orcid-incommon-vs-login.gov","chapter":"5 Onboarding, Enclave Access, N3C Team Science","heading":"5.2.1 ORCiD; InCommon vs Login.gov","text":"","code":""},{"path":"onboarding.html","id":"nih-it-security-training","chapter":"5 Onboarding, Enclave Access, N3C Team Science","heading":"5.2.2 NIH IT security training","text":"","code":""},{"path":"onboarding.html","id":"human-subjects-training","chapter":"5 Onboarding, Enclave Access, N3C Team Science","heading":"5.2.3 Human Subjects Training","text":"Due secure nature data available N3C Enclave registration users key. two options users can log create account, InCOmmon Login.gov. InCommon pathway available select institutions participate identity management service. can clock link confirm organization participates. institution participate InCOmmon, need create login.gov account. Use link Login.gov complete required fields create account. know pathway use create enclave account security measures put place, need ORCiD, complete NIH security Trainingn, also human subjects tratining.ORCiD, stands Open Researcher Contributor ID, unique identifier free charge researchers.N3C Data enclave hosted National Center Advancing Translational Sciences researchers must complete “Informational Securty, Counterintelligence, Privacy Awareness, Records Management Refresher, Emergency Prepardeness Refresher” course. course can accessed https://irtsectraining.nih.gov/public.aspx. course take approximately 60-90 minutes complete print certificate completion. Users need complete Human Subjects training aligns institution’s guidelines. need provide date completion part enclave creation.Overall, users need confirm use InCOmmon Login.gov pathway, register ORCiD, completed NIH Security Training, completed institution human subjects training.","code":""},{"path":"onboarding.html","id":"data-use-agreements","chapter":"5 Onboarding, Enclave Access, N3C Team Science","heading":"5.3 Data Use Agreements","text":"data use agreement (DUA) establishes permitted uses data N3C Data Enclave. signing agreement, institutional official assuring users institution abide terms defined agreement.DUA must executed National Center Advancing Translational Science (NCATS) research institution. DUA must signed authorized institutional officials authority bind users institution terms DUA. (citizen scientist affiliated institution must execute data use agreement NCATS.) DUA effect five years DUA Effective Date.Every individual access N3C Data Enclave must covered DUA. DUA must place account N3C Enclave requested. institution active DUA, additional action required regards DUA. list institutions DUAs place can found List DUA Signatories: (https://covid.cd2h.org/duas).Institutional Data Use Agreement form available :https://ncats.nih.gov/files/NCATS_N3C_Data_Use_Agreement.pdfFor information see:https://ncats.nih.gov/n3c/resources/data-access","code":""},{"path":"onboarding.html","id":"enclave-access","chapter":"5 Onboarding, Enclave Access, N3C Team Science","heading":"5.4 Enclave Access","text":"","code":""},{"path":"onboarding.html","id":"research-project-teams","chapter":"5 Onboarding, Enclave Access, N3C Team Science","heading":"5.5 Research Project Teams","text":"","code":""},{"path":"onboarding.html","id":"project-lead-vs-collaborations","chapter":"5 Onboarding, Enclave Access, N3C Team Science","heading":"5.5.1 Project Lead vs COllaborations","text":"","code":""},{"path":"onboarding.html","id":"common-roles-and-expectations-pis-pms-smes-analysts","chapter":"5 Onboarding, Enclave Access, N3C Team Science","heading":"5.5.2 Common roles and expectations (PIs, PMs, SMEs, Analysts, …)","text":"","code":""},{"path":"onboarding.html","id":"expertise-needed","chapter":"5 Onboarding, Enclave Access, N3C Team Science","heading":"5.5.2.1 Expertise needed","text":"","code":""},{"path":"onboarding.html","id":"domain-teams","chapter":"5 Onboarding, Enclave Access, N3C Team Science","heading":"5.6 Domain Teams","text":"N3C Data enclave built multi-site collaboration, aims bring together researchers different backgrounds similar questions using domain teams. N3C multi-site, can difficult collaborate researchers different backgrounds different sites. Domain Teams exist alleviate difficulty. collaboration examples collecting pilot data grant submission, sharing methodology cohort logic, learning use tools large-scale data like machine learning.example, let’s say institution just signed DUA questions relationship rurality COVID treatments. can look list domain teams see rural health. can get contact go next upcoming meeting. meeting can find whether questions already part existing project within domain team, new project created.don’t see type questions belonging existing domain teams can create new one :https://n3c-help.atlassian.net/servicedesk/customer/portal/2/group/3/create/58See list existing domain teams:https://covid.cd2h.org/domain-teams","code":""},{"path":"onboarding.html","id":"browsing-researchersprojectsinstitutions","chapter":"5 Onboarding, Enclave Access, N3C Team Science","heading":"5.7 Browsing Researchers/Projects/Institutions","text":"","code":""},{"path":"onboarding.html","id":"object-explorer-public-dashboard","chapter":"5 Onboarding, Enclave Access, N3C Team Science","heading":"5.7.1 Object Explorer, Public Dashboard","text":"enclave account can log use object explorer browse researchers research projects. object explorer can found left hand side view enclave homepage. Click Object Explorer several object-type groups, search researchers projects, click N3C Admin, can search Data Use Requests, N3C Researchers, Research Projects. looking particular N3C researcher, can click box search bar type name hit enter. new box displayed can clock researcher’s name can see research projects lead collabotaro . can go back Object Explorer, object type groups, click N3C Admin , search research projects clicking box. Using search bar top page can search key word. Type key word click enter results box displayed. can view results find project interested joining. screen, can select title project interested joining reading . public-facing version searching projects addition using enclave search method. Users can search https://covid.cd2h.org/projects https://covid.cd2h.org/dashboard/exploration#projects search title, lead investigator name also institution. many features available search using public-facing dashboard. four categories .","code":""},{"path":"data-access.html","id":"data-access","chapter":"6 Getting & Managing Data Access","heading":"6 Getting & Managing Data Access","text":"chapter drafted Google Docs \nhttps://drive.google.com/drive/u/0/folders/1rrYYjSm5cWni1wyvs__-ByPl9Q6uRy10See draft chapter outline \nhttps://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/","code":""},{"path":"data-understanding.html","id":"data-understanding","chapter":"7 Understanding the Data","heading":"7 Understanding the Data","text":"chapter drafted Google Docs \nhttps://drive.google.com/drive/u/0/folders/1OHv1P2DKGucKBpSNEiQp8lGfR2xYHPAWSee draft chapter outline \nhttps://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/","code":""},{"path":"data-analysis.html","id":"data-analysis","chapter":"8 Analyzing the Data","heading":"8 Analyzing the Data","text":"chapter drafted Google Docs \nhttps://drive.google.com/drive/u/0/folders/1RefwFn6mIitASq9IfPccN-T33iMohUEbSee draft chapter outline \nhttps://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/Chapter Leads: Amy Olex, Andrea ZhouChapter Contributors: Johanna Loomba, Evan French, etc…","code":""},{"path":"data-analysis.html","id":"identifying-concept-sets","chapter":"8 Analyzing the Data","heading":"8.1 Identifying Concept Sets","text":"data ingested ever-growing list data partners, electronic health information coded various vocabularies used across country mapped single vocabulary SNOMED CT. core terminology OMOP common data model used within enclave designated standard used represent clinical meanings hierarchical structure. leveraging hierarchical structure, parent codes descendants can captured ease create intentional concept sets use analysis. details around process concept set creation, read [authoring concept sets]#Authoring-Concept-Sets section.Concept Set Browser N3C specific tool allows researchers explore modify existing concept sets well create new concept sets fit exact study needs. New researchers can start search concept set list N3C Recommended concept sets. concept sets frozen validated state Logic Liaisons Data Liaisons obtaining clinician informatic reviews. concept sets ones used identify common comorbidities facts Phenotype Explorer Logic Liaison Fact Table templates. method finding commonly used concept sets exploring bundles within Concept Set Browser. sets concept sets often used together group. created *** used ***.","code":""},{"path":"data-analysis.html","id":"using-concept-sets","chapter":"8 Analyzing the Data","heading":"8.2 Using Concept Sets","text":"concept sets identified use analysis concept set browser, concept set members table becomes link concepts encompassing concept set. Researchers can use concept sets referencing concept set name concept set version id also known codeset id. searching concept set name, recommended also use most_recent_version = true obtain date list concept ids point analysis. method highly favored concept set marked N3C Recommended since concept sets can updated small number approved users gone re-validation, necessary, following updates vocabulary changes. Researchers may choose look concept sets concept set members table codeset id wish use current recent version concept set N3C Recommended user can make edits concept sets. allow researchers perform analysis start finish without worry someone modified concept set midstream without knowledge. instance researcher may choose reference concept set codeset id choosing use specific prior version existing concept set.","code":""},{"path":"data-analysis.html","id":"using-the-knowledge-store","chapter":"8 Analyzing the Data","heading":"8.3 Using the Knowledge Store","text":"N3C Knowledge Store application Enclave users can discover shared Code Templates, External Datasets, Reports, Cohorts, Python Libraries (also known Knowledge Objects) share similarly re-usable Knowledge Objects Enclave users, regardless specific DUR resource originated. Majority Knowledge Store objects come core contributors researchers alike develop resources believe may useful others either within outside research project team wish share broader community. find situation, can easily create KS resource can shared using Palantir’s documentation around templatization submitting Knowledge Store. Otherwise, specifics navigate Knowledge Store can found [guide]#Knowledge-Store-Guide within Enclave. many types Knowledge Objects, common code templates datasets.Datasets Knowledge Store can internal external datasets. Internal datasets generated data inside enclave, typically researchers part project, often patient level granularity. External datasets found Knowledge Store provide wealth information public datasets brought Enclave along crosswalks necessary joining aggregate data person level data various levels granularity. Either type dataset can imported workbook code repository used starting point transformation analysis.Depending author’s intended use, code templates can applied researcher’s custom input dataset code templates produce dataset can joined researcher’s study cohort. code templates can also imported customized produce dataset study analysis simply used example logic Enclave users newer coding. helpful starter templates produced [Logic Liaisons]#N3C-Logic-Liaisons. surveying Domain Team Leads establish list commonly derived variables continuous feedback N3C Community refine update list, Logic Liaisons developed, disseminated, continue maintain two master fact templates. two master fact templates produce visit-level person-level data frames commonly used derived variables [N3C patients]#-Patients-Template well subset index date acute COVID-19 infection, [confirmed COVID-19 Positive patients]#Confirmed-Covid-Pts-Template (PCR/AG positive U07.1 COVID-19 diagnosed).Logic Liaisons also developed, disseminated, continue maintain handful sister fact templates data quality templates Knowledge Store. sister templates utilize visit-level person-level datasets master fact template efficiently generate additional derived variables based broadly requested applicable logic study-specific fact indexing, co-occurrence, CCI score calculations. data quality templates provide variety visualizations looking [data density OMOP domain tables]#Data-Density. looking assess study specific variables, [Systematic Missingness template]#Systematic-Missingness provides nothing fact density indicator [Fact Density Site template]#Fact-Density provides relative densities fact across sites. [Training materials]#Logic-Liaison-Tutorials getting started Logic Liaison templates available within Enclave.necessary utilize Knowledge Store resources conducting research project, allow get jumpstart gathering understanding data avoiding effort duplication providing general starting point. Logic Liaison fact templates specifically designed provide validated community agreed-upon method calculating particular facts encounter level /patient level. Logic Liaison data quality templates provide structure analyzing data missingness, density, contribution quality site.","code":""},{"path":"data-analysis.html","id":"enclave-applications","chapter":"8 Analyzing the Data","heading":"8.4 Enclave Applications","text":"section cover usage various applications made available N3C Enclave, including Contour, Code Workbooks, Reports, (complete list Foundry applications can found ). However, designing running analysis utilizing data Enclave, helps understand concept “data transformation” data stored accessed via SPARK distributed file system.","code":""},{"path":"data-analysis.html","id":"foot-view-of-distributed-file-systems-spark-and-data-transformations","chapter":"8 Analyzing the Data","heading":"8.4.1 10,000 foot view of distributed file systems, SPARK, and data transformations","text":"Data N3C Enclave large stored one giant table. Instead stored multiple servers called “distributed file system” sets rows table may stored across multiple physical servers (Figure 1). Accessing multiple servers get data one table requires lot coordination behind scenes. SPARK program coordinating fetching, writing, analysis data. , Enclave user, can interface SPARK familiar Python, R, SQL commands order retrieve data run analysis. don’t necessarily need know details SPARK operates run basic code; however, working data N3C Enclave highly recommended get acquainted SPARK operates order optimize code make run faster (like WAY faster). can reference Chapter X book, Palatir’s SPARK Fundamentals SPARK Optimization modules details SPARK optimize code. rest chapter just going focus SPARK uses “data transformations’’.basics data transformation illustrated Figure 2A. One tables specified input transformed single output table. Multiple transformations can strung together (Figure 2B) create analysis pipeline (see Palatir’s Anatomy Data Pipeline module detailed information, well Best Practices Chapter X). primary required output always single table; however, visualizations graphs charts can also generated saved along way. , user, define transformations using Enclave applications like Contour Code Workbooks. Fusion sheets can utilized manually create tables input analysis (e.g. hold configuration options frequently used codesets), Reports used compile display analysis results summary tables, graphs, charts. following sections, applications discussed detail.","code":""},{"path":"data-analysis.html","id":"contour","chapter":"8 Analyzing the Data","heading":"8.4.2 Contour","text":"Foundry’s Contour application programming-free interface N3C Enclave allows limited knowledge Python, R, SQL create top-analysis pipelines point--click fashion, well interactive dashboards sharing results. best used quickly summarize visualize data, usage Contour’s expression language allows complex querying data aggregation. One advantages Contour ability quickly easily create summary figures various complexity source tables without code. Contour variety figure options, including bar charts, histograms heatmaps. detailed orientation Contour can found Foundry Documentation .","code":""},{"path":"data-analysis.html","id":"fusion","chapter":"8 Analyzing the Data","heading":"8.4.3 Fusion","text":"Palantir Documentation: Fusion Sheet OverviewUseful writing back datasets use within EnclaveLeverage cell references spreadsheet functionsIndex datasetsSync tables dataset use Foundry applicationsImport xls dataCreate chartsAllows customization flexibilityFusion spreadsheet application within Enclave analogous Excel Google Sheets. Palantir curated extensive documentation describing core functionality well providing select -tutorials. primary utility Fusion allow users sync specific cell ranges values within spreadsheet datasets, can subsequently [imported]#Importing--Viewing-Data Enclave application. tool excellent option use cases require manual data entry, curating lists [concept sets]#Concept-Set-Section configure [Logic Liaison Fact Templates]#LL-Fact-Templates. Unlike many Enclave applications, Fusion suitable large datasets; maximum size restriction 50 MB per document. Similar Google Sheets, Fusion allows users simultaneously edit document view users’ changes real time.Excel super user knows, spreadsheet merely mechanism storing data, also powerful tool analyzing, visualizing, applying complex logical operations data right. Fusion provides many features familiar spreadsheet applications cell-referencing formulas, formatting, charting library name . External .xls/.xlsx formatted files (4 MB) can directly imported Enclave Fusion sheets cell references, formulas, formatting preserved. [caveat].addition standard spreadsheet functionality, Fusion additional features allow bi-directionally integrate rest Enclave environment. first feature ability import Enclave datasets Fusion. Prior using dataset Fusion (including datasets synced Fusion sheets), must first indexed non-distributed format using _Data _tab top menu. can view available indexed datasets using Data>Datasets available menu option. Objects created within Fusion, formatted tables can embedded reports#Reports. Finally, Fusion sheets can templatized facilitate replication similar functionality.","code":""},{"path":"data-analysis.html","id":"code-workbooks","chapter":"8 Analyzing the Data","heading":"8.4.4 Code Workbooks","text":"Tutorial: Intro Code WorkbookPalantir Documentation: Code Workbook Overviewgraphical organization logicSimplification codeeasy reuse pre-authored logicAdd visualizations reportsSupports Python, R, SQLBranching facilitates collaborationWorkspace reuse templatized logicCode Workbook GUI-based application users apply code-based transformations datasets purpose creating new datasets visualizations. explicit goals application facilitate collaborative environment users can quickly iterate logic produce artifacts interoperable suite Enclave applications. default Code Workbook interface structured directed graph nodes represent either datasets transformations can output datasets. Edges represent flow data graph upstream datasets inputs logical operations performed downstream code transforms (see Figure). dataset user access within workspace Code Workbook located can imported input various types transform.","code":""},{"path":"data-analysis.html","id":"types-of-transform","chapter":"8 Analyzing the Data","heading":"8.4.4.1 Types of Transform","text":"Manual Entry transforms allow users manually curate non-persisted datasets directly Code Workbook “quick dirty” alternative manually curating persisted datasets Fusion#Fusion.Python Code transforms let users write Python function input datasets input parameters.R Code transforms let users write R function input datasets input parameters.SQL Code transforms let users write SparkSQL query create new dataset available inputsTemplate transforms parameterized blocks reusable code users can configure point--click interface. Many code templates available [Knowledge Store]#Knowledge-Store, users can also create templates scoped DUR workspace. Multiple single-node templates can combined create multi-node template allow reuse entire configurable pipelines.Visualize transforms offer point--click interface users create charts, distributions, histograms, pivot tables. Note transform available saved datasets.Python R transforms can optionally return single dataset produce visualizations using Python libraries/R packages. visualization produced Code Workbook subsequently embedded Reports#Reports document. Datasets returned transform ephemeral default, , transform must recomputed time dataset used downstream input, options exist conserve compute power either caching saving output. Caching stores output temporarily, saving dataset stores permanently Enclave. recommended transforms pipeline requiring significant compute saved datasets reduce iteration time development. dataset saved, users can set triggers schedules automatically updated certain input datasets updated regular temporal intervals.Tooling available within Code Workbooks facilitate application objective quick iteration. console feature, located top right, allows users interactively explore logic syntax Python, R, SQL outside transform node. Also top right, Global Code section users can globally import Python libraries R packages define custom functions used transform Code Workbook. Code transforms include Logs feature users view console output generated code view detailed stack traces transforms fail due error.Many Python R transforms rely external libraries packages can made available via Environment Configuration. Enclave provides number default configurations tailored common use cases, instance, default profile, includes common packages like pandas tidyverse suitable routine analysis, whereas profile-high-memory profile includes packages like founder_ml facilitate machine learning. Users can create Environment Configurations include packages meeting specific needs. libraries packages included list options, users can [submit ticket]#Tickets request additional packages made available. Enclave maintains instances non-custom configurations warm standby, allowing quickly initialized user requests new environment. Custom configurations require time initialization instances must started scratch rather merely assigned. reason, recommended use non-custom configurations possible.Following best practices collaborative software development, Code Workbook allows branching logic within workbook. popular source control technologies (.e. git), branching allows users make copies workbook can develop independently source workbook. development particular branch deemed complete, can merged back originating branch. Prior merge, users can preview line-level differences within node, well node-level differences nodes added/removed. Good practice dictates individual users perform development individual branches, merged back common master branch. master branch can change interval user cutting branch merging back , previewing merge changes important step ensuring individual’s changes correct compatible current state master branch. Another prime use case code branching ensure reproducibility given dataset used research project. OMOP N3C-curated datasets also versioned, teams can create code branch input datasets set version release effectively freeze dataset used specific analysis later reproducibility still allowing possibility adding additional features. User generated datasets set branch Code Workbook created.Palantir created extensive documentation Code Workbook application including tutorials. N3C also published training materials.","code":""},{"path":"data-analysis.html","id":"reports","chapter":"8 Analyzing the Data","heading":"8.4.5 Reports","text":"Palantir Documentation: Reports Overviewdisplay charts visualizations combination text descriptions analysisCollaborate others comments reportsAdd context attaching images filesCreate story around analysis resultsUseful sharing results even just putting together preliminary look progressMany research projects Enclave complex, involving multiple summary datasets, statistical analyses, visualizations scattered across multiple applications documents. Reports tool consolidating various research artifacts multiple sources within Enclave single coherent document. Formatted Fusion#Fusion tables, Contour#Contour charts, Python/R-generated images Code Workbooks#Code-Workbooks, embeddable Reports document, option add title /caption embedded artifact. Users can also create sections provide narrative structure documents using MarkDown blocks. components Reports document can arranged configured using point--click interface.embedded objects can configured refresh automatically underlying data sources update, allowing Reports function effectively dashboards. Reports also useful presenting executive summary results internal stakeholders well external presentations. [Logic Liaison Templates]#LL-Templates [Knowledge Store]#Knowledge-Store generally includes README created using Reports. Reports can requested download using Download Request Form. Palantir curated documentation creating editing Reports.","code":""},{"path":"data-analysis.html","id":"object-explorer","chapter":"8 Analyzing the Data","heading":"8.4.6 Object Explorer","text":"Palantir Documentation: Object ExplorerTutorial: Exploring N3C Projects Collaborators Object ExplorerEasily find objects interestCompare contrast itemsA step upstream Knowledge Store Palantir’s Object Explorer allows users explore analyze objects interest point click interface. Detailed information around use feature can found [Palantir’s documentation ]#Object-Explorer. Researchers can find unpublished Knowledge Objects, [explore N3C Projects Collaborators]#Object-Explorer-Tutorial, view object usage statistics, etc. using application.","code":""},{"path":"data-analysis.html","id":"data-lineage-aka-monocle","chapter":"8 Analyzing the Data","heading":"8.4.7 Data Lineage (aka Monocle)","text":"Whether ’re creating pipeline data analysis specific research project investigating one came across Knowledge Store determine useful study, ’ll likely want capability holistically assess dataset came . Data Lineage tool within Foundry platform allows users just - easily explore data pipelines start finish. upstream left downstream right, tool makes intuitive way visualize relationships datasets ancestors descendants enhanced views made possible color-coding grouping based dataset’s details. application particularly useful researcher needs schedule build dataset update weekly refresh data enclave. Palantir Documentation provides short tutorial additional descriptions tool’s functionality.","code":""},{"path":"data-analysis.html","id":"code-repositories","chapter":"8 Analyzing the Data","heading":"8.4.8 Code Repositories","text":"","code":""},{"path":"data-analysis.html","id":"protocol-pad","chapter":"8 Analyzing the Data","heading":"8.4.9 Protocol Pad","text":"Quick GuideDetailed GuideResearch studies can span many months pass hands many team members reaching stage researcher may want share results publication approved means. Protocol Pad serves electronic lab notebook help organize tasks, track progress, document results cohesive format throughout process reaching study’s final state.","code":""},{"path":"data-analysis.html","id":"draft-language","chapter":"8 Analyzing the Data","heading":"8.5 DRAFT Language","text":"demonstrate use Contour work simple use-case using SynPuf Synthetic dataset summarize patient demographics bar chart, filter table, join additional information another table, calculate patient’s age.","code":""},{"path":"data-analysis.html","id":"interface-overview","chapter":"8 Analyzing the Data","heading":"8.5.0.1 Interface Overview","text":"get started, let’s get oriented interface Contour application. create new Contour analysis click “+ New” button (Figure <new_button>) select “Analysis” option (Figure <analysis_option>). new Contour analysis open, see window similar Figure <contour_interface>. change name analysis, click last entry path (Figure <contour_interface>, ). path can also used navigate back previous parent directories Enclave. right analysis name drop-indicating “Editing mode” (Figure <contour_interface>, B). Note one person workbook open one person given Editing privileges Viewing Mode.center screen working space. Currently empty added datasets analysis. add new data set analysis, click “+ Create new path” button center screen (Figure <contour_interface>, C), plus “+” button towards top window ((Figure <contour_interface>, D). term “path” Contour used indicate location data set. time “Create Path” telling application data set start , whether source OMOP table output another Contour analysis.","code":""},{"path":"data-analysis.html","id":"importing-and-viewing-data","chapter":"8 Analyzing the Data","heading":"8.5.0.2 Importing and Viewing Data","text":"discussed introduction chapter, analyses work transformations, Contour exception. Analyses Contour built pipeline working top bottom. start analysis need import starting dataset (.e. create new path). Click “+ Create new path” button, navigate OMOP “person” table Synpuf Dataset going “” > “Data Catalog” > SynPuf Synthetic Data” > “person” (Figure <create_path>). window now look similar Figure <analysis_start>.view 3 sections aware :Starting datasetTransformations (currently none)Resulting dataset (can saved table imported another analysis starting path)add transformation (.k.. board), just click one suggestions (Figure <analysis_start>, B), can hover one arrows suggestions select “Insert Board” (Figure <insert_board>). arrows also appear transformation insert transformation anywhere pipeline. Just aware change results downstream!Notice top “+” button (Figure <analysis_Start>, red box) new tab named “person”. can create multiple analysis workflows within Contour analysis navigate using tabs.Now imported first data set, however notice displaying table preview. Within Contour, see data specifically tell create table one transformations. preview data “person” table, click “Visualize” button scroll “Table” (Figure <table_viz>). screen look like Figure <table_preview>.","code":""},{"path":"data-analysis.html","id":"creating-summary-figures","chapter":"8 Analyzing the Data","heading":"8.5.0.3 Creating Summary Figures","text":"One advantageous things Contour easy quickly create summary figures various complexity source tables without code. Contour variety figure options, including bar charts, histograms heatmaps.create bar chart example data, look table preview identify column name variable want plot. instance “race_concept_name”. Create new transformation table preview bar chart (named “Chart” list, Figure <bar_chart_options>). Initially chart empty tell columns use. “Data” tab right, set X-Axis “race_concept_name”, Y-Axis “person_id” “Unique count” (Figure <bar_char_options_set>), click \nCompute & save” view chart (Figure <bar_chart_figure>). can utilize “segment ” option segment primary column secondary column (Figure <bar_chart_segmented>), well explore options available. Note visualization option parameters. can review Foundry’s documentation details .","code":""},{"path":"practices.html","id":"practices","chapter":"9 Best Practices and Important Data Considerations","heading":"9 Best Practices and Important Data Considerations","text":"chapter drafted Google Docs \nhttps://drive.google.com/drive/u/0/folders/1ExkYChsnO3hYZk6HCI5cEfQdQJ9F-ynwSee draft chapter outline \nhttps://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/","code":""},{"path":"publishing.html","id":"publishing","chapter":"10 Publishing and Sharing Your Work","heading":"10 Publishing and Sharing Your Work","text":"chapter drafted Google Docs \nhttps://drive.google.com/drive/u/0/folders/1kmrjxsdrwbspPucPTU3hiOHMXJRQQpPpSee draft chapter outline \nhttps://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/","code":""},{"path":"support.html","id":"support","chapter":"11 Special Topic: Help and Support","heading":"11 Special Topic: Help and Support","text":"chapter drafted Google Docs \nhttps://drive.google.com/drive/u/0/folders/1SnhEKmA-A1GJHN5kBYRnX_za5dX_n1ECSee draft chapter outline \nhttps://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/","code":""},{"path":"machine-learning.html","id":"machine-learning","chapter":"12 Special Topic: Machine Learning","heading":"12 Special Topic: Machine Learning","text":"chapter drafted Google Docs \nhttps://drive.google.com/drive/u/0/folders/1HZ3IGv17zUl9t8RxZSl4uOq_FRzrgTp_See draft chapter outline \nhttps://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/","code":""},{"path":"enclave-advanced.html","id":"enclave-advanced","chapter":"13 Special Topic: Advanced Enclave Coding Techniques","heading":"13 Special Topic: Advanced Enclave Coding Techniques","text":"chapter drafted Google Docs \nhttps://drive.google.com/drive/u/0/folders/1K660Qn7m1z4TswwepM06CKgAPTojjt7qSee draft chapter outline \nhttps://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/","code":""},{"path":"example.html","id":"example","chapter":"14 Special Topic: Start to finish examples or worked examples","heading":"14 Special Topic: Start to finish examples or worked examples","text":"chapter drafted Google Docs \nhttps://drive.google.com/drive/u/0/folders/1rWxFtzk1kyUSRJPDgPWwlmVCjnWEGf6iSee draft chapter outline \nhttps://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/","code":""},{"path":"about.html","id":"about","chapter":"15 About","heading":"15 About","text":"(sample bookdown bs4 chapter helping configure settings. removed real chapters populated.)sample book written Markdown. can use anything Pandoc’s Markdown supports; example, math equation \\(^2 + b^2 = c^2\\).","code":""},{"path":"about.html","id":"usage","chapter":"15 About","heading":"15.1 Usage","text":"bookdown chapter .Rmd file, .Rmd file can contain one (one) chapter. chapter must start first-level heading: # good chapter, can contain one (one) first-level heading.Use second-level higher headings within chapters like: ## short section ### even shorter section.index.Rmd file required, also first book chapter. homepage render book.","code":""},{"path":"about.html","id":"render-book","chapter":"15 About","heading":"15.2 Render book","text":"can render HTML version example book without changing anything:Find Build pane RStudio IDE, andFind Build pane RStudio IDE, andClick Build Book, select output format, select “formats” ’d like use multiple formats book source files.Click Build Book, select output format, select “formats” ’d like use multiple formats book source files.build book R console:render example PDF bookdown::pdf_book, ’ll need install XeLaTeX. recommended install TinyTeX (includes XeLaTeX): https://yihui.org/tinytex/.","code":"\nbookdown::render_book()"},{"path":"about.html","id":"preview-book","chapter":"15 About","heading":"15.3 Preview book","text":"work, may start local server live preview HTML book. preview update edit book save individual .Rmd files. can start server work session using RStudio add-“Preview book”, R console:","code":"\nbookdown::serve_book()"},{"path":"cross.html","id":"cross","chapter":"16 Cross-references","heading":"16 Cross-references","text":"(sample bookdown bs4 chapter helping configure settings. removed real chapters populated.)Cross-references make easier readers find link elements book.","code":""},{"path":"cross.html","id":"chapters-and-sub-chapters","chapter":"16 Cross-references","heading":"16.1 Chapters and sub-chapters","text":"two steps cross-reference heading:Label heading: # Hello world {#nice-label}.\nLeave label like automated heading generated based heading title: example, # Hello world = # Hello world {#hello-world}.\nlabel un-numbered heading, use: # Hello world {-#nice-label} {# Hello world .unnumbered}.\nLeave label like automated heading generated based heading title: example, # Hello world = # Hello world {#hello-world}.label un-numbered heading, use: # Hello world {-#nice-label} {# Hello world .unnumbered}.Next, reference labeled heading anywhere text using \\@ref(nice-label); example, please see Chapter 16.\nprefer text link instead numbered reference use: text want can go .\nprefer text link instead numbered reference use: text want can go .","code":""},{"path":"cross.html","id":"captioned-figures-and-tables","chapter":"16 Cross-references","heading":"16.2 Captioned figures and tables","text":"Figures tables captions can also cross-referenced elsewhere book using \\@ref(fig:chunk-label) \\@ref(tab:chunk-label), respectively.See Figure ??.{r nice-fig, fig.cap='nice figure!', .width='80%', fig.asp=.75, fig.align='center', fig.alt='Plot connected points showing vapor pressure mercury increases exponentially temperature increases.'} par(mar = c(4, 4, .1, .1)) plot(pressure, type = 'b', pch = 19)Don’t miss Table ??.{r nice-tab, tidy=FALSE} knitr::kable(   head(pressure, 10), caption = 'nice table!',   booktabs = TRUE )","code":""},{"path":"parts.html","id":"parts","chapter":"17 Parts","heading":"17 Parts","text":"(sample bookdown bs4 chapter helping configure settings. removed real chapters populated.)can add parts organize one book chapters together. Parts can inserted top .Rmd file, first-level chapter heading file.Add numbered part: # (PART) Act one {-} (followed # chapter)Add unnumbered part: # (PART\\*) Act one {-} (followed # chapter)Add appendix special kind un-numbered part: # (APPENDIX) stuff {-} (followed # chapter). Chapters appendix prepended letters instead numbers.","code":""},{"path":"footnotes-and-citations.html","id":"footnotes-and-citations","chapter":"18 Footnotes and citations","heading":"18 Footnotes and citations","text":"(sample bookdown bs4 chapter helping configure settings. removed real chapters populated.)","code":""},{"path":"footnotes-and-citations.html","id":"footnotes","chapter":"18 Footnotes and citations","heading":"18.1 Footnotes","text":"Footnotes put inside square brackets caret ^[]. Like one 17.","code":""},{"path":"footnotes-and-citations.html","id":"citations","chapter":"18 Footnotes and citations","heading":"18.2 Citations","text":"Reference items bibliography file(s) using @key.example, using bookdown package18 (check last code chunk index.Rmd see citation key added) sample book, built top R Markdown knitr19 (citation added manually external file book.bib).\nNote .bib files need listed index.Rmd YAML bibliography key.bs4_book theme makes footnotes appear inline click . example book, added csl: chicago-fullnote-bibliography.csl index.Rmd YAML, include .csl file. download new style, recommend: https://www.zotero.org/styles/RStudio Visual Markdown Editor can also make easier insert citations: https://rstudio.github.io/visual-markdown-editing/#/citations","code":""},{"path":"blocks.html","id":"blocks","chapter":"19 Blocks","heading":"19 Blocks","text":"(sample bookdown bs4 chapter helping configure settings. removed real chapters populated.)","code":""},{"path":"blocks.html","id":"equations","chapter":"19 Blocks","heading":"19.1 Equations","text":"equation.\\[\\begin{equation}\n  f\\left(k\\right) = \\binom{n}{k} p^k\\left(1-p\\right)^{n-k}\n  \\tag{19.1}\n\\end{equation}\\]may refer using \\@ref(eq:binom), like see Equation (19.1).","code":""},{"path":"blocks.html","id":"theorems-and-proofs","chapter":"19 Blocks","heading":"19.2 Theorems and proofs","text":"Labeled theorems can referenced text using \\@ref(thm:tri), example, check smart theorem 19.1.Theorem 19.1  right triangle, \\(c\\) denotes length hypotenuse\n\\(\\) \\(b\\) denote lengths two sides, \n\\[^2 + b^2 = c^2\\]Read https://bookdown.org/yihui/bookdown/markdown-extensions--bookdown.html.","code":""},{"path":"blocks.html","id":"callout-blocks","chapter":"19 Blocks","heading":"19.3 Callout blocks","text":"bs4_book theme also includes special callout blocks, like .rmdnote.can use markdown inside block.{r collapse=TRUE} head(beaver1, n = 5)python transform:output Logs tab:user define appearance blocks LaTeX output.may also use: .rmdcaution, .rmdimportant, .rmdtip, .rmdwarning block name.R Markdown Cookbook provides help use custom blocks design callouts: https://bookdown.org/yihui/rmarkdown-cookbook/custom-blocks.html","code":"def my_transform(input1, input2):\n    result = input1.head(6)\n    print(\"this is a logged output\")\n\n    return resultthis is a logged output"},{"path":"sharing-your-book.html","id":"sharing-your-book","chapter":"20 Sharing your book","heading":"20 Sharing your book","text":"(sample bookdown bs4 chapter helping configure settings. removed real chapters populated.)","code":""},{"path":"sharing-your-book.html","id":"publishing-1","chapter":"20 Sharing your book","heading":"20.1 Publishing","text":"HTML books can published online, see: https://bookdown.org/yihui/bookdown/publishing.html","code":""},{"path":"sharing-your-book.html","id":"pages","chapter":"20 Sharing your book","heading":"20.2 404 pages","text":"default, users directed 404 page try access webpage found. ’d like customize 404 page instead using default, may add either _404.Rmd _404.md file project root use code /Markdown syntax.","code":""},{"path":"sharing-your-book.html","id":"metadata-for-sharing","chapter":"20 Sharing your book","heading":"20.3 Metadata for sharing","text":"Bookdown HTML books provide HTML metadata social sharing platforms like Twitter, Facebook, LinkedIn, using information provide index.Rmd YAML. setup, set url book path cover-image file. book’s title description also used.bs4_book provides enhanced metadata social sharing, chapter shared unique description, auto-generated based content.Specify book’s source repository GitHub repo _output.yml file, allows users view chapter’s source file suggest edit. Read features output format :https://pkgs.rstudio.com/bookdown/reference/bs4_book.htmlOr use:{r eval=FALSE} ?bookdown::bs4_book","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
