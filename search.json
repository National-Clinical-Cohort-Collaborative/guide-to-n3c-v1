[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Guide to N3C",
    "section": "",
    "text": "The Guide to N3C is designed to guide research with the National COVID Cohort Collaborative (N3C)."
  },
  {
    "objectID": "index.html#contributing-content",
    "href": "index.html#contributing-content",
    "title": "Guide to N3C",
    "section": "Contributing Content",
    "text": "Contributing Content\nThe N3C and its domain teams are healthiest when assimilating contributions from reseachers of different skills (e.g., clinicians & informaticians), specialties (e.g., endocrinology & gerontology), programming languages (e.g., Python, R, & SQL) and experiences (e.g., students & PIs).\nAccordingly, the guide-to-n3c-v1 repository welcomes input from you.\nIf you see a small mistake or unclear language, we invite you to inform us in a new issue or to edit the source and submitting a pull request. When an editor reviews and accepts your change, the website will be updated within minutes.\nIf you have an idea for something more substantial such as a chapter or section, please start a new issue and the N3C Educational Committee will coordinate with you where it fits best."
  },
  {
    "objectID": "index.html#platform",
    "href": "index.html#platform",
    "title": "Guide to N3C",
    "section": "Platform",
    "text": "Platform\n\nAs the chapters are being written, talk to the chapter’s Lead Author to learn if it’s being written in GitHub or Google Docs. Eventually all Google Docs chapters will be translated to Markdown. Once a chapter has been finally converted to Markdown…\nTo make small changes like spelling corrections, we recommend editing the source directly in GitHub. It handles the details without your knowledge (like starting a fork and prompting your pull request). From the appropriate page of the book, click on the “Edit this page ” button and type your change in the GitHub editor.\nSubstantial edits and writing are better accommodated by a text editor on your local machine that can preview the rendered content as you type. We suggest Visual Studio Code or RStudio.\nYou don’t have to understand the rest to contribute, but for those interested:\n\nThe majority of this book is written in a collection of Markdown documents and assembled by the Quarto.\nAfter your change is pushed to GitHub, a GitHub Action spawns a small VM that (a) collects all the Markdown documents, (b) calls Quarto/Pandoc to convert them to html, and (c) moves the rendered html files to the “gh-pages” branch.\nGitHub Pages serves the contents of the gh-pages branch to anyone with a browser."
  },
  {
    "objectID": "index.html#funding",
    "href": "index.html#funding",
    "title": "Guide to N3C",
    "section": "Funding",
    "text": "Funding\nThe N3C is supported by NIH National Center for Advancing Translational Sciences (NCATS)."
  },
  {
    "objectID": "chapters/intro.html",
    "href": "chapters/intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "Note\n\n\n\nThis chapter is being drafted in Google Docs at https://drive.google.com/drive/u/0/folders/16QkU2vonX5iZzjsLCxIEREPEdZ9S6wza\nSee a draft of the chapter outline at https://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAt this point, any edits to this chapter should be made in Google Docs. The current Markdown is for testing only. It is NOT the source of truth (yet).\n\n\nAdditional Contributors:\n\n1.0.1 Mission\nThe National COVID Cohort Collaborative, or N3C, is an open-science community stewarded by the National Center for Data To Health (CD2H) and the NIH National Center for Advancing Translational Sciences (NCATS), with significant contributions from many partners including the Clinical and Translational Science Awards (CTSA) program, Centers for Translational Research (CTRs), and thousands of researchers from hundreds of participating institutions in the US and abroad.\nFaced with the COVID-19 pandemic, the issue addressed by N3C is clear and direct: the US has no centralized data repository for health records and related information, hindering the response of the scientific community.1 Although healthcare providers are mandated by law to utilize electronic health records (EHR), little guidance coordinates how or exactly what information to collect and store. Commercial EHR suites (e.g. Epic) are widely used, and controlled vocabularies (e.g. ICD10 and SNOMED) provide standards for representing medical information, but there are many such standards in use and EHR software is highly configurable to the needs of individual organizations. As a result, databases of EHR information across the US are largely non-interoperable, presenting challenges to researchers hoping to use this vast national store of information in practice.\n\n\n1.0.2 Common Data Models and N3C\nIn recent years, the common solution to these issues have been the creation of Common Data Models (CDMs). A Common Data Model is an agreed-upon structure and format for databases containing clinical information, into which diverse organizational EHR databases can be standardized for research purposes. Even so, healthcare organizations are reluctant to share their data directly, because these risks associated with data breaches for protected health information (PHI) defined by HIPAA are high. As a result, several groups of healthcare and research organizations have formed _federated _research networks, where each organization in a\n\n\n\nA visual representation of disparate, non-compatible EHR databases across the United States.\n\n\nnetwork translates some subset of their EHR data into an agreed-upon common data model, and affiliated researchers can then write queries intended for data in that format. Examples of such federated networks include PCORNet and i2b2, each of which utilize their own common data model. In a federated model, data queries are generated by researchers, but executed locally by the data owners and only summarized or specifically requested results are sent back to researchers. This ensures protection for the raw data (which never leaves the boundaries of any individual organization), but prevents exploratory data investigation and other techniques (like many machine-learning methods) which require direct access to the totality of the data.\nDriven by the imperative of addressing COVID-19, in concert with the use of a FedRAMP-certified cloud-based analysis ecosystem we call the N3C Data Enclave,2 N3C is partnering with EHR data providers across the nation to collect billions of EHR data points for millions of patients with and without COVID-19 in a single, secure, accessible database for research use. N3C simultaneously moderates controlled access to these data by research teams from across the country (and beyond), including from private companies, community colleges, universities, medical schools, and government entities.\nLike federated research networks, N3C also uses a common data model, known as OMOP, chosen for its strong community support and open nature, support of scientific use cases, and availability of tools for translating and working with data (we’ll discuss the OMOP data format in more detail in later chapters).3 To rapidly collect data from around the country, N3C leverages the existing work data owners have already done to convert their organization-unique data to one of a handful of N3C-supported “source” common data models: PCORNet, i2b2, TriNetX, ACT, and OMOP. A potential data partner with data in PCORNet format, for example, will locally run a set of N3C-generated “PCORNet to OMOP” translation scripts prior to transferring the result to N3C via a secure channel. The process of coalescing multiple such data payloads into a unified whole is known as harmonization, and is a complex task even after everything has been mapped to OMOP initially. Two overlapping teams of EHR data experts participate in this process: one works closely with data partners to make it as easy as possible to contribute data to N3C, and another handles the post-ingestion harmonization and comprehensive quality checks of the incoming data.\n\n\n1.0.3 The N3C “Enclave” and Data Access\nOnce harmonized and stored in the secure Enclave, the data are made available via a web-based interface to research teams using common tools such as SQL, Python, and R, as well as a number of code-light graphical user interfaces.\n\n\n\nA visual representation of N3C’s data harmonization from source-CDM model, and team-based access to these data in a secure cloud-based enclave.\n\n\nMere access to the Enclave, however, doesn’t automatically provide access to any of the protected data itself (although we do make other, publicly-available datasets available with minimal restriction for practice and learning purposes). Multiple “levels” of the data are available with different anonymization techniques applied, facilitating “just enough” access to research teams depending on their needs and ability to access protected health information. Accessing the most secure level, for example, requires obtaining approval by an Institutional Review Board (IRB) who validates the appropriateness of human subjects research, while the lowest level is heavily anonymized and accessible by private individuals (citizen scientists) with only certain legal and training requirements.\nBecause effective analysis of EHR data requires a diverse set of skills–especially clinical and data science/statistical expertise–N3C provides organizational structures and resources to rapidly create and support multidisciplinary research teams, many of which are geographically diverse as well. As of December 2021, dozens of these “Domain Teams” support nearly 300 ongoing research projects, contributed to by over 2500 researchers hailing from 250+ different institutions and organizations. Sixty-nine data partners provide EHR data for 10 million patients (⅓ of whom have had COVID-19), representing 5.5 billion lab results, 1.6 billion medication records, 1 billion clinical observations, and 500 million clinical visits. For up-to-date information on these numbers and more, visit our dashboard at https://covid.cd2h.org/dashboard.\n\n\n\nSummary statistics for N3C patients as of Aug, 2022. Confirmed COVID-19 patients are those with a known positive PCR or Antigen lab test, possible patients are those with likely symptomatology.\n\n\n\n\n1.0.4 Benefits of Participation\nFor researchers, N3C provides a unique opportunity to participate in next-generation, distributed team science. Investigators with expertise in multiple domains come together across organizational boundaries to answer questions critical to the understanding and management of COVID-19 and its impact on the health of individuals and communities across the United States. Clinical, health informatics, data science, epidemiology, biostatistics, and public health experts join forces in true team science manner to …. and form Domain Teams to support and encourage….\nFor researchers:\n\nParticipate in next-generation distributed team science\nBuild connections and collaborations\nSupport from fellow researchers and domain experts (computational, clinical, etc)\nSee chapter “Onboarding, Enclave Access, N3C Team Science”\n“N3C Clinical Domain Teams enable researchers with shared interests to analyze data within the N3C Data Enclave more efficiently and to collaborate on multi-site research. The Clinical Domain Teams, developed within the Clinical Scenarios subgroup, focus on specific clinical questions surrounding COVID-19’s impact on health conditions. Clinical Domain Teams are enabled by Slack channels for discussion, meetings, and document management, and are supported by N3C workstreams and administration. N3C encourages researchers of all levels to join a Domain Team that represents their interests, or to suggest new clinical areas to explore.”\n\n“N3C Domain Teams enable researchers with shared interests analyze data within the N3C Data Enclave and collaborate more efficiently in a team science environment. These teams provide an opportunity to collect pilot data for grant submissions, train algorithms on larger datasets, inform clinical trial design, learn how to use tools for large scale COVID-19 data, and validate results. Domain Teams are enabled by Slack channels for discussion, meetings, and document management and are supported by N3C workstreams. N3C encourages researchers of all levels to join a Domain Team that represents their interests, or to suggest new clinical areas to explore. A Domain Team can submit one or more research projects, but collaboration is encouraged for similar concepts.”\n“Multi-discipline Clinical Domain Teams focus on clinical questions surrounding COVID-19’s impact on health conditions and consist of clinical and subject matter experts, statisticians, informaticists, and machine learning specialists. Cross-Cutting Domain Teams have a varied focus that applies to multiple domains.”\n\nLargest database of de-identified EHR data in the US\n\n“one of the largest, most secure clinical data resources for accelerating and collaborating on COVID-19 research” from N3C website\n\nBig-data capabilities and powerful tools (R, python, packages, sql)\nAccessible - no compute infrastructure needed other than a browser\nLearn and gain experience working with clinical data in a common data model\nWork with EHR data that has been checked for quality, completeness, and consistency\n\nFor institutions w/ researchers (why sign a DUA):\n\nIncrease research productivity and profile\nEncourage cross-institutional/geographically-diverse connections\nProvide clinical translational research opportunities to faculty and students\nEnable real-world learning opportunities for students\n\n\nFor data partners (why contribute data):\n\nRaise institutional research profile\nGet feedback on local data quality and completeness in comparison to peers\n\nCompare your local research results to results on data from partners across the US to assess generalizability\n\nPlace your data in a secure enclave that supports broad access and reproducibility\nGrow the userbase of researchers utilizing your data, including at your own institution\n\nNews articles about N3C\nVOX one\nMIT press article\nExemplars of great projects\nQuery the community to see who wants to be featured :)\nProjects that have been in the news (press/news articles) and/or have been published, potentially highly cited\nStudent papers/projects\nMaybe restrict to those that have a peer-reviewed publication?\nBARDA challenge\n\n\n\n\n\n\nThis article in MIT Technology Review provides a good overview of N3C and the surrounding landscape: It took a pandemic, but the US finally has (some) centralized medical data.↩︎\nThe Federal Risk and Authorization Management Program (FedRAMP) is a rigorous, standardized certification program with an emphasis on security and information protection. The Enclave is an installation of Palantir Technologies’ Foundry platform, a FedRAMP-certified data analytics suite.↩︎\nOMOP was originally developed by its namesake, the Observational Medical Outcomes Partnership, but is now stewarded by the Observational Health Data Sciences and Informatics (OHDSI, pronounced “odyssey”), an international group of researchers and clinicians. For complete information about OHDSI and OMOP, see the Book of OHDSI.↩︎"
  },
  {
    "objectID": "chapters/research-story.html#sec-story-onboarding",
    "href": "chapters/research-story.html#sec-story-onboarding",
    "title": "2  A Research Story",
    "section": "2.1 Onboarding",
    "text": "2.1 Onboarding\nThe startup costs are more expensive for an N3C investigation compared to most, but the incremental costs are cheaper. Even with strong institutional support, the university’s agreement with the NIH takes several months in legal and administrative channels. Yet after clearing that first (tall) hurdle for your site, each specific project takes only a week or two to be processed by the N3C staff. That’s a remarkably short time considering the scale of available data. It’s likely quicker than initiating a project based on a single EMR from your site –much quicker than EMRs from 70+ sites.\n\n\n\n\n\n\nVoice of someone like Bill Kurtis, but without the connotation of murder\n\n\n\nThe next afternoon you are chatting with your institution’s Navigator.1 She organized the local N3C presentation and invited any interested attendees to contact her.\n\n\n\n\n\n\n\n\nHover over a footnote to see the popup, without jumping to the bottom of the page.\n\n\n\n\nNavigator: I’m glad you think the N3C might help your research. As I wrote in this morning’s email, the agreement between the university and the NIH was established last year, so don’t worry about that.2 There are two remaining steps. First, complete your personal paperwork.3 Second, submit a DUR tailored to your hypotheses.4\nInvestigator: Remind me what a DUR is?\nN: A data use request describes your upcoming project. Once a committee approves your proposal, your project’s code and data are protected in this workspace allotted on the NIH cloud.5 Everyone on your project uses this dedicated workspace too. But they don’t have to submit additional DURs –your grant them permission to join yours.6\nI: Umm, I think I got it.\nN: It will make sense once you get it into it. Skim the example DUR proposals I’m sending now. Then start filling out this online form. Get as far as you can, and then I’ll help with the rest. If there’s something I don’t know, I’ll ask a friend. The DUR application process will take about an hour. Then the proposal will likely be approved within a week or two. In the meantime, we can talk about potential collaborators."
  },
  {
    "objectID": "chapters/research-story.html#sec-story-team",
    "href": "chapters/research-story.html#sec-story-team",
    "title": "2  A Research Story",
    "section": "2.2 Team building & collaborating",
    "text": "2.2 Team building & collaborating\nThe next step is to build a team to leverage retrospective medical records. Like most contemporary research teams, heterogenous skills are important. Ideally a team has at least:\n\na navigator who has learned the administrative and IRB requirements and is able to facilitate the investigation,\na data engineer who understands the challenges of EMRs and is able to extract and transform information,\na statistician who understands the limitations of observational collection and is able to model retrospective data,\na subject matter expert (SME) who has clinical experience with the disease of interest and is able to inform decisions with EMR variables, and\na principal investigator who knows the literature and is able form testable hypotheses and write the manuscript.\n\nN3C teams have some differences from conventional research teams at single sites. Some trends we have noticed are:\n\nMost N3C teams have researchers from at least three institutions. In the experience of the authors and editors, this encourages more diverse opinions and more willingness to express constructive criticism. Researchers from a single institution/lab are sometimes are more reluctant to generate contrary views.\nThe role of navigator is even more important. Your local EMR investigations are likely guided by someone with years of experience with the institutional safeguards and the personnel who can help when something stalls. N3C is bigger and younger than your site’s EMR research team, so an N3C project will benefit when guided by a bright, patient, and persistent navigator.\n\nIf your team needs someone, consider asking a relevant domain team for helping identifying and approaching a potential collaborator.\n\n\n\n\n\n\nVoice of Jamie Foxx\n\n\n\nRecruiting your crew…"
  },
  {
    "objectID": "chapters/research-story.html#research-teams-first-meeting",
    "href": "chapters/research-story.html#research-teams-first-meeting",
    "title": "2  A Research Story",
    "section": "2.3 Research Team’s First Meeting",
    "text": "2.3 Research Team’s First Meeting\n\n\n\n\n\n\nVoice of …\n\n\n\nThree weeks later…\nOnce the team is assembled, the first discussion is usually a variation of this exchange:\n\n\n\nInvestigator: Welcome everyone. We’d like to know if Drug A or Drug B is associated with better outcomes.\nStatistician: No problem. I can longitudinally model the type and amount of each medication received by each patient, relative to their intake date.\nData Engineer: Hmmm. I’m happy to produce a dataset with the dose and frequency columns7, but you may not find it useful. Those two columns are sparsely populated and they look inconsistent across sites.8\nI: Bummer. Then what’s realistic or feasible?\nSubject Matter Expert: Maybe this simplifies the picture… In my clinical experience, a patient rarely switches between Drugs A & B. Based on the initial presentation, their provider will pick A or B, and complete the regimen unless there’s an adverse event.\nS: In that case, should my initial model have three levels for treatment: A, B, and A+B?\nI: Probably. In the N3C database, can someone tell me how many patients get both during the same visit?\nDE: I’m already logged into the Enclave9. Give me 2 minutes to whip up something in SQL.10\nI: Oh my goodness, is that your cat? What a cutie! 11\nDE after a few minutes: Ok, I got it. [Unmutes himself.] Ok, I got it. 40% of patients are Drug A only, 52% are Drug B only, while 8% have at least one administration of both Drug A & B in the same visit.\nSME: Weird. 8% is a lot more than I expected. I was thinking around 1%.\nDE: Hmm, let me check. Give me another minute.12\nDE after a few minutes: I see what you mean. It looks like the bulk of the combo patients were admitted in the spring of 2020. After Jan 2021, only 3% of patients have both Drug A & B.\nS: I was already planning to model the phase of the pandemic. I’ll test if there’s a significant interaction between time and treatment.\nI: I like that as a starting point. Regarding the question about dose and frequency… For now let’s assume the providers were following the current dosing guidelines. Therefore the dose and frequency variables can be dropped from the analyses.\nS: Phew. I didn’t want to admit this. But I skimmed the dosing guidelines you emailed yesterday. It looked complicated. I wasn’t sure if I could appropriately incorporate those variables in the model.\nI: Well, that’s everything I wanted to cover today. See you in two weeks. Wait. I can’t believe I forgot. Sorry -our Navigator is sick this week and I’m almost worthless in her absence. Is everyone still on the call? For our secondary hypothesis, we want everything to connect to a patient’s diagnoses. …before, during, and after their covid hospitalization.\nDE: Bad news. This is kinda like the dose and frequency situation a few minutes ago. The structure of the OMOP diagnosis table theoretically can connect a patient’s diagnoses across different locations. But the quality of the historical records really depends on the site. Some places like Delaware leverage their state’s HIE13 to populate their N3C dataset. However other places are not as well connected. If a patient doesn’t have diagnosis records, it’s tough to determine if they are healthy, or if their primary care provider uses a siloed EMR.14\nI: Ugh. Good point.\nDE: But I’ve got good news. All the N3C contributors comprehensively capture all conditions diagnosed during the visit. Furthermore the diagnosis codes are standardized really well across sites. That’s because all the providers enter ICD codes into the EMR, which eventually can be cleanly mapped to OMOP’s standard concepts.15\nI: Well, that’s fine for this paper. Maybe our next manuscript will follow up with N3C’s death records.16\nSME: Sorry everybody, I have clinic this week, and they’re calling me. I need to drop.17\nS: Can I go back and ask a question about medications? I see that Drug A has 15 different brand names. I don’t recognize half of them. How should I classify them?\nDE: It’s actually worse than that. Sorry I’m a downer today. Can you see my screen? Drug A has 15 brand names and 200 different RxNorm codes; each package is uniquely identified by the NIH’s NLM. SME and I started on a concept set Thursday. We’re operationalizing the drug classes by their RxNorm ingredient. There are five ingredients that are conceptualized as Drug A. A friend showed me how she used the OMOP tables in a different project.18 I’ll roll up the meds into the patient-level dataset. It will have one integer for the number of medication records tied to a Drug A ingredient and another integer for Drug B records. You’ll probably want to transform the two counts into two booleans.\nS: And if I change my mind and decide to use the counts, then at least I’ll know.\nShoreleave: and knowing is half the battle."
  },
  {
    "objectID": "chapters/research-story.html#protocol-variables-definitions",
    "href": "chapters/research-story.html#protocol-variables-definitions",
    "title": "2  A Research Story",
    "section": "2.4 Protocol, variables, & definitions",
    "text": "2.4 Protocol, variables, & definitions\nThis aspect of the scientific process is probably both the most familiar and most vague. Most researchers have several years of graduate-level courses and real-world experience.\n\nTradeoffs are inevitable when selecting variables. Rarely will an investigator’s first choice be available.\nRetrospective medical records are extracted from a larger dataset. An investigation can use only a fraction of the terabytes in an EMR. Many decisions are involve to include only the relevant variables among the qualifying patients.\n\n{Mention CD2H’s Informatics Playbook}\n(Wu and C2DH 2022, chap. 1)"
  },
  {
    "objectID": "chapters/research-story.html#creating-an-analysis-ready-dataset",
    "href": "chapters/research-story.html#creating-an-analysis-ready-dataset",
    "title": "2  A Research Story",
    "section": "2.5 Creating an analysis-ready dataset",
    "text": "2.5 Creating an analysis-ready dataset\n{Conventional data engineer role. Dataset is created with input from the analyst.}"
  },
  {
    "objectID": "chapters/research-story.html#learning-and-using-omop-e.g.-concept-sets",
    "href": "chapters/research-story.html#learning-and-using-omop-e.g.-concept-sets",
    "title": "2  A Research Story",
    "section": "2.6 Learning and using OMOP (e.g. concept sets)",
    "text": "2.6 Learning and using OMOP (e.g. concept sets)\nOMOP originated in 2014 to facilitate the detection of small but significant side effects from new pharmaceuticals. Detecting a small signal requires a large datasets –larger than any single health care database (Observational Health Data Sciences and Informatics 2019, chap. 1). Since then, the foundation has supported many other research goals. It is well-suited for N3C because:\n\nIt has evolved from 10? years and accommodates a wide range of data sources\nIt has an established community and documentation to help institutions convert their EMR to OMOP and to help researchers analyze their hypotheses.\n\n{3-4 sentence description of the original OMOP motivation. It standardizes (a) tables & columns and (b) vocabulary. Spend 1-2 paragraphs on concept set, focusing more on motivations than the mechanics.}"
  },
  {
    "objectID": "chapters/research-story.html#analyses",
    "href": "chapters/research-story.html#analyses",
    "title": "2  A Research Story",
    "section": "2.7 Analyses",
    "text": "2.7 Analyses\n\nDeveloping the Analyses\nfinalizing analysis\n\nPinning to a release\nDRR\nfigures"
  },
  {
    "objectID": "chapters/research-story.html#draft-paper-pub-committee",
    "href": "chapters/research-story.html#draft-paper-pub-committee",
    "title": "2  A Research Story",
    "section": "2.8 Draft paper, pub committee",
    "text": "2.8 Draft paper, pub committee\n\n\n\n\n\n\nVoice of Sam Elliot\n\n\n\nNearing the trail head…\n\n\n\n\n\n\nObservational Health Data Sciences and Informatics. 2019. The Book of OHDSI: Observational Health Data Sciences and Informatics. United States: Independent. https://ohdsi.github.io/TheBookOfOhdsi/.\n\n\nWu, Chunlei, and C2DH. 2022. “Informatics Playbook.” https://playbook.cd2h.org/."
  },
  {
    "objectID": "chapters/lifecycle.html",
    "href": "chapters/lifecycle.html",
    "title": "3  Data Lifecycle - From Patients to N3C Researchers",
    "section": "",
    "text": "Note\n\n\n\nThis chapter is being drafted in Google Docs at https://drive.google.com/drive/u/0/folders/1ZjnFezddZk0YllqIDZN1mgexn1yM51tH\nSee a draft of the chapter outline at https://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAt this point, any edits to this chapter should be made in Google Docs. The current Markdown is for testing only. It is NOT the source of truth (yet)."
  },
  {
    "objectID": "chapters/governance.html",
    "href": "chapters/governance.html",
    "title": "4  Governance, Leadership, and Operations Structures",
    "section": "",
    "text": "Note\n\n\n\nThis chapter is being drafted in Google Docs at https://drive.google.com/drive/u/0/folders/19lryu26FaMAVrDHHARYcFJFpb18vOxcT\nSee a draft of the chapter outline at https://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAt this point, any edits to this chapter should be made in Google Docs. The current Markdown is for testing only. It is NOT the source of truth (yet)."
  },
  {
    "objectID": "chapters/onboarding.html#researcher-eligibility",
    "href": "chapters/onboarding.html#researcher-eligibility",
    "title": "5  Onboarding, Enclave Access, N3C Team Science",
    "section": "5.1 Researcher Eligibility",
    "text": "5.1 Researcher Eligibility\nCitizen scientists, researchers from foreign institutions and researchers from U.S.-based institutions are all eligible to have access to the N3C Data Enclave. Everyone with an N3C Data Enclave account has access to the tools and public datasets that are available in the Enclave.\nThere are several levels of Electronic Health Record (EHR) data that are available within the N3C Data Enclave. (For more information about the levels of data, see the section ‘Description of Levels 1, 2, 3’ in the ‘Getting & Managing Data Access’ chapter. LINK NEEDS TO BE ADDED HERE)\nCitizen scientists are only eligible to access synthetic data (Level 1). This data is artificial but statistically-comparable to, and computationally derived from, the original EHR data.\nResearchers from foreign institutions are eligible to access synthetic data (Level 1) and patient data that has been deidentified by removal of protected health information (PHI) (Level 2). (PHI includes 18 elements defined by the Health Insurance Portability and Accountability Act (HIPAA).)\nResearchers from U.S.-based institutions are eligible to access synthetic data (Level 1), deidentified patient data (Level 2) and patient data that includes dates of service and patient zip code (Level 3). (The latter data set is referred to as a limited dataset because it contains only 2 or the 18 PHI elements.)"
  },
  {
    "objectID": "chapters/onboarding.html#registration",
    "href": "chapters/onboarding.html#registration",
    "title": "5  Onboarding, Enclave Access, N3C Team Science",
    "section": "5.2 Registration",
    "text": "5.2 Registration\n\n5.2.1 ORCiD; InCommon vs Login.gov\n\n\n5.2.2 NIH IT security training\n\n\n5.2.3 Human Subjects Training\nDue to the secure nature of the data that is available in the N3C Enclave registration of users is key. There are two options in which users can log in and create an account, InCOmmon or Login.gov. The InCommon pathway is available to select institutions that participate in that identity management service. You can clock of the link to confirm if your organization participates. If your institution does not participate with InCOmmon, you will need to create a login.gov account. Use the link to Login.gov and complete the required fields to create an account. Once you know which pathway you will use to create an enclave account there are other security measures that are put in place, you will need to have a ORCiD, complete NIH security Trainingn, and also human subjects tratining.\nORCiD, which stands for Open Researcher and Contributor ID, is a unique identifier free of charge to researchers.\nThe N3C Data enclave is hosted by National Center for Advancing Translational Sciences and all researchers must complete the “Informational Securty, Counterintelligence, Privacy Awareness, Records Management Refresher, Emergency Prepardeness Refresher” course. The course can be accessed at https://irtsectraining.nih.gov/public.aspx. The course take approximately 60-90 minutes to complete and you should print your certificate of completion. Users need to complete Human Subjects training that aligns with their institution’s guidelines. You will need to provide the date of completion as part of enclave creation.\nOverall, users will need to confirm if they use the InCOmmon or Login.gov pathway, register for an ORCiD, have completed NIH Security Training, and completed institution human subjects training."
  },
  {
    "objectID": "chapters/onboarding.html#data-use-agreements",
    "href": "chapters/onboarding.html#data-use-agreements",
    "title": "5  Onboarding, Enclave Access, N3C Team Science",
    "section": "5.3 Data Use Agreements",
    "text": "5.3 Data Use Agreements\nThe data use agreement (DUA) establishes the permitted uses of the data in the N3C Data Enclave. By signing the agreement, an institutional official is assuring that users from their institution will abide by the terms defined in the agreement.\nA DUA must be executed by National Center for Advancing Translational Science (NCATS) and a research institution. The DUA must be signed by authorized institutional officials who have the authority to bind all users at their institution to the terms of the DUA. (A citizen scientist who is not affiliated with an institution must execute a data use agreement with NCATS.) A DUA will be in effect for five years from the DUA Effective Date.\nEvery individual who has access to the N3C Data Enclave must be covered by a DUA. This DUA must be in place before an account for the N3C Enclave is requested. If your institution has an active DUA, there is no additional action required with regards to the DUA. A list of institutions with DUAs in place can be found at List of DUA Signatories: (https://covid.cd2h.org/duas).\nThe Institutional Data Use Agreement form is available at:\nhttps://ncats.nih.gov/files/NCATS_N3C_Data_Use_Agreement.pdf\nFor more information see:\nhttps://ncats.nih.gov/n3c/resources/data-access"
  },
  {
    "objectID": "chapters/onboarding.html#enclave-access",
    "href": "chapters/onboarding.html#enclave-access",
    "title": "5  Onboarding, Enclave Access, N3C Team Science",
    "section": "5.4 Enclave Access",
    "text": "5.4 Enclave Access"
  },
  {
    "objectID": "chapters/onboarding.html#research-project-teams",
    "href": "chapters/onboarding.html#research-project-teams",
    "title": "5  Onboarding, Enclave Access, N3C Team Science",
    "section": "5.5 Research Project Teams",
    "text": "5.5 Research Project Teams\n\n5.5.1 Project Lead vs COllaborations\n\n\n5.5.2 Common roles and expectations (PIs, PMs, SMEs, Analysts, …)\n\n5.5.2.1 Expertise needed"
  },
  {
    "objectID": "chapters/onboarding.html#domain-teams",
    "href": "chapters/onboarding.html#domain-teams",
    "title": "5  Onboarding, Enclave Access, N3C Team Science",
    "section": "5.6 Domain Teams",
    "text": "5.6 Domain Teams\nThe N3C Data enclave is built for multi-site collaboration, and aims to bring together researchers of different backgrounds with similar questions using domain teams. Because N3C is multi-site, it can be difficult to collaborate with researchers of different backgrounds from different sites. Domain Teams exist to alleviate this difficulty. Some collaboration examples could be collecting pilot data for grant submission, sharing methodology and cohort logic, or learning how to use tools for large-scale data like machine learning.\nFor example, let’s say your institution just signed the DUA and you have some questions about the relationship between rurality and COVID treatments. You can look at the list of domain teams to see rural health. Then you can get in contact and go to the next upcoming meeting. At the meeting you can find out whether your questions are already part of an existing project within the domain team, or if a new project should be created.\nIf you don’t see your type of questions belonging to any existing domain teams you can create a new one here:\nhttps://n3c-help.atlassian.net/servicedesk/customer/portal/2/group/3/create/58\nSee here for a list of existing domain teams:\nhttps://covid.cd2h.org/domain-teams"
  },
  {
    "objectID": "chapters/onboarding.html#browsing-researchersprojectsinstitutions",
    "href": "chapters/onboarding.html#browsing-researchersprojectsinstitutions",
    "title": "5  Onboarding, Enclave Access, N3C Team Science",
    "section": "5.7 Browsing Researchers/Projects/Institutions",
    "text": "5.7 Browsing Researchers/Projects/Institutions\n\n5.7.1 Object Explorer, Public Dashboard\nOnce you have an enclave account you can log in and use the object explorer to browse researchers and research projects. The object explorer can be found on the left hand side of your view on the enclave homepage. Click on Object Explorer and there are several object-type groups, to search researchers and projects, click on N3C Admin, from there are you can search Data Use Requests, N3C Researchers, and Research Projects. If you are looking for a particular N3C researcher, you can click on that box and in the search bar type in their name and hit enter. A new box will be displayed and you can clock on that researcher’s name and from there you can see the research projects that are lead of or a collabotaro on. You can go back to the Object Explorer, object type groups, click N3C Admin again, and search research projects by clicking that box. Using the search bar at the top of the page you can search by key word. Type in the key word and click enter and a results box will be displayed. You can view all results to find the project in which you are interested in joining. From that screen, you can select the title of the project that you are interested in joining or reading about. There is a public-facing version of searching projects in addition to using the enclave as a search method. Users can search https://covid.cd2h.org/projects or https://covid.cd2h.org/dashboard/exploration#projects and search for title, lead investigator name and also the institution. There are many features that are available to search using the public-facing dashboard. There are four categories of."
  },
  {
    "objectID": "chapters/data-access.html",
    "href": "chapters/data-access.html",
    "title": "6  Getting & Managing Data Access",
    "section": "",
    "text": "Note\n\n\n\nThis chapter is being drafted in Google Docs at https://drive.google.com/drive/u/0/folders/1rrYYjSm5cWni1wyvs__-ByPl9Q6uRy10\nSee a draft of the chapter outline at https://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAt this point, any edits to this chapter should be made in Google Docs. The current Markdown is for testing only. It is NOT the source of truth (yet)."
  },
  {
    "objectID": "chapters/data-understanding.html",
    "href": "chapters/data-understanding.html",
    "title": "7  Understanding the Data",
    "section": "",
    "text": "Note\n\n\n\nThis chapter is being drafted in Google Docs at https://drive.google.com/drive/u/0/folders/1OHv1P2DKGucKBpSNEiQp8lGfR2xYHPAW\nSee a draft of the chapter outline at https://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAt this point, any edits to this chapter should be made in Google Docs. The current Markdown is for testing only. It is NOT the source of truth (yet)."
  },
  {
    "objectID": "chapters/data-analysis.html#identifying-concept-sets",
    "href": "chapters/data-analysis.html#identifying-concept-sets",
    "title": "8  Analyzing the Data",
    "section": "8.1 Identifying Concept Sets",
    "text": "8.1 Identifying Concept Sets\nAs data is ingested from the ever-growing list of data partners, the electronic health information coded in the various vocabularies used across the country are mapped to a single vocabulary of SNOMED CT. This is the core terminology for the OMOP common data model used within the enclave and a designated standard used to represent clinical meanings in a hierarchical structure. By leveraging the hierarchical structure, parent codes and descendants can be captured with ease to create intentional concept sets for use in analysis. For more details around the process of concept set creation, read the [authoring concept sets]#Authoring-Concept-Sets section.\nThe Concept Set Browser is an N3C specific tool that allows researchers to explore and modify existing concept sets as well as create new concept sets to fit their exact study needs. New researchers can start their search for a concept set with the list of N3C Recommended concept sets. These concept sets have been frozen in their validated state by the Logic Liaisons and the Data Liaisons after obtaining clinician and informatic reviews. These concept sets are the ones used to identify common comorbidities and other facts on the Phenotype Explorer and in the Logic Liaison Fact Table templates. The other method of finding commonly used concept sets is by exploring bundles within the Concept Set Browser. These are sets of concept sets that are often used together in a group. These are created by *** and used when ***."
  },
  {
    "objectID": "chapters/data-analysis.html#using-concept-sets",
    "href": "chapters/data-analysis.html#using-concept-sets",
    "title": "8  Analyzing the Data",
    "section": "8.2 Using Concept Sets",
    "text": "8.2 Using Concept Sets\nOnce concept sets have been identified for use in an analysis through the concept set browser, the concept set members table becomes the link between concepts and the encompassing concept set. Researchers can use concept sets by referencing the concept set name or the concept set version id also known as the codeset id. When searching for a concept set by name, it is recommended to also use most_recent_version = true to obtain the most up to date list of concept ids at any point in the analysis. This method is highly favored if the concept set is marked as N3C Recommended since these concept sets can only be updated by a small number of approved users after they have gone through re-validation, if necessary, following updates such as vocabulary changes. Researchers may choose to look up concept sets in the concept set members table by their codeset id if they wish to use the current most recent version of a concept set that is not N3C Recommended as any user can make edits to these concept sets. This will allow researchers to perform their analysis from start to finish without worry that someone has modified their concept set midstream without their knowledge. The other instance in which a researcher may choose to reference a concept set by codeset id is when choosing to use a specific prior version of an existing concept set."
  },
  {
    "objectID": "chapters/data-analysis.html#using-the-knowledge-store",
    "href": "chapters/data-analysis.html#using-the-knowledge-store",
    "title": "8  Analyzing the Data",
    "section": "8.3 Using the Knowledge Store",
    "text": "8.3 Using the Knowledge Store\nThe N3C Knowledge Store is an application where Enclave users can discover shared Code Templates, External Datasets, Reports, Cohorts, and Python Libraries (all also known as Knowledge Objects) and share similarly re-usable Knowledge Objects of their own with other Enclave users, regardless of the specific DUR from which the resource originated. Majority of Knowledge Store objects come about as core contributors and researchers alike develop resources they believe may be useful for others either within or outside of their research project team and wish to share them with the broader community. If you find yourself in this situation, you can easily create a KS resource that can be shared using Palantir’s documentation around templatization and submitting to the Knowledge Store. Otherwise, more specifics on how to navigate the Knowledge Store can be found in this [guide]#Knowledge-Store-Guide within the Enclave. Of the many types of Knowledge Objects, the most common are code templates and datasets.\nDatasets in the Knowledge Store can be internal or external datasets. Internal datasets are generated from data inside the enclave, typically by researchers as part of their project, and are often of patient level granularity. External datasets found in the Knowledge Store provide a wealth of information from public datasets that have been brought into the Enclave along with the crosswalks necessary for joining these aggregate data to person level data at various levels of granularity. Either type of dataset can be imported into a workbook or code repository to be used as a starting point for further transformation or analysis.\nDepending on the author’s intended use, some code templates can be applied to a researcher’s custom input dataset while other code templates produce a dataset that can be joined with a researcher’s study cohort. The code templates can also be imported and customized to produce a dataset for study analysis or simply used as example logic for Enclave users who are newer to coding. A few helpful starter templates are those produced by the [Logic Liaisons]#N3C-Logic-Liaisons. Through surveying the Domain Team Leads to establish a list of commonly derived variables and continuous feedback from the N3C Community to refine and update this list, the Logic Liaisons have developed, disseminated, and continue to maintain two master fact templates. These two master fact templates each produce visit-level and person-level data frames of commonly used derived variables for [all N3C patients]#All-Patients-Template as well as a subset who have an index date for their acute COVID-19 infection, the [confirmed COVID-19 Positive patients]#Confirmed-Covid-Pts-Template (PCR/AG positive or U07.1 COVID-19 diagnosed).\nThe Logic Liaisons have also developed, disseminated, and continue to maintain a handful of sister fact templates and data quality templates in the Knowledge Store. The sister templates utilize the visit-level and person-level datasets of the master fact template to efficiently generate additional derived variables based on broadly requested and applicable logic such as study-specific fact indexing, co-occurrence, and CCI score calculations. The data quality templates provide a variety of visualizations for looking at [data density of the OMOP domain tables]#Data-Density. When looking to assess study specific variables, the [Systematic Missingness template]#Systematic-Missingness provides an all or nothing fact density indicator while the [Fact Density by Site template]#Fact-Density provides relative densities of a fact across sites. [Training materials]#Logic-Liaison-Tutorials for getting started with Logic Liaison templates are available within the Enclave.\nWhile it is not necessary to utilize Knowledge Store resources when conducting your research project, it does allow you to get a jumpstart on gathering and understanding the data by avoiding effort duplication and providing a general starting point. The Logic Liaison fact templates are specifically designed to provide a validated and community agreed-upon method for calculating particular facts at the encounter level and/or the patient level. The Logic Liaison data quality templates provide the same structure for analyzing data missingness, density, and contribution quality by site."
  },
  {
    "objectID": "chapters/data-analysis.html#enclave-applications",
    "href": "chapters/data-analysis.html#enclave-applications",
    "title": "8  Analyzing the Data",
    "section": "8.4 Enclave Applications",
    "text": "8.4 Enclave Applications\nThis section will cover the usage of various applications made available in the N3C Enclave, including Contour, Code Workbooks, Reports, and more (a complete list of Foundry applications can be found here). However, before designing and running an analysis utilizing data in the Enclave, it helps to understand the concept of a “data transformation” and how the data is stored and accessed via SPARK on a distributed file system.\n\n8.4.1 10,000 foot view of distributed file systems, SPARK, and data transformations\nData in the N3C Enclave is so large it cannot be stored all in one giant table. Instead it is stored on multiple servers in what is called a “distributed file system” where sets of rows in a table may be stored across multiple physical servers (Figure 1). Accessing these multiple servers to get data from one table requires a lot of coordination behind the scenes. SPARK is the program coordinating the fetching, writing, and analysis of data. You, as an Enclave user, can interface with SPARK through familiar Python, R, and SQL commands in order to retrieve data and run your analysis. You don’t necessarily need to know all of the details in how SPARK operates to run basic code; however, when working with data in the N3C Enclave it is highly recommended to get more acquainted with how SPARK operates in order to optimize your code to make it run faster (like WAY faster). You can reference Chapter X of this book, or Palatir’s SPARK Fundamentals and SPARK Optimization modules for more details on SPARK and how to optimize your code. For the rest of this chapter we are just going to focus on how SPARK uses “data transformations’’.\nThe basics of a data transformation are illustrated in Figure 2A. One or more tables are specified as the input and are transformed into a single output table. Multiple transformations can be strung together (Figure 2B) to create an analysis pipeline (see Palatir’s Anatomy of a Data Pipeline module for more detailed information, as well as Best Practices in Chapter X). The primary and required output is always a single table; however, visualizations such as graphs and charts can also be generated and saved along the way. You, the user, define the transformations using Enclave applications like Contour and Code Workbooks. Fusion sheets can be utilized to manually create tables for input into an analysis (e.g. to hold configuration options or frequently used codesets), and Reports are used to compile and display analysis results such as summary tables, graphs, and charts. In the following sections, each of these applications is discussed in more detail.\n\n\n8.4.2 Contour\nFoundry’s Contour application is a programming-free interface to the N3C Enclave that allows those with limited knowledge of Python, R, and SQL to create top-down analysis pipelines in a point-and-click fashion, as well as interactive dashboards for sharing results. It is best used to quickly summarize and visualize data, and usage of Contour’s expression language allows for more complex querying and data aggregation. One of the advantages of Contour is the ability to quickly and easily create summary figures with various complexity from source tables without having to code. Contour has a variety of figure options, including bar charts, histograms and heatmaps. A detailed orientation to Contour can be found in the Foundry Documentation here.\n\n\n8.4.3 Fusion\nPalantir Documentation: Fusion Sheet Overview\n\nUseful for writing back datasets for use within the Enclave\nLeverage cell references and spreadsheet functions\nIndex datasets\nSync tables to a dataset to use in other Foundry applications\nImport xls data\nCreate charts\nAllows customization and flexibility\n\n\nFusion is a spreadsheet application within the Enclave analogous to Excel or Google Sheets. Palantir has curated extensive documentation describing its core functionality as well as providing select how-to tutorials. The primary utility of Fusion is to allow users to sync specific cell ranges of values within a spreadsheet to datasets, which can subsequently be [imported]#Importing-and-Viewing-Data into any other Enclave application. This tool is an excellent option for use cases which require manual data entry, such as curating lists of [concept sets]#Concept-Set-Section to configure the [Logic Liaison Fact Templates]#LL-Fact-Templates. Unlike many other Enclave applications, Fusion is not suitable for large datasets; it has a maximum size restriction of 50 MB per document. Similar to Google Sheets, Fusion allows users to simultaneously edit the same document and view other users’ changes in real time.\nAs any Excel super user knows, a spreadsheet is not merely a mechanism for storing data, but also a powerful tool for analyzing, visualizing, and applying complex logical operations on data in its own right. Fusion provides many features familiar to other spreadsheet applications such as cell-referencing formulas, formatting, and a charting library to name a few. External .xls/.xlsx formatted files (up to 4 MB) can be directly imported into the Enclave as Fusion sheets with all cell references, formulas, and formatting preserved. [caveat].\nIn addition to standard spreadsheet functionality, Fusion has additional features which allow it to bi-directionally integrate with the rest of your Enclave environment. The first such feature is the ability to import other Enclave datasets into Fusion. Prior to using any dataset in Fusion (including datasets synced from Fusion sheets), it must first be indexed into a non-distributed format using the _Data _tab in the top menu. You can view available indexed datasets using the Data>Datasets available menu option. Objects created within Fusion, such as formatted tables can be embedded in reports#Reports. Finally, Fusion sheets can be templatized to facilitate replication of similar functionality.\n\n\n8.4.4 Code Workbooks\nTutorial: Intro to Code Workbook\nPalantir Documentation: Code Workbook Overview\n\ngraphical organization of logic\nSimplification of code\neasy reuse of pre-authored logic\nAdd visualizations from here to reports\nSupports Python, R, and SQL\nBranching facilitates collaboration\nWorkspace to reuse templatized logic\n\nCode Workbook is a GUI-based application for users to apply code-based transformations to datasets for the purpose of creating new datasets and visualizations. The explicit goals of the application are to facilitate a collaborative environment in which users can quickly iterate over logic to produce artifacts interoperable with the suite of Enclave applications. The default Code Workbook interface is structured as a directed graph in which nodes represent either datasets or transformations which can output datasets. Edges represent the flow of data through the graph such that upstream datasets are inputs for logical operations performed by downstream code transforms (see Figure). Any dataset which a user has access to within the workspace where the Code Workbook is located can be imported as an input to the various types of transform.\n\n8.4.4.1 Types of Transform\n\nManual Entry transforms allow users to manually curate non-persisted datasets directly in the Code Workbook as a “quick and dirty” alternative to manually curating persisted datasets with Fusion#Fusion.\nPython Code transforms let users write a Python function with input datasets as input parameters.\nR Code transforms let users write an R function with input datasets as input parameters.\nSQL Code transforms let users write a SparkSQL query to create a new dataset from the available inputs\nTemplate transforms are parameterized blocks of reusable code which users can configure from a point-and-click interface. Many code templates are available in the [Knowledge Store]#Knowledge-Store, but users can also create their own templates scoped to their DUR workspace. Multiple single-node templates can be combined to create a multi-node template to allow reuse of entire configurable pipelines.\nVisualize transforms offer a point-and-click interface for users to create charts, distributions, histograms, and pivot tables. Note this transform is only available for saved datasets.\n\nBoth Python and R transforms can optionally return a single dataset and produce visualizations using Python libraries/R packages. Any visualization produced in a Code Workbook and subsequently be embedded in a Reports#Reports document. Datasets returned by a transform are ephemeral by default, that is, the transform must be recomputed each time the dataset is used as a downstream input, but options exist to conserve compute power by either caching or saving the output. Caching stores the output temporarily, while saving the dataset stores it permanently in the Enclave. It is recommended that transforms in a pipeline requiring significant compute be saved as datasets to reduce iteration time during development. Once a dataset is saved, users can set triggers and schedules for it to be automatically updated when certain input datasets are updated or at regular temporal intervals.\nTooling is available within Code Workbooks to facilitate the application objective of quick iteration. The console feature, located in the top right, allows users to interactively explore logic and syntax in Python, R, or SQL outside of a transform node. Also in the top right, is the Global Code section where users can globally import Python libraries and R packages or define custom functions to be used in any transform in the Code Workbook. Code transforms include a Logs feature for users to view console output generated by code and to view detailed stack traces when transforms fail due to an error.\nMany Python and R transforms rely on external libraries and packages which can be made available via the Environment Configuration. The Enclave provides a number of default configurations tailored to common use cases, for instance, the default profile, which includes common packages like pandas and tidyverse is suitable for routine analysis, whereas the profile-high-memory profile includes packages like founder_ml to facilitate machine learning. Users can create their own Environment Configurations which include packages meeting their specific needs. Not all libraries and packages are included in the list of options, but users can [submit a ticket]#Tickets to request additional packages be made available. The Enclave maintains instances of the non-custom configurations on warm standby, allowing them to be quickly initialized when a user requests a new environment. Custom configurations require more time for initialization as instances of these must be started from scratch rather than merely assigned. For this reason, it is recommended to use non-custom configurations when possible.\nFollowing best practices for collaborative software development, Code Workbook allows for branching of the logic within a workbook. As with other popular source control technologies (i.e. git), branching allows users to make copies of a workbook which they can develop independently of the source workbook. Once the development in a particular branch is deemed complete, it can be merged back into the originating branch. Prior to the merge, users can preview both line-level differences within each node, as well as node-level differences of nodes that have been added/removed. Good practice dictates that individual users perform all development on individual branches, which are then merged back into a common master branch. Because the master branch can change in the interval between a user cutting a branch and merging it back in, previewing merge changes is an important step for ensuring that the individual’s changes are both correct and compatible with the current state of the master branch. Another prime use case for code branching is to ensure the reproducibility of a given dataset used in a research project. Because the OMOP and N3C-curated datasets are also versioned, teams can create a code branch in which all input datasets are set to the same version release to effectively freeze a dataset used in a specific analysis for later reproducibility while still allowing the possibility of adding additional features. User generated datasets are set to the same branch as the Code Workbook in which they were created.\nPalantir has created extensive documentation of the Code Workbook application including tutorials. N3C has also published training materials.\n\n\n\n8.4.5 Reports\nPalantir Documentation: Reports Overview\n\ndisplay charts and visualizations in combination with text descriptions about the analysis\nCollaborate with others through comments on the reports\nAdd context by attaching images and other files\nCreate a story around analysis results\nUseful when sharing results or even just putting together preliminary look at the progress\n\nMany research projects in the Enclave are complex, involving multiple summary datasets, statistical analyses, and visualizations scattered across multiple applications and documents. Reports is a tool for consolidating various research artifacts from multiple sources within the Enclave into a single coherent document. Formatted Fusion#Fusion tables, Contour#Contour charts, Python/R-generated images from Code Workbooks#Code-Workbooks, and more are all embeddable in a Reports document, with the option to add a title and/or caption for each embedded artifact. Users can also create sections and provide narrative structure to their documents using MarkDown blocks. All components of a Reports document can be arranged and configured using a point-and-click interface.\nAll embedded objects can be configured to refresh automatically when the underlying data sources update, allowing Reports to function effectively as dashboards. Reports are also useful for presenting an executive summary of results for internal stakeholders as well as external presentations. [Logic Liaison Templates]#LL-Templates in the [Knowledge Store]#Knowledge-Store generally includes a README which is created using Reports. Reports can be requested for download using the Download Request Form. Palantir has curated documentation for creating and editing Reports.\n\n\n8.4.6 Object Explorer\nPalantir Documentation: Object Explorer\nTutorial: Exploring N3C Projects and Collaborators with Object Explorer\n\nEasily find objects of interest\nCompare and contrast items\n\nA step upstream of the Knowledge Store is Palantir’s Object Explorer which allows users to explore and analyze objects of interest through a point and click interface. Detailed information around how to use this feature can be found in [Palantir’s documentation here]#Object-Explorer. Researchers can find unpublished Knowledge Objects, [explore N3C Projects and Collaborators]#Object-Explorer-Tutorial, view object usage statistics, etc. using this application.\n\n\n8.4.7 Data Lineage (aka Monocle)\nWhether you’re creating a pipeline for data analysis specific to your research project or investigating one you came across in the Knowledge Store to determine if it will be useful to your study, you’ll likely want the capability to holistically assess how that dataset came about. The Data Lineage tool within the Foundry platform allows users to do just that - easily explore data pipelines from start to finish. With upstream on the left and downstream on the right, this tool makes for an intuitive way to visualize the relationships between datasets and their ancestors or descendants with enhanced views made possible through color-coding and grouping based on a dataset’s details. This application is particularly useful if a researcher needs to schedule a build for a dataset to update with the weekly refresh of data in the enclave. Palantir Documentation provides a short tutorial and additional descriptions of this tool’s functionality.\n\n\n8.4.8 Code Repositories\n\n\n8.4.9 Protocol Pad\nQuick Guide\nDetailed Guide\nResearch studies can span many months and pass through the hands of many team members before reaching a stage where the researcher may want to share the results through publication or other approved means. The Protocol Pad serves as an electronic lab notebook to help organize tasks, track progress, and document results in a cohesive format throughout the process of reaching a study’s final state."
  },
  {
    "objectID": "chapters/data-analysis.html#draft-language",
    "href": "chapters/data-analysis.html#draft-language",
    "title": "8  Analyzing the Data",
    "section": "8.5 DRAFT Language",
    "text": "8.5 DRAFT Language\nTo demonstrate the use of Contour we will work through a simple use-case using the SynPuf Synthetic dataset to summarize patient demographics as a bar chart, filter a table, join in additional information from another table, and calculate a patient’s age.\n\n8.5.0.1 Interface Overview\nBefore we get started, let’s get oriented to the interface for the Contour application. To create a new Contour analysis click on the “+ New” button (Figure <new_button>) and select the “Analysis” option (Figure <analysis_option>). A new Contour analysis will open, and you will see a window similar to that in Figure <contour_interface>. To change the name of this analysis, click on the last entry in the path (Figure <contour_interface>, A). This path can also be used to navigate back to previous parent directories in the Enclave. To the right of the analysis name is a drop-down indicating you are in “Editing mode” (Figure <contour_interface>, B). Note that if more than one person has the same workbook open only one person will be given Editing privileges while the other will be in Viewing Mode.\nThe center of the screen is your working space. Currently it is empty because we have not added any datasets for analysis. To add a new data set for analysis, click on the “+ Create new path” button in the center of the screen (Figure <contour_interface>, C), or the plus “+” button towards the top of the window ((Figure <contour_interface>, D). The term “path” in Contour is used to indicate the location of a data set. Each time you “Create a Path” you are telling the application which data set to start with, whether it be a source OMOP table or the output from another Contour analysis.\n\n\n8.5.0.2 Importing and Viewing Data\nAs discussed in the introduction to this chapter, all analyses work through transformations, and Contour is no exception. Analyses in Contour are built as a pipeline working from top to bottom. To start an analysis we need to import a starting dataset (i.e. create a new path). Click on the “+ Create new path” button, then navigate to the OMOP “person” table in the Synpuf Dataset by going to “All” > “Data Catalog” > SynPuf Synthetic Data” > “person” (Figure <create_path>). Your window should now look similar to Figure <analysis_start>.\nIn this view there are 3 sections to be aware of:\n\nStarting dataset\nTransformations (currently there are none)\nResulting dataset (can be saved as a table or imported into another analysis as the starting path)\n\nTo add a transformation (a.k.a. board), just click on one of the suggestions (Figure <analysis_start>, B), or you can hover over one of the arrows before or after the suggestions and select “Insert Board” (Figure <insert_board>). These arrows will also appear before and after each transformation so you insert a transformation anywhere in the pipeline. Just be aware it will change all results downstream!\nNotice at the top where the “+” button is (Figure <analysis_Start>, red box) there is a new tab named “person”. You can create multiple analysis workflows within the same Contour analysis and navigate through them using the tabs.\nNow we have imported our first data set, however notice it is not displaying the table for a preview. Within Contour, to see the data you specifically have to tell it to create a table as one of the transformations. To preview the data in the “person” table, click on the “Visualize” button and scroll down to “Table” (Figure <table_viz>). Your screen should look like Figure <table_preview>.\n\n\n8.5.0.3 Creating Summary Figures\nOne of the advantageous things about Contour is that it is easy to quickly create summary figures of various complexity from source tables without having to code. Contour has a variety of figure options, including bar charts, histograms and heatmaps.\nTo create a bar chart of our example data, look through the table preview to identify the column name that has the variable you want to plot. In our instance it will be “race_concept_name”. Create a new transformation below the table preview for a bar chart (named “Chart” in the list, Figure <bar_chart_options>). Initially the chart is empty because we have to tell it which columns to use. In the “Data” tab on the right, set the X-Axis to be “race_concept_name”, and the Y-Axis to be “person_id” and “Unique count” (Figure <bar_char_options_set>), then click on\nCompute & save” to view the chart (Figure <bar_chart_figure>). You can utilize the “segment by” option to segment your primary column by a secondary column (Figure <bar_chart_segmented>), as well as explore some of the other options available. Note that each visualization option will have its own parameters. You can review Foundry’s documentation for more details on each of these."
  },
  {
    "objectID": "chapters/practices.html",
    "href": "chapters/practices.html",
    "title": "9  Best Practices and Important Data Considerations",
    "section": "",
    "text": "Note\n\n\n\nThis chapter is being drafted in Google Docs at https://drive.google.com/drive/u/0/folders/1ExkYChsnO3hYZk6HCI5cEfQdQJ9F-ynw\nSee a draft of the chapter outline at https://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAt this point, any edits to this chapter should be made in Google Docs. The current Markdown is for testing only. It is NOT the source of truth (yet)."
  },
  {
    "objectID": "chapters/publishing.html",
    "href": "chapters/publishing.html",
    "title": "10  Publishing and Sharing Your Work",
    "section": "",
    "text": "Note\n\n\n\nThis chapter is being drafted in Google Docs at https://drive.google.com/drive/u/0/folders/1kmrjxsdrwbspPucPTU3hiOHMXJRQQpPp\nSee a draft of the chapter outline at https://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAt this point, any edits to this chapter should be made in Google Docs. The current Markdown is for testing only. It is NOT the source of truth (yet)."
  },
  {
    "objectID": "chapters/support.html",
    "href": "chapters/support.html",
    "title": "11  Help and Support",
    "section": "",
    "text": "Note\n\n\n\nThis chapter is being drafted in Google Docs at https://drive.google.com/drive/u/0/folders/1SnhEKmA-A1GJHN5kBYRnX_za5dX_n1EC\nSee a draft of the chapter outline at https://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAt this point, any edits to this chapter should be made in Google Docs. The current Markdown is for testing only. It is NOT the source of truth (yet)."
  },
  {
    "objectID": "chapters/machine-learning.html",
    "href": "chapters/machine-learning.html",
    "title": "12  Machine Learning",
    "section": "",
    "text": "Note\n\n\n\nThis chapter is being drafted in Google Docs at https://drive.google.com/drive/u/0/folders/1HZ3IGv17zUl9t8RxZSl4uOq_FRzrgTp_\nSee a draft of the chapter outline at https://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAt this point, any edits to this chapter should be made in Google Docs. The current Markdown is for testing only. It is NOT the source of truth (yet)."
  },
  {
    "objectID": "chapters/enclave-advanced.html",
    "href": "chapters/enclave-advanced.html",
    "title": "13  Advanced Enclave Coding Techniques",
    "section": "",
    "text": "Note\n\n\n\nThis chapter is being drafted in Google Docs at https://drive.google.com/drive/u/0/folders/1K660Qn7m1z4TswwepM06CKgAPTojjt7q\nSee a draft of the chapter outline at https://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAt this point, any edits to this chapter should be made in Google Docs. The current Markdown is for testing only. It is NOT the source of truth (yet)."
  },
  {
    "objectID": "chapters/examples.html",
    "href": "chapters/examples.html",
    "title": "14  Start to finish examples or worked examples",
    "section": "",
    "text": "Note\n\n\n\nThis chapter is being drafted in Google Docs at https://drive.google.com/drive/u/0/folders/1rWxFtzk1kyUSRJPDgPWwlmVCjnWEGf6i\nSee a draft of the chapter outline at https://docs.google.com/document/d/1ttUKgwVcIZHM87elrlUNV6Qi9thzOwKBg8GegKObEtg/\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAt this point, any edits to this chapter should be made in Google Docs. The current Markdown is for testing only. It is NOT the source of truth (yet)."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Observational Health Data Sciences and Informatics. 2019. The Book\nof OHDSI: Observational Health Data Sciences and Informatics.\nUnited States: Independent. https://ohdsi.github.io/TheBookOfOhdsi/.\n\n\nWu, Chunlei, and C2DH. 2022. “Informatics\nPlaybook.” https://playbook.cd2h.org/."
  }
]